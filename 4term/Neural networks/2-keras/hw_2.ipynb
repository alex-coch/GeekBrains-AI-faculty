{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "id": "CK5v01oCYJod",
        "outputId": "70c0fb33-64a8-4c87-ba36-04e8a48a1176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "id": "BdtNDP-W6TJi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_imagef, train_labelf), (test_imagef, test_labelf) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "gEHMPKPT6bgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48f21f4-71af-48fd-cf82-becda01510b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imagef.min(), train_imagef.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn5Jwbou9jsk",
        "outputId": "72a68c44-f7d1-406b-f6b6-d1c996b9b27a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BuM-iR_xQz_9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images.\n",
        "train_imagef = (train_imagef / 255) - 0.5\n",
        "test_imagef = (test_imagef / 255) - 0.5"
      ],
      "metadata": {
        "id": "5lVWae248OUe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imagef = train_imagef.reshape((-1, 784))\n",
        "test_imagef = test_imagef.reshape((-1, 784))"
      ],
      "metadata": {
        "id": "SCdDrnv-E-WZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imagef.shape, test_imagef.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Il3FGOFxgj",
        "outputId": "69dce1e8-4f32-45b6-c285-11509eee6112"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  Dense(128, activation='relu', input_shape=(784,)),\n",
        "  Dense(100, activation='relu'),\n",
        "  Dense(80, activation='relu'),\n",
        "  Dense(10, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "z5XbPvy1HPns"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the images.\n",
        "train_imagef = train_imagef.reshape((-1, 784))\n",
        "test_imagef = test_imagef.reshape((-1, 784))"
      ],
      "metadata": {
        "id": "Fhxwn3AQNaTE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model.\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "6EOG-3VkO2VF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model.\n",
        "model.fit(\n",
        "  train_imagef,\n",
        "  to_categorical(train_labelf),\n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        ")\n",
        "# Evaluate the model.\n",
        "model.evaluate(\n",
        "  test_imagef,\n",
        "  to_categorical(test_labelf)\n",
        ")\n",
        "model.save_weights('modewlf.h5')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5LUxfMAPDE5",
        "outputId": "c7668d54-c29e-4969-cb53-0b98fa2b2b8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 16s 4ms/step - loss: 0.4885 - accuracy: 0.8218\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3726 - accuracy: 0.8623\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3367 - accuracy: 0.8768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3121 - accuracy: 0.8844\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2915 - accuracy: 0.8914\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8726\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 80)                8080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,270\n",
            "Trainable params: 122,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labelf[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6InPbmZIvZ7w",
        "outputId": "45972bd6-84c5-4c5a-9aa3-a78abb025fc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, 3, 0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_imagef, train_labelf,\n",
        "#                     batch_size=64,\n",
        "#                     epochs=3,\n",
        "#                     validation_data"
      ],
      "metadata": {
        "id": "J1sAu3esEu3N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "при увеличении числа нейронов скрытого слоя качечтво модели растет, наилучшее качество получилось при 25 эпохах\n",
        "при 5 эпохах и кол-ве обуч примеров 32 качество модели растет лучшее число 88,5 а сигмоида 0,86\n",
        "при 12 эпохах и кол-ве примеров 12 качество модели растет лучший показатель 89,7 а сигмоида 87.4 \n",
        "при 20 эпохах и и код-ве обуч 68 лучший показатель 94,4 сигмоида 88,7"
      ],
      "metadata": {
        "id": "eRvraHOgGVnB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7BN9O7bUBkJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# создаем модель model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(80, activation='relu'),\n",
        "    Dense(10, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# сохраняем ее веса (это начальная точка) model.save_weights('model.h5')\n",
        "model.save_weights('modewlf.h5')\n",
        "\n",
        "# будем сохранять модели в словарь\n",
        "models = {}\n",
        "\n",
        "plt.figure(figsize=(16, 7))\n",
        "colors = ['g', 'b', 'r']\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "# вектор для вывода результатов\n",
        "epoch = np.arange(num_epochs+1)"
      ],
      "metadata": {
        "id": "MgLv5o-xEu9u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b59315e9-cb3f-4374-8f11-2c519917157f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 57.7 ms, sys: 3.34 ms, total: 61 ms\n",
            "Wall time: 61.1 ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x700 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5mEPDyzEUhga"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "# # будем изменять оптимизаторы\n",
        "# for i, i_optim in enumerate([SGD(), RMSprop(), Adam()]):\n",
        "#     print(f'Оптимизатор: {i_optim.get_config()[\"name\"]}')"
      ],
      "metadata": {
        "id": "nlxzelh3UTUC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "# будем изменять оптимизаторы\n",
        "for i, i_optim in enumerate([SGD(), RMSprop(), Adam()]): \n",
        "    print(f'Оптимизатор: {i_optim.get_config()[\"name\"]}')\n",
        "# создаем рабочую модель  model_i, куда будем загружать эти веса (она должна быть идентичной структуры)\n",
        "  \n",
        "    model_i = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(80, activation='relu'),\n",
        "        Dense(10, activation='sigmoid'),\n",
        "    ])\n",
        "      \n",
        "  # загружаем веса model_i.load_weights('model.h5')\n",
        "    model_i.load_weights('modewlf.h5')\n",
        "      \n",
        "  # компилируем model_i с одним из оптимизаторов\n",
        "    model_i.compile(\n",
        "          optimizer=i_optim,\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'],\n",
        "          )\n",
        "\n",
        "\n",
        "      # # # вычисляем ошибку для modeli без обучения\n",
        "    # h0_train = model_i.evaluate( train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "    # h0_val = model_i.evaluate(train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "\n",
        "      # проводим обучение модели \n",
        "    h = model_i.fit(\n",
        "                  train_imagef, \n",
        "                  to_categorical(train_labelf),\n",
        "                  epochs=num_epochs,\n",
        "                  batch_size=batch_size)\n",
        "                  # validation_data=(test_imagef, test_labelf) )\n",
        "                  # verbose=0)\n",
        "\n",
        "    # вычисляем ошибку для modeli после обучения\n",
        "    loss, metric = model_i.evaluate(test_imagef, to_categorical(test_labelf), batch_size=64)\n",
        "    print(f'Качество на тесте: {loss=}, {metric=}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9H7cgEk6xAi",
        "outputId": "06425980-e793-4884-9dee-ce6d04b1a146"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оптимизатор: SGD\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7780 - accuracy: 0.7274\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4717 - accuracy: 0.8304\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4214 - accuracy: 0.8477\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3922 - accuracy: 0.8587\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3713 - accuracy: 0.8655\n",
            "157/157 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8496\n",
            "Качество на тесте: loss=0.4152015149593353, metric=0.8496000170707703\n",
            "Оптимизатор: RMSprop\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5025 - accuracy: 0.8142\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3823 - accuracy: 0.8594\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3556 - accuracy: 0.8712\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3432 - accuracy: 0.8778\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3365 - accuracy: 0.8804\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8436\n",
            "Качество на тесте: loss=0.5119884610176086, metric=0.8435999751091003\n",
            "Оптимизатор: Adam\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.4923 - accuracy: 0.8197\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3690 - accuracy: 0.8640\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3324 - accuracy: 0.8767\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3106 - accuracy: 0.8852\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2925 - accuracy: 0.8907\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8739\n",
            "Качество на тесте: loss=0.35978347063064575, metric=0.8738999962806702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_i = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(80, activation='relu'),\n",
        "    Dense(10, activation='sigmoid'),\n",
        "])\n",
        "  \n",
        "# загружаем веса model_i.load_weights('model.h5')\n",
        "model_i.load_weights('modewlf.h5')\n",
        "  \n",
        "# компилируем model_i с одним из оптимизаторов\n",
        "model_i.compile(\n",
        "      optimizer='Adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "      )\n",
        "\n",
        "\n",
        "  # # # вычисляем ошибку для modeli без обучения\n",
        "# h0_train = model_i.evaluate( train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "# h0_val = model_i.evaluate(train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "\n",
        "  # проводим обучение модели \n",
        "h = model_i.fit(\n",
        "              train_imagef, \n",
        "              to_categorical(train_labelf),\n",
        "              epochs=num_epochs,\n",
        "              batch_size=batch_size*2)\n",
        "              # validation_data=(test_imagef, test_labelf) )\n",
        "              # verbose=0)\n",
        "\n",
        "# вычисляем ошибку для modeli после обучения\n",
        "model_i.evaluate(test_imagef, to_categorical(test_labelf), batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK6LT5IRCbEy",
        "outputId": "2c243ae8-45c1-4ca0-d09b-02b107e2ee67"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 5s 4ms/step - loss: 0.5013 - accuracy: 0.8176\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3734 - accuracy: 0.8627\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3357 - accuracy: 0.8766\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3102 - accuracy: 0.8844\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2947 - accuracy: 0.8899\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35387998819351196, 0.8730000257492065]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_i = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(80, activation='relu'),\n",
        "    Dense(10, activation='sigmoid'),\n",
        "])\n",
        "  \n",
        "# загружаем веса model_i.load_weights('model.h5')\n",
        "model_i.load_weights('modewlf.h5')\n",
        "  \n",
        "# компилируем model_i с одним из оптимизаторов\n",
        "model_i.compile(\n",
        "      optimizer='Adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "      )\n",
        "\n",
        "\n",
        "  # # # вычисляем ошибку для modeli без обучения\n",
        "# h0_train = model_i.evaluate( train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "# h0_val = model_i.evaluate(train_imagef[:48000], to_categorical(train_labelf [:48000]), verbose=0)\n",
        "\n",
        "  # проводим обучение модели \n",
        "h = model_i.fit(\n",
        "              train_imagef, \n",
        "              to_categorical(train_labelf),\n",
        "              epochs=num_epochs*2,\n",
        "              batch_size=batch_size)\n",
        "              # validation_data=(test_imagef, test_labelf) )\n",
        "              # verbose=0)\n",
        "\n",
        "# вычисляем ошибку для modeli после обучения\n",
        "model_i.evaluate(test_imagef, to_categorical(test_labelf), batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4EP7LrDBqHb",
        "outputId": "31742e3e-1a64-4fe8-e2ff-f00b358eedda"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4935 - accuracy: 0.8180\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3726 - accuracy: 0.8614\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3364 - accuracy: 0.8749\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3134 - accuracy: 0.8825\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2938 - accuracy: 0.8903\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2819 - accuracy: 0.8941\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2668 - accuracy: 0.8988\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2568 - accuracy: 0.9039\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2480 - accuracy: 0.9071\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2393 - accuracy: 0.9102\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3415442705154419, 0.878000020980835]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yq1crMIZCGeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы:\n",
        "\n",
        "\n",
        "- Из рассмотренных отпимизаторов SGD, RMSprop, Adam лучшие показатели у Adam\n",
        "- увеличение числа batch не приводит к изменению точности - влияет на скорость обучения\n",
        "- увеличение эпох обучение увеличивает точность модели, но важно при этом отслеживать переобучение "
      ],
      "metadata": {
        "id": "zunfR8V2C6hS"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
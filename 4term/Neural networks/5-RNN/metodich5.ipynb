{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJiUvDz7EMdS"
      },
      "source": [
        "# Введение в искусственные нейронные сети\n",
        "# Урок 5. Рекуррентные нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcwdBFH6EMdy"
      },
      "source": [
        "Теперь давайте попробуем с помощью Keras построить LSTM нейронную сеть для оценки настроений отзвывов на IMD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eu0D2NuEMdz"
      },
      "source": [
        "Данный датасет слишком мал, чтобы преимущества LSTM проявились, однако в учебных целях он подойдет.\n",
        "\n",
        "В тренировке рекуррентных нейронных сетей важную роль играет размер batch, но еще большую роль играет выбор функций loss и optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d9bbL06EMd0",
        "outputId": "c102c033-ae20-48fc-e56d-692c75f9b544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загрузка данных...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "334/334 [==============================] - 102s 295ms/step - loss: 0.4292 - accuracy: 0.7918 - val_loss: 0.3538 - val_accuracy: 0.8436\n",
            "334/334 [==============================] - 14s 40ms/step - loss: 0.3538 - accuracy: 0.8436\n",
            "Результат при тестировании: 0.35379090905189514\n",
            "Тестовая точность: 0.8435999751091003\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "max_features = 15000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 75 # увеличьте значение для ускорения обучения\n",
        "\n",
        "print('Загрузка данных...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'тренировочные последовательности')\n",
        "print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "print('Pad последовательности (примеров в x единицу времени)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Построение модели...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='Nadam', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Процесс обучения...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1, # увеличьте при необходимости\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Результат при тестировании:', score)\n",
        "print('Тестовая точность:', acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGmfwueFGajO"
      },
      "source": [
        "1. Модель показывает наилучшие результаты если использовать оптимайзер \"Nadam\". Качество модели снижается обратно пропорционально увеличению количества эпох.\n",
        "В текущей реализации модели изменение других параметров не оказывает значимого влияния на качество модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTgLemMWEMd6"
      },
      "source": [
        "Давайте также посмотрим пример в которм будет использоваться другой класс задач - генерация текста на основе тренировочного текста. В задачу нейросети будет входить обучившись на тексте Алиса в стране чудес и начать генерировать текст похожий на тот, что можно встретить в этой книге. Также в этом примере будет использоваться GRU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXGIAKvqIwkt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# построчное чтение из примера с текстом \n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkaVPjxmz4ao"
      },
      "outputs": [],
      "source": [
        "with open(\"pg1661.txt\", 'rb') as _in:\n",
        "    lines = []\n",
        "    for line in _in:\n",
        "        line = line.strip().lower().decode(\"utf-8\", \"ignore\")\n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "        lines.append(line)\n",
        "text = \" \".join(lines)\n",
        "chars = set([c for c in text])\n",
        "nb_chars = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYuTLuwNEMd7"
      },
      "outputs": [],
      "source": [
        "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
        "# ID and a specific character. The numerical ID will correspond to a column\n",
        "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
        "# число при использовании one-hot кодировки для представление входов символов\n",
        "char2index = {c: i for i, c in enumerate(chars)}\n",
        "index2char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# для удобства выберете фиксированную длину последовательность 10 символов \n",
        "SEQLEN, STEP = 120, 2\n",
        "input_chars, label_chars = [], []\n",
        "\n",
        "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
        "for i in range(0, len(text) - SEQLEN, STEP):\n",
        "    input_chars.append(text[i: i + SEQLEN])\n",
        "    label_chars.append(text[i + SEQLEN])\n",
        "\n",
        "\n",
        "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
        "\n",
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "for i, input_char in enumerate(input_chars):\n",
        "    for j, ch in enumerate(input_char):\n",
        "        X[i, j, char2index[ch]] = 1\n",
        "    y[i, char2index[label_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
        "BATCH_SIZE, HIDDEN_SIZE = 64, 256\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 20\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "\n",
        "# Create a super simple recurrent neural network. There is one recurrent\n",
        "# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n",
        "# encoded input layer. This is followed by a Dense fully-connected layer\n",
        "# across the set of possible next characters, which is converted to a\n",
        "# probability score via a standard softmax activation with a multi-class\n",
        "# cross-entropy loss function linking the prediction to the one-hot\n",
        "# encoding character label.\n",
        "\n",
        "'''\n",
        "Создание очень простой рекуррентной нейронной сети. В ней будет один реккурентный \n",
        "закодированный входной слой. За ним последует полносвязный слой связанный с набором возможных \n",
        "следующих символов, которые конвертированы в вероятностные результаты через стандартную softmax активацию \n",
        "с multi-class cross-encoding loss функцию ссылающуются на предсказание one-hot encoding лейбл символа\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
        "        HIDDEN_SIZE,\n",
        "        return_sequences=False,\n",
        "        input_shape=(SEQLEN, nb_chars),\n",
        "        unroll=True\n",
        "    )\n",
        ")\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "\n",
        "# выполнение серий тренировочных и демонстрационных итераций \n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "\n",
        "    # для каждой итерации запуск передачи данных в модель \n",
        "    print(\"=\" * 50)\n",
        "    print(\"Итерация #: %d\" % (iteration))\n",
        "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "    # Select a random example input sequence.\n",
        "    test_idx = np.random.randint(len(input_chars))\n",
        "    test_chars = input_chars[test_idx]\n",
        "\n",
        "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
        "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
        "    print(\"Генерация из посева: %s\" % (test_chars))\n",
        "    print(test_chars, end=\"\")\n",
        "    for i in range(NUM_PREDS_PER_EPOCH):\n",
        "\n",
        "        # здесь one-hot encoding.\n",
        "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
        "        for j, ch in enumerate(test_chars):\n",
        "            X_test[0, j, char2index[ch]] = 1\n",
        "\n",
        "        # осуществление предсказания с помощью текущей модели.\n",
        "        pred = model.predict(X_test, verbose=0)[0]\n",
        "        y_pred = index2char[np.argmax(pred)]\n",
        "\n",
        "        # вывод предсказания добавленного к тестовому примеру \n",
        "        print(y_pred, end=\"\")\n",
        "\n",
        "        # инкрементация тестового примера содержащего предсказание\n",
        "        test_chars = test_chars[1:] + y_pred\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6W0GHOxrU_k"
      },
      "outputs": [],
      "source": [
        "# Модель генерирует более осмысленный текст при увеличении количества эпох и итераций, а так же при увеличении количества нейронов в скрытом слое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcJKO5sKEMeA"
      },
      "source": [
        "## Практическое задание\n",
        "\n",
        "<ol>\n",
        "    <li>Попробуйте изменить параметры нейронной сети работающей с датасетом imdb либо нейронной сети работающей airline-passengers(она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить ее точность. Приложите анализ.</li>\n",
        "    <li>Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения.</li>\n",
        "    <li>* Попробуйте на numpy реализовать нейронную сеть архитектуры LSTM</li>\n",
        "    <li>* Предложите свои варианты решения проблемы исчезающего градиента в RNN</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyPcVErxgwAu",
        "outputId": "dc362a5a-d899-48bb-c753-36d6321871f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Загрузка данных...\n",
            "25000 тренировочные последовательности\n",
            "25000 тестовые последовательности\n",
            "Pad последовательности (примеров в x единицу времени)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Построение модели...\n",
            "Процесс обучения...\n",
            "334/334 [==============================] - 90s 261ms/step - loss: 0.4329 - accuracy: 0.7910 - val_loss: 0.3619 - val_accuracy: 0.8397\n",
            "334/334 [==============================] - 12s 37ms/step - loss: 0.3619 - accuracy: 0.8397\n",
            "Результат при тестировании: 0.3618793487548828\n",
            "Тестовая точность: 0.839680016040802\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "max_features = 15000\n",
        "\n",
        "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
        "maxlen = 80\n",
        "batch_size = 75 # увеличьте значение для ускорения обучения\n",
        "def train_nn():\n",
        "  print('Загрузка данных...')\n",
        "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "  print(len(x_train), 'тренировочные последовательности')\n",
        "  print(len(x_test), 'тестовые последовательности')\n",
        "\n",
        "  print('Pad последовательности (примеров в x единицу времени)')\n",
        "  x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "  x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:', x_test.shape)\n",
        "\n",
        "  print('Построение модели...')\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, 128))\n",
        "  model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='Nadam', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  print('Процесс обучения...')\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=1, # увеличьте при необходимости\n",
        "            validation_data=(x_test, y_test))\n",
        "  score, acc = model.evaluate(x_test, y_test,\n",
        "                              batch_size=batch_size)\n",
        "  print('Результат при тестировании:', score)\n",
        "  print('Тестовая точность:', acc)\n",
        "train_nn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY2WJFPxjHRj"
      },
      "source": [
        "0) Базовая модель\n",
        "Результат при тестировании: 0.366113543510437\n",
        "Тестовая точность: 0.8388000130653381\n",
        "\n",
        "1)\n",
        "max_features = 20000\n",
        "Результат при тестировании: 0.3566175699234009\n",
        "Тестовая точность: 0.8389999866485596\n",
        "\n",
        "2)\n",
        "optimizer='Adam'\n",
        "Результат при тестировании: 0.35511690378189087\n",
        "Тестовая точность: 0.8424000144004822\n",
        "\n",
        "4)\n",
        "maxlen = 70\n",
        "Результат при тестировании: 0.36260467767715454\n",
        "Тестовая точность: 0.8402000069618225\n",
        "\n",
        "5)\n",
        "maxlen = 90\n",
        "Результат при тестировании: 0.3413623571395874\n",
        "Тестовая точность: 0.8503199815750122\n",
        "\n",
        "6)\n",
        "batch_size = 60\n",
        "Результат при тестировании: 0.3505716919898987\n",
        "Тестовая точность: 0.8442000150680542\n",
        "\n",
        "7)\n",
        "max_features = 12500\n",
        "Результат при тестировании: 0.36554190516471863\n",
        "Тестовая точность: 0.8426799774169922\n",
        "\n",
        "8)\n",
        "epochs = 3\n",
        "Результат при тестировании: 0.43193426728248596\n",
        "Тестовая точность: 0.8325200080871582\n",
        "\n",
        "9)\n",
        "model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
        "Результат при тестировании: 0.3988613188266754\n",
        "Тестовая точность: 0.8286799788475037\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
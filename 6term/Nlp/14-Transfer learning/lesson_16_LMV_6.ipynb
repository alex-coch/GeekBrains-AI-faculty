{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dialogflow gensim==3.6.0 annoy tqdm stop_words pymorphy2 python-telegram-bot==13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_1.jpg' width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_2.jpg' width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_3.jpg' width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.   RESTART KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xAhRcgdAVJzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "    \n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать файл Otvety.txt по ссылке\n",
    "# https://drive.google.com/file/d/1DQL9ybca4USImUDaxxHmkIZNmClKBtKG/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JBnSQav-VJz6"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('prepared_answers.txt'):\n",
    "\n",
    "    question = None\n",
    "    written = False\n",
    "\n",
    "    with open(\"prepared_answers.txt\", \"w\") as fout:  \n",
    "        with open(\"Otvety.txt\", \"r\") as fin:\n",
    "            for line in tqdm_notebook(fin):\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qNovia_FVJz7"
   },
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f32db27df42f4863a58d2d9996f088e3"
     ]
    },
    "id": "uvwpdubYVJz8",
    "outputId": "83dd0de8-4106-4dbc-c584-61c1a23cb9bd"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "file_path_from = 'Otvety.txt'\n",
    "file_path_to = 'Otvety2.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "    \n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w') as fileto:\n",
    "        with open(file_path_from) as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences.append(spls)\n",
    "                c += 1\n",
    "                if c > 500000000:\n",
    "                    break\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb5ebf93bcb4571bfa6d57897dd8b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7016256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "file_path_from = 'Otvety2.txt'\n",
    "if os.path.isfile(file_path_from):  \n",
    "    N = get_num_lines(file_path_from) \n",
    "    with open(file_path_to, mode = 'r') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences.append(line.split())\n",
    "    filefrom.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '15',\n",
       " '1700',\n",
       " '2',\n",
       " '20',\n",
       " '2048х1546',\n",
       " '300вт',\n",
       " '34',\n",
       " '3g',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '500',\n",
       " '6',\n",
       " '67',\n",
       " '6последний',\n",
       " '70',\n",
       " '800',\n",
       " 'acronis',\n",
       " 'br',\n",
       " 'brconvert',\n",
       " 'brps',\n",
       " 'brв',\n",
       " 'brвампир',\n",
       " 'brвитание',\n",
       " 'brвсе',\n",
       " 'brгде',\n",
       " 'brдикобраз',\n",
       " 'brести',\n",
       " 'brзабористый',\n",
       " 'brзамыкание',\n",
       " 'brзеркало',\n",
       " 'brзнать',\n",
       " 'brи',\n",
       " 'brкаждый',\n",
       " 'brм',\n",
       " 'brмоя',\n",
       " 'brобщениеить',\n",
       " 'brпереть',\n",
       " 'brпо',\n",
       " 'brподкормка',\n",
       " 'brприветик',\n",
       " 'brсорт',\n",
       " 'brсуществовать',\n",
       " 'brтеперь',\n",
       " 'brтожий',\n",
       " 'brэтота',\n",
       " 'c',\n",
       " 'cmd',\n",
       " 'dos',\n",
       " 'dove',\n",
       " 'everest',\n",
       " 'fat16',\n",
       " 'fat32',\n",
       " 'fdisk',\n",
       " 'fsntfs',\n",
       " 'hd',\n",
       " 'ipad',\n",
       " 'ipad2',\n",
       " 'ipad3',\n",
       " 'lte',\n",
       " 'magic',\n",
       " 'ntfs',\n",
       " 'paragon',\n",
       " 'partition',\n",
       " 'speedfan',\n",
       " 'susanbr',\n",
       " 'x',\n",
       " 'автомобиль',\n",
       " 'адекватный',\n",
       " 'айпад',\n",
       " 'академия',\n",
       " 'акронис',\n",
       " 'алгоритм',\n",
       " 'анализ',\n",
       " 'анемия',\n",
       " 'аренда',\n",
       " 'бабушка',\n",
       " 'бандит',\n",
       " 'барьер',\n",
       " 'бежать',\n",
       " 'белка',\n",
       " 'белый',\n",
       " 'беременная',\n",
       " 'беременность',\n",
       " 'беречь',\n",
       " 'бессознательный',\n",
       " 'биополе',\n",
       " 'биоэнергия',\n",
       " 'благодаря',\n",
       " 'благотворительность',\n",
       " 'близкий',\n",
       " 'блок',\n",
       " 'бог',\n",
       " 'боль',\n",
       " 'больший',\n",
       " 'большой',\n",
       " 'борьба',\n",
       " 'бош',\n",
       " 'брать',\n",
       " 'буква',\n",
       " 'бушевать',\n",
       " 'бываютмочь',\n",
       " 'быстро',\n",
       " 'вампир',\n",
       " 'ванна',\n",
       " 'ванная',\n",
       " 'варение',\n",
       " 'вариант',\n",
       " 'везти',\n",
       " 'версия',\n",
       " 'весить',\n",
       " 'весна',\n",
       " 'вести',\n",
       " 'взбить',\n",
       " 'взять',\n",
       " 'вид',\n",
       " 'видео',\n",
       " 'видеть',\n",
       " 'видимо',\n",
       " 'вирус',\n",
       " 'витамин',\n",
       " 'витаминовный',\n",
       " 'вкусностейд',\n",
       " 'влажный',\n",
       " 'вместе',\n",
       " 'вместеоформление',\n",
       " 'внимание',\n",
       " 'внук',\n",
       " 'внутрь',\n",
       " 'вобщий',\n",
       " 'вода',\n",
       " 'возможно',\n",
       " 'возможность',\n",
       " 'волк',\n",
       " 'волос',\n",
       " 'вообще',\n",
       " 'вопрос',\n",
       " 'восполнить',\n",
       " 'воспринимать',\n",
       " 'вправду',\n",
       " 'врач',\n",
       " 'вред',\n",
       " 'вроде',\n",
       " 'вряд',\n",
       " 'вспомогательный',\n",
       " 'вставить',\n",
       " 'встреча',\n",
       " 'встречать',\n",
       " 'всякий',\n",
       " 'выбирать',\n",
       " 'выбор',\n",
       " 'вывод',\n",
       " 'выглядеть',\n",
       " 'выгодный',\n",
       " 'вызывать',\n",
       " 'выпадать',\n",
       " 'выпадение',\n",
       " 'выполнить',\n",
       " 'выпускать',\n",
       " 'выращивание',\n",
       " 'выращивать',\n",
       " 'выращиваться',\n",
       " 'высаживать',\n",
       " 'высосать',\n",
       " 'высунуть',\n",
       " 'вытянуть',\n",
       " 'выше',\n",
       " 'гинекологомэндокринолог',\n",
       " 'глаз',\n",
       " 'глициния',\n",
       " 'говорить',\n",
       " 'голова',\n",
       " 'голубой',\n",
       " 'гормон',\n",
       " 'гормональный',\n",
       " 'графика',\n",
       " 'гриб',\n",
       " 'грунт',\n",
       " 'густой',\n",
       " 'дабы',\n",
       " 'данные',\n",
       " 'данный',\n",
       " 'даный',\n",
       " 'датрагивац',\n",
       " 'датчик',\n",
       " 'дать',\n",
       " 'дв',\n",
       " 'двенашка',\n",
       " 'двигатель',\n",
       " 'двоеточие',\n",
       " 'девушка',\n",
       " 'действие',\n",
       " 'декретемочь',\n",
       " 'делать',\n",
       " 'деликатный',\n",
       " 'дело',\n",
       " 'демонстрировать',\n",
       " 'деньга',\n",
       " 'дерево',\n",
       " 'держать',\n",
       " 'директор',\n",
       " 'дисбаланс',\n",
       " 'диск',\n",
       " 'дисплей',\n",
       " 'длина',\n",
       " 'добрый',\n",
       " 'доверять',\n",
       " 'довольный',\n",
       " 'договориться',\n",
       " 'доктор',\n",
       " 'документ',\n",
       " 'должный',\n",
       " 'дом',\n",
       " 'домашний',\n",
       " 'домой',\n",
       " 'доработать',\n",
       " 'дорогой',\n",
       " 'дос',\n",
       " 'достать',\n",
       " 'др',\n",
       " 'драйвер',\n",
       " 'друг',\n",
       " 'думать',\n",
       " 'дурак',\n",
       " 'дурацкий',\n",
       " 'духовный',\n",
       " 'ждать',\n",
       " 'желатина',\n",
       " 'желе',\n",
       " 'железо',\n",
       " 'железосодержащий',\n",
       " 'желтковый',\n",
       " 'желток',\n",
       " 'жертва',\n",
       " 'животное',\n",
       " 'жёсткий',\n",
       " 'забавно',\n",
       " 'забывать',\n",
       " 'завести',\n",
       " 'зависеть',\n",
       " 'завод',\n",
       " 'заводbr',\n",
       " 'загрузочный',\n",
       " 'заключаться',\n",
       " 'закрасться',\n",
       " 'закрыть',\n",
       " 'замыкаться',\n",
       " 'заниматься',\n",
       " 'запись',\n",
       " 'зарабатывать',\n",
       " 'заставлять',\n",
       " 'зачастую',\n",
       " 'защита',\n",
       " 'защититься',\n",
       " 'заявить',\n",
       " 'здоровый',\n",
       " 'зелёный',\n",
       " 'зеркальный',\n",
       " 'зима',\n",
       " 'зимовать',\n",
       " 'знакомый',\n",
       " 'знать',\n",
       " 'игла',\n",
       " 'идти',\n",
       " 'измерение',\n",
       " 'иммунитет',\n",
       " 'иначе',\n",
       " 'интересный',\n",
       " 'интересовать',\n",
       " 'интернет',\n",
       " 'информация',\n",
       " 'искать',\n",
       " 'исполнительный',\n",
       " 'итэлма',\n",
       " 'итэлмавыпускать',\n",
       " 'йопарить',\n",
       " 'каво',\n",
       " 'кагбэ',\n",
       " 'кадочный',\n",
       " 'кадровик',\n",
       " 'какимтый',\n",
       " 'каков',\n",
       " 'кальций',\n",
       " 'камера',\n",
       " 'качать',\n",
       " 'квартира',\n",
       " 'кератин',\n",
       " 'кисломолочный',\n",
       " 'китайцский',\n",
       " 'кличка',\n",
       " 'клок',\n",
       " 'клятва',\n",
       " 'книга',\n",
       " 'кожа',\n",
       " 'колдовство',\n",
       " 'кольцо',\n",
       " 'команда',\n",
       " 'командировка',\n",
       " 'командировочный',\n",
       " 'комп',\n",
       " 'комплекс',\n",
       " 'комплект',\n",
       " 'компьютер',\n",
       " 'конвертировать',\n",
       " 'конкретный',\n",
       " 'консистенция',\n",
       " 'контроллер',\n",
       " 'контур',\n",
       " 'конь',\n",
       " 'корневой',\n",
       " 'кот',\n",
       " 'котом•♦',\n",
       " 'котрый',\n",
       " 'кошка',\n",
       " 'крапива',\n",
       " 'кратец',\n",
       " 'крепость',\n",
       " 'кровный',\n",
       " 'кровь',\n",
       " 'крокодил',\n",
       " 'крупный',\n",
       " 'ксожаление',\n",
       " 'кстати',\n",
       " 'купить',\n",
       " 'курага',\n",
       " 'курить',\n",
       " 'курс',\n",
       " 'кушать',\n",
       " 'ледяной',\n",
       " 'лежать',\n",
       " 'лететь',\n",
       " 'лето',\n",
       " 'лечение',\n",
       " 'линза',\n",
       " 'лично',\n",
       " 'луковый',\n",
       " 'любить',\n",
       " 'любовник',\n",
       " 'маг',\n",
       " 'магнолия',\n",
       " 'мазать',\n",
       " 'майонез',\n",
       " 'малыш',\n",
       " 'мама',\n",
       " 'мамочка',\n",
       " 'маска',\n",
       " 'масло',\n",
       " 'мастер',\n",
       " 'масяня',\n",
       " 'материнский',\n",
       " 'мбитс',\n",
       " 'менша',\n",
       " 'местечко',\n",
       " 'месяц',\n",
       " 'метод',\n",
       " 'микроэлемент',\n",
       " 'милиция',\n",
       " 'миллион',\n",
       " 'минута',\n",
       " 'молодёжь',\n",
       " 'молочный',\n",
       " 'момент',\n",
       " 'мощный',\n",
       " 'мощьнея',\n",
       " 'мпкс',\n",
       " 'мудрый',\n",
       " 'муж',\n",
       " 'мужик',\n",
       " 'мысленно',\n",
       " 'мысль',\n",
       " 'мыть',\n",
       " 'навредить',\n",
       " 'надёжно',\n",
       " 'нажраться',\n",
       " 'название',\n",
       " 'назначить',\n",
       " 'называться',\n",
       " 'найти',\n",
       " 'налепить',\n",
       " 'налечь',\n",
       " 'наложить',\n",
       " 'наносить',\n",
       " 'наоборот',\n",
       " 'наполнить',\n",
       " 'например',\n",
       " 'нарастить',\n",
       " 'нарваться',\n",
       " 'народный',\n",
       " 'наружу',\n",
       " 'нарушение',\n",
       " 'настоящий',\n",
       " 'насчёт',\n",
       " 'натуральный',\n",
       " 'научно',\n",
       " 'находиться',\n",
       " 'находка',\n",
       " 'начинаться',\n",
       " 'небо',\n",
       " 'негатив',\n",
       " 'незаметно',\n",
       " 'незнать',\n",
       " 'незначительный',\n",
       " 'немецкий',\n",
       " 'необходимо',\n",
       " 'неприменный',\n",
       " 'неприятность',\n",
       " 'неприятный',\n",
       " 'нервный',\n",
       " 'нести',\n",
       " 'нетглавное',\n",
       " 'нидавать',\n",
       " 'нижеа',\n",
       " 'никак',\n",
       " 'никакой',\n",
       " 'никто',\n",
       " 'ничто',\n",
       " 'новый',\n",
       " 'нога',\n",
       " 'ноль',\n",
       " 'нормально',\n",
       " 'носить',\n",
       " 'нравиться',\n",
       " 'нужный',\n",
       " 'облако',\n",
       " 'оболочка',\n",
       " 'обрабатывать',\n",
       " 'образ',\n",
       " 'образовать',\n",
       " 'обратить',\n",
       " 'обратиться',\n",
       " 'общение',\n",
       " 'объяснять',\n",
       " 'овощ',\n",
       " 'одолжить',\n",
       " 'окова',\n",
       " 'окружающий',\n",
       " 'окружение',\n",
       " 'олег',\n",
       " 'олегаbrbrшо',\n",
       " 'опасность',\n",
       " 'опасный',\n",
       " 'организм',\n",
       " 'особенность',\n",
       " 'особо',\n",
       " 'особый',\n",
       " 'оставлять',\n",
       " 'остальной',\n",
       " 'остановить',\n",
       " 'остаться',\n",
       " 'отвар',\n",
       " 'ответ',\n",
       " 'ответилачтый',\n",
       " 'отдавать',\n",
       " 'отдать',\n",
       " 'отделение',\n",
       " 'отделить',\n",
       " 'отдельный',\n",
       " 'отдохнуть',\n",
       " 'отдыхать',\n",
       " 'открытый',\n",
       " 'отличие',\n",
       " 'отметить',\n",
       " 'отнести',\n",
       " 'относиться',\n",
       " 'отношение',\n",
       " 'отправляться',\n",
       " 'отражать',\n",
       " 'отрицательный',\n",
       " 'отстать',\n",
       " 'отталкиваться',\n",
       " 'отформатировать',\n",
       " 'охотник',\n",
       " 'очередь',\n",
       " 'ошибка',\n",
       " 'ощущать',\n",
       " 'ощущение',\n",
       " 'п',\n",
       " 'палец',\n",
       " 'памытьbr',\n",
       " 'память',\n",
       " 'параллельно',\n",
       " 'парень',\n",
       " 'парикмахер',\n",
       " 'парикмахерский',\n",
       " 'паучок',\n",
       " 'перестать',\n",
       " 'перестройка',\n",
       " 'печень',\n",
       " 'пиар',\n",
       " 'пила',\n",
       " 'писать',\n",
       " 'питание',\n",
       " 'питаться',\n",
       " 'плата',\n",
       " 'плечо',\n",
       " 'плохой',\n",
       " 'поверхность',\n",
       " 'поверьте',\n",
       " 'поговорить',\n",
       " 'поговорка',\n",
       " 'погреб',\n",
       " 'подавиться',\n",
       " 'подарок',\n",
       " 'поделиться',\n",
       " 'поднимать',\n",
       " 'подобный',\n",
       " 'подозрение',\n",
       " 'подорожник',\n",
       " 'подсказать',\n",
       " 'подсолнечный',\n",
       " 'подходить',\n",
       " 'позвонить',\n",
       " 'пойти',\n",
       " 'показывать',\n",
       " 'покрывать',\n",
       " 'покупать',\n",
       " 'покупка',\n",
       " 'пол',\n",
       " 'поле',\n",
       " 'полезный',\n",
       " 'полиция',\n",
       " 'положение',\n",
       " 'полоса',\n",
       " 'полоскать',\n",
       " 'полотенце',\n",
       " 'получать',\n",
       " 'получить',\n",
       " 'польза',\n",
       " 'помешать',\n",
       " 'помещение',\n",
       " 'помогалопот',\n",
       " 'помогоать',\n",
       " 'помолчать',\n",
       " 'помочий',\n",
       " 'помочь',\n",
       " 'помощь',\n",
       " 'понравиться',\n",
       " 'понт',\n",
       " 'пообщаться',\n",
       " 'попадаться',\n",
       " 'попить',\n",
       " 'попробовать',\n",
       " 'порядок',\n",
       " 'посмотреть',\n",
       " 'посоветовать',\n",
       " 'поспать',\n",
       " 'поставить',\n",
       " 'посторонний',\n",
       " 'постричь',\n",
       " 'поцелуй',\n",
       " 'почва',\n",
       " 'почувствовать',\n",
       " 'правило',\n",
       " 'пребывать',\n",
       " 'предприятие',\n",
       " 'представить',\n",
       " 'прежде',\n",
       " 'препарат',\n",
       " 'привести',\n",
       " 'привлекать',\n",
       " 'пригласить',\n",
       " 'приготовление',\n",
       " 'призрак',\n",
       " 'прийти',\n",
       " 'приказ',\n",
       " 'прикалывать',\n",
       " 'прикольно',\n",
       " 'прикосновение',\n",
       " 'прикреплять',\n",
       " 'прилагаться',\n",
       " 'применять',\n",
       " 'принимать',\n",
       " 'присутствие',\n",
       " 'причина',\n",
       " 'приятный',\n",
       " 'приём',\n",
       " 'пробегать',\n",
       " 'пробел',\n",
       " 'пробиться',\n",
       " 'проблема',\n",
       " 'пробоина',\n",
       " 'прога',\n",
       " 'программа',\n",
       " 'продолжить',\n",
       " 'продукция',\n",
       " 'производственный',\n",
       " 'проконсультироваться',\n",
       " 'пропил',\n",
       " 'простой',\n",
       " 'профессионал',\n",
       " 'прохладный',\n",
       " 'процессор',\n",
       " 'прочитать',\n",
       " 'прошлау',\n",
       " 'прямо',\n",
       " 'прятаться',\n",
       " 'пуск',\n",
       " 'пускай',\n",
       " 'пусть',\n",
       " 'пьяный',\n",
       " 'пёс',\n",
       " 'работа',\n",
       " 'работать',\n",
       " 'равно',\n",
       " 'развести',\n",
       " 'разговаривать',\n",
       " 'разгонять',\n",
       " 'размер',\n",
       " 'разный',\n",
       " 'разрешение',\n",
       " 'рак',\n",
       " 'распространяться',\n",
       " 'растение',\n",
       " 'растеряться',\n",
       " 'растить',\n",
       " 'расчёска',\n",
       " 'ребёнок',\n",
       " 'ребёночек',\n",
       " 'регион',\n",
       " 'редкость',\n",
       " 'резкий',\n",
       " 'результатомситуация',\n",
       " 'рекомендовать',\n",
       " 'репейный',\n",
       " 'ровно',\n",
       " 'родаммочь',\n",
       " 'роды',\n",
       " 'роза',\n",
       " 'розличий',\n",
       " 'розовый',\n",
       " 'ромашка',\n",
       " 'россия',\n",
       " 'рубль',\n",
       " 'рука',\n",
       " 'русь',\n",
       " 'рутина',\n",
       " 'сад',\n",
       " 'сайт',\n",
       " 'салат',\n",
       " 'салон',\n",
       " 'самолечение',\n",
       " 'самый',\n",
       " 'свалиться',\n",
       " 'сватать',\n",
       " 'свободнейможный',\n",
       " 'свой',\n",
       " 'связь',\n",
       " 'свёкла',\n",
       " 'сделать',\n",
       " 'себябез',\n",
       " 'сера',\n",
       " 'серый',\n",
       " 'серьёзно',\n",
       " 'сила',\n",
       " 'силиконовый',\n",
       " 'синеголубой',\n",
       " 'синтетический',\n",
       " 'система',\n",
       " 'сиська',\n",
       " 'сися',\n",
       " 'ситуация',\n",
       " 'скачать',\n",
       " 'скорее',\n",
       " 'скорость',\n",
       " 'скрещивание',\n",
       " 'слава',\n",
       " 'следовать',\n",
       " 'следующий',\n",
       " 'слеш',\n",
       " 'слух',\n",
       " 'случай',\n",
       " 'смазывать',\n",
       " 'смело',\n",
       " 'сменить',\n",
       " 'смородиновый',\n",
       " 'смотреть',\n",
       " 'смочь',\n",
       " 'смыть',\n",
       " 'снаружи',\n",
       " 'собачка',\n",
       " 'собеседник',\n",
       " 'соблюдать',\n",
       " 'собрать',\n",
       " 'собственный',\n",
       " 'совершить',\n",
       " 'совет',\n",
       " 'советовать',\n",
       " 'содержание',\n",
       " 'содержаться',\n",
       " 'соединить',\n",
       " 'сон',\n",
       " 'сорт',\n",
       " 'состояние',\n",
       " 'сохранный',\n",
       " 'специалист',\n",
       " 'сплошной',\n",
       " 'спокойно',\n",
       " 'способ',\n",
       " 'способпрекратить',\n",
       " 'спрос',\n",
       " 'спросить',\n",
       " 'спрячь',\n",
       " 'спугнуть',\n",
       " 'средний',\n",
       " 'средство',\n",
       " 'ставить',\n",
       " 'стандарт',\n",
       " 'стать',\n",
       " 'стена',\n",
       " 'сто',\n",
       " 'стоить',\n",
       " 'столкнуться',\n",
       " 'страшный',\n",
       " 'сумасшедший',\n",
       " 'сумма',\n",
       " 'супер',\n",
       " 'существенный',\n",
       " 'существовать',\n",
       " 'счастие',\n",
       " 'счётчик',\n",
       " 'съесть',\n",
       " 'сыпалисьный',\n",
       " 'сыпаться',\n",
       " 'таг',\n",
       " 'тдв',\n",
       " 'тема',\n",
       " 'температура',\n",
       " 'тероть',\n",
       " 'технология',\n",
       " 'тип',\n",
       " 'тк',\n",
       " 'толпа',\n",
       " 'толща',\n",
       " 'трезвый',\n",
       " 'трезвыйвывозить',\n",
       " 'трихолог',\n",
       " 'тщательно',\n",
       " 'тьма',\n",
       " 'тя',\n",
       " 'тяжесть',\n",
       " 'тёплый',\n",
       " 'убедиться',\n",
       " 'угодный',\n",
       " 'удача',\n",
       " 'удивляться',\n",
       " 'удобный',\n",
       " 'удовлетворить',\n",
       " 'удоствоверение',\n",
       " 'удручающий',\n",
       " 'ужасно',\n",
       " 'узнать',\n",
       " 'указательный',\n",
       " 'указывать',\n",
       " 'укрывать',\n",
       " 'укрытие',\n",
       " 'укус',\n",
       " 'улица',\n",
       " 'улучшить',\n",
       " 'упорство',\n",
       " 'управление',\n",
       " 'усваиваться',\n",
       " 'услуга',\n",
       " 'установить',\n",
       " 'устраивать',\n",
       " 'устройство',\n",
       " 'уход',\n",
       " 'учиться',\n",
       " 'файловый',\n",
       " 'фальшивка',\n",
       " 'формат',\n",
       " 'форматировать',\n",
       " 'фото',\n",
       " 'фрося',\n",
       " 'фрукт',\n",
       " 'хабаровск',\n",
       " 'хватаеттак',\n",
       " 'хватаетхотя',\n",
       " 'хватать',\n",
       " 'химия',\n",
       " 'хищник',\n",
       " 'ходить',\n",
       " 'холодец',\n",
       " 'холодильник',\n",
       " 'хомячок',\n",
       " 'хороший',\n",
       " 'хотяб',\n",
       " 'хр',\n",
       " 'хранение',\n",
       " 'хранить',\n",
       " 'храниться',\n",
       " 'хрящик',\n",
       " 'хурма',\n",
       " 'цвести',\n",
       " 'цветной',\n",
       " 'цена',\n",
       " 'часть',\n",
       " 'чашечка',\n",
       " 'чепчикеbrонить',\n",
       " 'черенок',\n",
       " 'четырехядерный',\n",
       " 'чутьчуть',\n",
       " 'шампунь',\n",
       " 'шанс',\n",
       " 'шип',\n",
       " 'шок',\n",
       " 'шумиха',\n",
       " 'эбу',\n",
       " 'экран',\n",
       " 'электроника',\n",
       " 'электронный',\n",
       " 'эмоция',\n",
       " 'эндокринолог',\n",
       " 'энергетический',\n",
       " 'энергия',\n",
       " 'этобыть',\n",
       " 'эффективно',\n",
       " 'эффективный',\n",
       " 'яблоко',\n",
       " 'ягода',\n",
       " 'язык',\n",
       " 'яйцо',\n",
       " 'якобы',\n",
       " 'январь',\n",
       " '—',\n",
       " '♦•давно']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = []\n",
    "_ = [vec.extend(x)  for x in sentences[:100]]\n",
    "vec = list(set(vec))\n",
    "vec.sort()\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'] = value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['вопрос', 'тдв', 'отдыхать', 'лично', 'советовать', 'завести'],\n",
       " ['хомячок'],\n",
       " ['мужик', 'йопарить', 'собачка', '50', 'кошка'],\n",
       " ['общение'],\n",
       " ['паучок'],\n",
       " ['пол', 'памытьbr', 'таг', 'тип', 'каво'],\n",
       " ['вообще', 'пообщаться'],\n",
       " ['советовать', 'сися', 'завести']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = sentences[:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zwXvXkJBVJ0B"
   },
   "outputs": [],
   "source": [
    "# Обучим модель FastText\n",
    "\n",
    "file_path_from = 'ft_model'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    sentences = [i for i in tqdm(sentences) if len(i) > 2]\n",
    "    modelFT = FastText(sentences=sentences, size=100, min_count=1, window=5)\n",
    "    modelFT.save(\"ft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(\"ft_model\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Размерность вектора модели. Если установить 100 — каждое слово в корпусе будет представлено в виде 100-мерного вектора, и т.п.\n",
    "#Наименьшее допустимое количество символов в слове, для которого будет создаваться векторное представление; так можно убрать частотные, но не очень значимые слова типа союзов и предлогов.\n",
    "#Размер окна. Этот параметр задает, сколько соседних слов считается частью контекста. Если выставить 40, то алгоритм возьмет 40 слов спереди от слова и 40 слов сзади от слова;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#просто на новой версии gensim часть с фасттекстом падала, пришлось править:\n",
    "#        for word in question:\n",
    "#            if word in modelFT.wv:\n",
    "\n",
    "#ну и в других местах тоже modelFT.wv\n",
    "#если кто в колабе будет делать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'а',\n",
       " 'алло',\n",
       " 'без',\n",
       " 'близко',\n",
       " 'более',\n",
       " 'больше',\n",
       " 'будем',\n",
       " 'будет',\n",
       " 'будете',\n",
       " 'будешь',\n",
       " 'будто',\n",
       " 'буду',\n",
       " 'будут',\n",
       " 'будь',\n",
       " 'бы',\n",
       " 'бывает',\n",
       " 'бывь',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'важная',\n",
       " 'важное',\n",
       " 'важные',\n",
       " 'важный',\n",
       " 'вам',\n",
       " 'вами',\n",
       " 'вас',\n",
       " 'ваш',\n",
       " 'ваша',\n",
       " 'ваше',\n",
       " 'ваши',\n",
       " 'вверх',\n",
       " 'вдали',\n",
       " 'вдруг',\n",
       " 'ведь',\n",
       " 'везде',\n",
       " 'весь',\n",
       " 'вниз',\n",
       " 'внизу',\n",
       " 'во',\n",
       " 'вокруг',\n",
       " 'вон',\n",
       " 'восемнадцатый',\n",
       " 'восемнадцать',\n",
       " 'восемь',\n",
       " 'восьмой',\n",
       " 'вот',\n",
       " 'впрочем',\n",
       " 'времени',\n",
       " 'время',\n",
       " 'все',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всем',\n",
       " 'всеми',\n",
       " 'всему',\n",
       " 'всех',\n",
       " 'всею',\n",
       " 'всю',\n",
       " 'всюду',\n",
       " 'вся',\n",
       " 'всё',\n",
       " 'второй',\n",
       " 'вы',\n",
       " 'г',\n",
       " 'где',\n",
       " 'говорил',\n",
       " 'говорит',\n",
       " 'год',\n",
       " 'года',\n",
       " 'году',\n",
       " 'да',\n",
       " 'давно',\n",
       " 'даже',\n",
       " 'далеко',\n",
       " 'дальше',\n",
       " 'даром',\n",
       " 'два',\n",
       " 'двадцатый',\n",
       " 'двадцать',\n",
       " 'две',\n",
       " 'двенадцатый',\n",
       " 'двенадцать',\n",
       " 'двух',\n",
       " 'девятнадцатый',\n",
       " 'девятнадцать',\n",
       " 'девятый',\n",
       " 'девять',\n",
       " 'действительно',\n",
       " 'дел',\n",
       " 'день',\n",
       " 'десятый',\n",
       " 'десять',\n",
       " 'для',\n",
       " 'до',\n",
       " 'довольно',\n",
       " 'долго',\n",
       " 'должно',\n",
       " 'другая',\n",
       " 'другие',\n",
       " 'других',\n",
       " 'друго',\n",
       " 'другое',\n",
       " 'другой',\n",
       " 'е',\n",
       " 'его',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'ещё',\n",
       " 'ею',\n",
       " 'её',\n",
       " 'ж',\n",
       " 'же',\n",
       " 'жизнь',\n",
       " 'за',\n",
       " 'занят',\n",
       " 'занята',\n",
       " 'занято',\n",
       " 'заняты',\n",
       " 'затем',\n",
       " 'зато',\n",
       " 'зачем',\n",
       " 'здесь',\n",
       " 'значит',\n",
       " 'и',\n",
       " 'из',\n",
       " 'или',\n",
       " 'им',\n",
       " 'именно',\n",
       " 'иметь',\n",
       " 'ими',\n",
       " 'имя',\n",
       " 'иногда',\n",
       " 'их',\n",
       " 'к',\n",
       " 'каждая',\n",
       " 'каждое',\n",
       " 'каждые',\n",
       " 'каждый',\n",
       " 'кажется',\n",
       " 'как',\n",
       " 'какая',\n",
       " 'какой',\n",
       " 'кем',\n",
       " 'когда',\n",
       " 'кого',\n",
       " 'ком',\n",
       " 'кому',\n",
       " 'конечно',\n",
       " 'которая',\n",
       " 'которого',\n",
       " 'которой',\n",
       " 'которые',\n",
       " 'который',\n",
       " 'которых',\n",
       " 'кроме',\n",
       " 'кругом',\n",
       " 'кто',\n",
       " 'куда',\n",
       " 'лет',\n",
       " 'ли',\n",
       " 'лишь',\n",
       " 'лучше',\n",
       " 'люди',\n",
       " 'м',\n",
       " 'мало',\n",
       " 'между',\n",
       " 'меля',\n",
       " 'менее',\n",
       " 'меньше',\n",
       " 'меня',\n",
       " 'миллионов',\n",
       " 'мимо',\n",
       " 'мира',\n",
       " 'мне',\n",
       " 'много',\n",
       " 'многочисленная',\n",
       " 'многочисленное',\n",
       " 'многочисленные',\n",
       " 'многочисленный',\n",
       " 'мной',\n",
       " 'мною',\n",
       " 'мог',\n",
       " 'могут',\n",
       " 'мож',\n",
       " 'может',\n",
       " 'можно',\n",
       " 'можхо',\n",
       " 'мои',\n",
       " 'мой',\n",
       " 'мор',\n",
       " 'мочь',\n",
       " 'моя',\n",
       " 'моё',\n",
       " 'мы',\n",
       " 'на',\n",
       " 'наверху',\n",
       " 'над',\n",
       " 'надо',\n",
       " 'назад',\n",
       " 'наиболее',\n",
       " 'наконец',\n",
       " 'нам',\n",
       " 'нами',\n",
       " 'нас',\n",
       " 'начала',\n",
       " 'наш',\n",
       " 'наша',\n",
       " 'наше',\n",
       " 'наши',\n",
       " 'не',\n",
       " 'него',\n",
       " 'недавно',\n",
       " 'недалеко',\n",
       " 'нее',\n",
       " 'ней',\n",
       " 'нельзя',\n",
       " 'нем',\n",
       " 'немного',\n",
       " 'нему',\n",
       " 'непрерывно',\n",
       " 'нередко',\n",
       " 'несколько',\n",
       " 'нет',\n",
       " 'нею',\n",
       " 'неё',\n",
       " 'ни',\n",
       " 'нибудь',\n",
       " 'ниже',\n",
       " 'низко',\n",
       " 'никогда',\n",
       " 'никуда',\n",
       " 'ними',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'но',\n",
       " 'ну',\n",
       " 'нужно',\n",
       " 'нх',\n",
       " 'о',\n",
       " 'об',\n",
       " 'оба',\n",
       " 'обычно',\n",
       " 'один',\n",
       " 'одиннадцатый',\n",
       " 'одиннадцать',\n",
       " 'однажды',\n",
       " 'однако',\n",
       " 'одного',\n",
       " 'одной',\n",
       " 'около',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'оно',\n",
       " 'опять',\n",
       " 'особенно',\n",
       " 'от',\n",
       " 'отовсюду',\n",
       " 'отсюда',\n",
       " 'очень',\n",
       " 'первый',\n",
       " 'перед',\n",
       " 'по',\n",
       " 'под',\n",
       " 'пожалуйста',\n",
       " 'позже',\n",
       " 'пока',\n",
       " 'пор',\n",
       " 'пора',\n",
       " 'после',\n",
       " 'посреди',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'почему',\n",
       " 'почти',\n",
       " 'прекрасно',\n",
       " 'при',\n",
       " 'про',\n",
       " 'просто',\n",
       " 'против',\n",
       " 'процентов',\n",
       " 'пятнадцатый',\n",
       " 'пятнадцать',\n",
       " 'пятый',\n",
       " 'пять',\n",
       " 'раз',\n",
       " 'разве',\n",
       " 'рано',\n",
       " 'раньше',\n",
       " 'рядом',\n",
       " 'с',\n",
       " 'сам',\n",
       " 'сама',\n",
       " 'сами',\n",
       " 'самим',\n",
       " 'самими',\n",
       " 'самих',\n",
       " 'само',\n",
       " 'самого',\n",
       " 'самой',\n",
       " 'самом',\n",
       " 'самому',\n",
       " 'саму',\n",
       " 'свое',\n",
       " 'своего',\n",
       " 'своей',\n",
       " 'свои',\n",
       " 'своих',\n",
       " 'свою',\n",
       " 'сеаой',\n",
       " 'себе',\n",
       " 'себя',\n",
       " 'сегодня',\n",
       " 'седьмой',\n",
       " 'сейчас',\n",
       " 'семнадцатый',\n",
       " 'семнадцать',\n",
       " 'семь',\n",
       " 'сих',\n",
       " 'сказал',\n",
       " 'сказала',\n",
       " 'сказать',\n",
       " 'сколько',\n",
       " 'слишком',\n",
       " 'сначала',\n",
       " 'снова',\n",
       " 'со',\n",
       " 'собой',\n",
       " 'собою',\n",
       " 'совсем',\n",
       " 'спасибо',\n",
       " 'стал',\n",
       " 'суть',\n",
       " 'т',\n",
       " 'та',\n",
       " 'так',\n",
       " 'такая',\n",
       " 'также',\n",
       " 'такие',\n",
       " 'такое',\n",
       " 'такой',\n",
       " 'там',\n",
       " 'твой',\n",
       " 'твоя',\n",
       " 'твоё',\n",
       " 'те',\n",
       " 'тебе',\n",
       " 'тебя',\n",
       " 'тем',\n",
       " 'теми',\n",
       " 'теперь',\n",
       " 'тех',\n",
       " 'то',\n",
       " 'тобой',\n",
       " 'тобою',\n",
       " 'тогда',\n",
       " 'того',\n",
       " 'тоже',\n",
       " 'только',\n",
       " 'том',\n",
       " 'тому',\n",
       " 'тот',\n",
       " 'тою',\n",
       " 'третий',\n",
       " 'три',\n",
       " 'тринадцатый',\n",
       " 'тринадцать',\n",
       " 'ту',\n",
       " 'туда',\n",
       " 'тут',\n",
       " 'ты',\n",
       " 'тысяч',\n",
       " 'у',\n",
       " 'уж',\n",
       " 'уже',\n",
       " 'уметь',\n",
       " 'хорошо',\n",
       " 'хотеть',\n",
       " 'хоть',\n",
       " 'хотя',\n",
       " 'хочешь',\n",
       " 'часто',\n",
       " 'чаще',\n",
       " 'чего',\n",
       " 'человек',\n",
       " 'чем',\n",
       " 'чему',\n",
       " 'через',\n",
       " 'четвертый',\n",
       " 'четыре',\n",
       " 'четырнадцатый',\n",
       " 'четырнадцать',\n",
       " 'что',\n",
       " 'чтоб',\n",
       " 'чтобы',\n",
       " 'чуть',\n",
       " 'шестнадцатый',\n",
       " 'шестнадцать',\n",
       " 'шестой',\n",
       " 'шесть',\n",
       " 'эта',\n",
       " 'эти',\n",
       " 'этим',\n",
       " 'этими',\n",
       " 'этих',\n",
       " 'это',\n",
       " 'этого',\n",
       " 'этой',\n",
       " 'этом',\n",
       " 'этому',\n",
       " 'этот',\n",
       " 'эту',\n",
       " 'я'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(get_stop_words(\"ru\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем Индексы для вопросов-ответов\n",
    "\n",
    "file_path_from = 'speaker.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    modelFT = FastText.load(\"ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "    with open(\"prepared_answers.txt\", \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"\\t\")\n",
    "            index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "            vector_ft = np.zeros(100)\n",
    "            for word in question:\n",
    "                if word in modelFT.wv:\n",
    "                    vector_ft += modelFT.wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 50_000:\n",
    "                break\n",
    "\n",
    "    ft_index.build(10)\n",
    "    ft_index.save('speaker.ann')\n",
    "    \n",
    "    with open(\"index_speaker.pkl\", \"wb\") as f:\n",
    "        pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ofHcj4W8VJ0E",
    "outputId": "f40f185c-ae76-4c53-c08f-5428d1745c7b"
   },
   "outputs": [],
   "source": [
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speaker.ann')\n",
    "index_map = pd.read_pickle(\"index_speaker.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76, 26, 39, 24, 49, 18, 95, 12, 70, 64, 86, 62, 23, 46, 11, 68, 87,\n",
       "       55, 31, 34, 22, 30, 54, 28, 20, 14, 93,  7, 67, 63, 10, 29, 80, 73,\n",
       "       83, 97, 98, 35,  9, 52,  2, 89, 40, 42, 77, 37,  8, 32, 57, 27, 13,\n",
       "       60, 61, 66, 45,  1, 56, 51, 96, 82, 94, 21, 71, 90, 79, 85, 75, 16,\n",
       "       33, 59, 81, 53, 69, 99, 44, 88,  0,  4, 41, 19, 38, 72, 58, 43,  5,\n",
       "       91, 36,  3, 78, 65, 50, 47, 15, 25, 48, 74,  6, 92, 84, 17])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "b9DvlLGVVJ0F",
    "outputId": "27a213d5-372d-428b-de89-0b1f19af8a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([20299, 40798, 29518, 12973, 14908],\n",
       " [1.2104798555374146,\n",
       "  1.215636134147644,\n",
       "  1.2166720628738403,\n",
       "  1.2169945240020752,\n",
       "  1.2171131372451782])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ft_index.get_nns_by_vector(np.random.permutation(100), 5, include_distances=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['от общественного транспорта чтоб его .. \\n',\n",
       " 'Бесплатно скачать можно здесь. <br>http://www.softportal.com/freesoftware/4741. \\n',\n",
       " 'жизнь надоела. \\n',\n",
       " 'Мне вообще ни кто не верит :))))). \\n',\n",
       " 'А мне всегда кого-то не хватает..... \\n']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_map[x] for x in a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Z-qxfw70VJ0G",
    "outputId": "d9ad78f5-5ed3-4690-e5d4-2d05ba34155c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02aa28ed1874e9d9d2a7776da1ffb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "      <td>[продать, детский, шапка, продать, шапкикажда,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "      <td>[блузка, темносиний, 42, размерсостояние, отли...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                       descrirption  \\\n",
       "0     Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1             Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2                 Брюки  Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3  Продам детские шапки  Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4                Блузка  Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2  59534826aaab284cba337e06          9.0            906   \n",
       "3  57de544096ad842e26de8027         22.0           2217   \n",
       "4  5ad4d2626c86cb168d212022          9.0            907   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "2  http://cache3.youla.io/files/images/360_360/59...   \n",
       "3  http://cache3.youla.io/files/images/360_360/57...   \n",
       "4  http://cache3.youla.io/files/images/360_360/5a...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...  \n",
       "3  [продать, детский, шапка, продать, шапкикажда,...  \n",
       "4  [блузка, темносиний, 42, размерсостояние, отли...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#. Создадим модель продуктовых данных\n",
    "\n",
    "shop_data = pd.read_csv(\"ProductsDataset.csv\")\n",
    "#shop_data = shop_data.iloc[:5000, :]\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].progress_apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rqml_x5JVJ0H"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Xfxh1xO9VJ0I"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc50595f8e274cbb8d1921b9d2342a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ff132e0c7846eeb73eba2bffd12186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "# Speaker\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in tqdm(idxs)]\n",
    "# Product\n",
    "positive_texts = [\" \".join(val) for val in tqdm(shop_data['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3ud68payVJ0J"
   },
   "outputs": [],
   "source": [
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "N_oxnOuzVJ0K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, \n",
    "                                                    stratify=labels, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tNzqfsIZVJ0K",
    "outputId": "d3173275-3a00-47e2-8243-372f61a627c5"
   },
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression().fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "q_bWwksAVJ0L",
    "outputId": "e410d691-e516-45aa-ac0e-d8ef0378cc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761279737489745"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23VbtYIiVJ0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XFgbubh7VJ0N"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yx8AkUiiVJ0N",
    "outputId": "dce321cc-2846-4c1c-a42e-c6aff189837e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.77199591271185"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_vect.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aQQG_bluVJ0O",
    "outputId": "90701b9a-a491-417a-a291-fc3209df90fb"
   },
   "outputs": [],
   "source": [
    "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152640"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['кожаный', 'накидканатуральный', 'кожа', 'отличный', 'состояние']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.155587745156026,\n",
       " 7.023960450305621,\n",
       " 10.696032786103176,\n",
       " 11.10149789421134,\n",
       " 11.10149789421134]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.values())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9ae8735faac34a36be98a6d1f1fcd62e"
     ]
    },
    "id": "JjWyFjJBVJ0P",
    "outputId": "69c1e269-b020-4542-9b84-812cc5485b08"
   },
   "outputs": [],
   "source": [
    "# Создаем Индексы для продуктовых данных\n",
    "\n",
    "file_path_from = 'shop.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    \n",
    "    ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "    index_map_shop = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in tqdm(range(len(shop_data))):\n",
    "        n_ft = 0\n",
    "        index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in shop_data.loc[i, \"text\"]:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index_shop.add_item(counter, vector_ft)\n",
    "        counter += 1\n",
    "\n",
    "    ft_index_shop.build(10)\n",
    "    ft_index_shop.save('shop.ann')\n",
    "\n",
    "    file_path_from = 'index_shop.pkl'\n",
    "    if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "        with open(\"index_shop.pkl\", \"wb\") as f:\n",
    "            pickle.dump(index_map_shop, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "ft_index_shop = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index_shop.load('shop.ann') \n",
    "\n",
    "index_map_shop = pd.read_pickle(\"index_shop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iwnz2qFTVJ0Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "47tviu39VJ0Q"
   },
   "outputs": [],
   "source": [
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "H3jf5wMsVJ0R",
    "outputId": "d6f9717b-3d10-472e-bc27-893bf19f21bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4460, 17938, 4897, 6088, 468],\n",
       " [1.20292329788208,\n",
       "  1.2040966749191284,\n",
       "  1.2047914266586304,\n",
       "  1.205664038658142,\n",
       "  1.2065114974975586])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index_shop.get_nns_by_vector(np.ones(100)*20, 5, include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание своего бота в телеграмм\n",
    "# @botfather\n",
    "# name1\n",
    "# name1_BOT\n",
    "#. ->. API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3sxuG-hVJ0S",
    "outputId": "e61e1613-8860-4e1a-814a-eda3f75bd6ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/fd42fwqn6g746zjn0s08wmxm0000gn/T/ipykernel_10879/3572922789.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  return vector_ft / n_ft\n"
     ]
    }
   ],
   "source": [
    "# заменить на свой токен\n",
    "updater = Updater(\"6128988575:AAFBzUvWwsZkMBt0zXVVjiAKQf4YwNFyaH0\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет, давай пообщаемся?')\n",
    "\n",
    "def textMessage(update, context):\n",
    "    \n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = lr.predict(vect)\n",
    "    \n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "    if distances[0] > 2.5:\n",
    "        print(distances[0])\n",
    "        context.bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "        return\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "        \n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://github.com/Koziev/NLP_Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lesson_16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

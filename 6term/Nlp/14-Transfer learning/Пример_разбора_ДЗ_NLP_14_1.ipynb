{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-07T19:07:16.311421Z",
     "iopub.status.busy": "2023-03-07T19:07:16.309718Z",
     "iopub.status.idle": "2023-03-07T19:07:16.337465Z",
     "shell.execute_reply": "2023-03-07T19:07:16.336561Z",
     "shell.execute_reply.started": "2023-03-07T19:07:16.311380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bashim-quotes/dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание:\n",
    "1. Обучить модель GPT для генерации своих цитат\n",
    "2. взять новостные данные из https://github.com/natasha/corus load_lenta2, нам понадобится сам текст и заголовок. Обучить модель T5/ или GPT для генерации заголовков для статей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек и датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:07:21.427252Z",
     "iopub.status.busy": "2023-03-07T19:07:21.426641Z",
     "iopub.status.idle": "2023-03-07T19:07:32.728180Z",
     "shell.execute_reply": "2023-03-07T19:07:32.726943Z",
     "shell.execute_reply.started": "2023-03-07T19:07:21.427215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:07:46.964902Z",
     "iopub.status.busy": "2023-03-07T19:07:46.964303Z",
     "iopub.status.idle": "2023-03-07T19:07:57.501388Z",
     "shell.execute_reply": "2023-03-07T19:07:57.500125Z",
     "shell.execute_reply.started": "2023-03-07T19:07:46.964853Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:07:57.507427Z",
     "iopub.status.busy": "2023-03-07T19:07:57.506601Z",
     "iopub.status.idle": "2023-03-07T19:07:57.517277Z",
     "shell.execute_reply": "2023-03-07T19:07:57.512217Z",
     "shell.execute_reply.started": "2023-03-07T19:07:57.507389Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bankholdup/rugpt3_song_writer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:07:57.519609Z",
     "iopub.status.busy": "2023-03-07T19:07:57.518890Z",
     "iopub.status.idle": "2023-03-07T19:07:59.024051Z",
     "shell.execute_reply": "2023-03-07T19:07:59.022962Z",
     "shell.execute_reply.started": "2023-03-07T19:07:57.519539Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rec = pd.read_json('../input/bashim-quotes/dataset.jsonl', lines=True).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:08:02.991673Z",
     "iopub.status.busy": "2023-03-07T19:08:02.990613Z",
     "iopub.status.idle": "2023-03-07T19:08:03.011086Z",
     "shell.execute_reply": "2023-03-07T19:08:03.009863Z",
     "shell.execute_reply.started": "2023-03-07T19:08:02.991616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-30 11:24:00+00:00</td>\n",
       "      <td>22010.0</td>\n",
       "      <td>&lt;Ares&gt; ppdv, все юниксы очень дружелюбны.. они...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-30 11:25:00+00:00</td>\n",
       "      <td>25105.0</td>\n",
       "      <td>&lt;томатик_рад&gt; а ты не чувствуешь красоту мира?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-30 11:27:00+00:00</td>\n",
       "      <td>7192.0</td>\n",
       "      <td>&lt;Дор&gt; \"мышка, почему у тебя такие большие глаз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-30 11:28:00+00:00</td>\n",
       "      <td>29169.0</td>\n",
       "      <td>&lt;PPDV[os2]&gt; \"Мальчики, вы что больные, бегать ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-08-30 11:26:00+00:00</td>\n",
       "      <td>7140.0</td>\n",
       "      <td>&lt;Ohtori_Akio&gt; мы - как разработчики - живём с ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date   rating  \\\n",
       "id                                      \n",
       "1  2004-08-30 11:24:00+00:00  22010.0   \n",
       "2  2004-08-30 11:25:00+00:00  25105.0   \n",
       "3  2004-08-30 11:27:00+00:00   7192.0   \n",
       "4  2004-08-30 11:28:00+00:00  29169.0   \n",
       "5  2004-08-30 11:26:00+00:00   7140.0   \n",
       "\n",
       "                                                 text  \n",
       "id                                                     \n",
       "1   <Ares> ppdv, все юниксы очень дружелюбны.. они...  \n",
       "2   <томатик_рад> а ты не чувствуешь красоту мира?...  \n",
       "3   <Дор> \"мышка, почему у тебя такие большие глаз...  \n",
       "4   <PPDV[os2]> \"Мальчики, вы что больные, бегать ...  \n",
       "5   <Ohtori_Akio> мы - как разработчики - живём с ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:08:08.291270Z",
     "iopub.status.busy": "2023-03-07T19:08:08.290161Z",
     "iopub.status.idle": "2023-03-07T19:08:08.298278Z",
     "shell.execute_reply": "2023-03-07T19:08:08.297101Z",
     "shell.execute_reply.started": "2023-03-07T19:08:08.291218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81497, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:08:08.616885Z",
     "iopub.status.busy": "2023-03-07T19:08:08.615965Z",
     "iopub.status.idle": "2023-03-07T19:08:08.648269Z",
     "shell.execute_reply": "2023-03-07T19:08:08.647277Z",
     "shell.execute_reply.started": "2023-03-07T19:08:08.616835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 81497 entries, 1 to 463648\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype              \n",
      "---  ------  --------------  -----              \n",
      " 0   date    81497 non-null  datetime64[ns, UTC]\n",
      " 1   rating  80642 non-null  float64            \n",
      " 2   text    81497 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_rec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:08:09.204774Z",
     "iopub.status.busy": "2023-03-07T19:08:09.203819Z",
     "iopub.status.idle": "2023-03-07T19:08:09.212419Z",
     "shell.execute_reply": "2023-03-07T19:08:09.211336Z",
     "shell.execute_reply.started": "2023-03-07T19:08:09.204734Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_text(text):\n",
    "    clr_text = re.sub(r\"<.*?>\", \" \", text).lower()\n",
    "    clr_text = summary = re.sub(r\"\\s\", \" \", clr_text)\n",
    "    return clr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:08:14.479676Z",
     "iopub.status.busy": "2023-03-07T19:08:14.478750Z",
     "iopub.status.idle": "2023-03-07T19:08:15.761584Z",
     "shell.execute_reply": "2023-03-07T19:08:15.760212Z",
     "shell.execute_reply.started": "2023-03-07T19:08:14.479618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-30 11:24:00+00:00</td>\n",
       "      <td>22010.0</td>\n",
       "      <td>&lt;Ares&gt; ppdv, все юниксы очень дружелюбны.. они...</td>\n",
       "      <td>ppdv, все юниксы очень дружелюбны.. они прос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-30 11:25:00+00:00</td>\n",
       "      <td>25105.0</td>\n",
       "      <td>&lt;томатик_рад&gt; а ты не чувствуешь красоту мира?...</td>\n",
       "      <td>а ты не чувствуешь красоту мира?   честно го...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-30 11:27:00+00:00</td>\n",
       "      <td>7192.0</td>\n",
       "      <td>&lt;Дор&gt; \"мышка, почему у тебя такие большие глаз...</td>\n",
       "      <td>\"мышка, почему у тебя такие большие глаза?\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-30 11:28:00+00:00</td>\n",
       "      <td>29169.0</td>\n",
       "      <td>&lt;PPDV[os2]&gt; \"Мальчики, вы что больные, бегать ...</td>\n",
       "      <td>\"мальчики, вы что больные, бегать в палату к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-08-30 11:26:00+00:00</td>\n",
       "      <td>7140.0</td>\n",
       "      <td>&lt;Ohtori_Akio&gt; мы - как разработчики - живём с ...</td>\n",
       "      <td>мы - как разработчики - живём с субейзом под...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date   rating  \\\n",
       "id                                      \n",
       "1  2004-08-30 11:24:00+00:00  22010.0   \n",
       "2  2004-08-30 11:25:00+00:00  25105.0   \n",
       "3  2004-08-30 11:27:00+00:00   7192.0   \n",
       "4  2004-08-30 11:28:00+00:00  29169.0   \n",
       "5  2004-08-30 11:26:00+00:00   7140.0   \n",
       "\n",
       "                                                 text  \\\n",
       "id                                                      \n",
       "1   <Ares> ppdv, все юниксы очень дружелюбны.. они...   \n",
       "2   <томатик_рад> а ты не чувствуешь красоту мира?...   \n",
       "3   <Дор> \"мышка, почему у тебя такие большие глаз...   \n",
       "4   <PPDV[os2]> \"Мальчики, вы что больные, бегать ...   \n",
       "5   <Ohtori_Akio> мы - как разработчики - живём с ...   \n",
       "\n",
       "                                           clear_text  \n",
       "id                                                     \n",
       "1     ppdv, все юниксы очень дружелюбны.. они прос...  \n",
       "2     а ты не чувствуешь красоту мира?   честно го...  \n",
       "3     \"мышка, почему у тебя такие большие глаза?\" ...  \n",
       "4     \"мальчики, вы что больные, бегать в палату к...  \n",
       "5     мы - как разработчики - живём с субейзом под...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec[\"clear_text\"] = df_rec[\"text\"].apply(lambda x: clear_text(x))\n",
    "df_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T19:58:28.241526Z",
     "iopub.status.busy": "2023-03-07T19:58:28.240596Z",
     "iopub.status.idle": "2023-03-07T19:58:39.406308Z",
     "shell.execute_reply": "2023-03-07T19:58:39.405088Z",
     "shell.execute_reply.started": "2023-03-07T19:58:28.241468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2) (0.6.2)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:22:44.752824Z",
     "iopub.status.busy": "2023-03-07T20:22:44.752127Z",
     "iopub.status.idle": "2023-03-07T20:22:54.951389Z",
     "shell.execute_reply": "2023-03-07T20:22:54.950230Z",
     "shell.execute_reply.started": "2023-03-07T20:22:44.752787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pymorphy2 in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2) (0.6.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "\n",
    "import re\n",
    "import pymorphy2\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def text_proc_3(text):\n",
    "    if text != '':\n",
    "        text = re.sub(r\"\\s+\", \" \", text) # убрал лишние пробелы (\\s+ Любой пробельный символ 1 и более вхождений шаблона)\n",
    "        text = re.sub(r\"^\\s+\", \"\", text) #  уберу первые пробелы в начале строки\n",
    "        text = text.rstrip() #  уберу последний пробел в начале строки\n",
    "    return text\n",
    "\n",
    "def lemma(txt):\n",
    "    return morph.parse(txt)[0].normal_form\n",
    "\n",
    "def concat(vec):\n",
    "    return ' '.join(vec)\n",
    "\n",
    "def prep1(string):\n",
    "    string = string.lower()\n",
    "    string = string.replace('ё', 'е')\n",
    "    string = string.replace(':', '.')\n",
    "    string = string.replace('!', '.')\n",
    "    string = string.replace(',', '.')\n",
    "    string = string.replace('.', ' . ')\n",
    "    string = string.replace(' . ', ' ')\n",
    "    string = string.replace('№', '')\n",
    "    string = string.replace('sd', '')\n",
    "    string = string.replace('im', '')\n",
    "    string = string.replace('\\\\', ' ')\n",
    "    string = string.replace(' .', '. ')\n",
    "    string = string.replace('•', '.')\n",
    "    string = string.replace('.', ' ')\n",
    "    string = string.replace('xxx', ' ').replace('yyy', ' ').replace('ххх', ' ')\n",
    "    string = re.sub('[^а-яА-Я]', ' ', string) # заменил на пробел не буквы\n",
    "    string = text_proc_3(concat(list(  [lemma(j) for j in string.split() ] ) ))\n",
    "    string = text_proc_3(string) # убрал лишние пробелы \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:22:54.954694Z",
     "iopub.status.busy": "2023-03-07T20:22:54.954002Z",
     "iopub.status.idle": "2023-03-07T20:34:40.001898Z",
     "shell.execute_reply": "2023-03-07T20:34:40.000870Z",
     "shell.execute_reply.started": "2023-03-07T20:22:54.954646Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rec['clear_text'] = df_rec['clear_text'].apply(lambda x: prep1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.003726Z",
     "iopub.status.busy": "2023-03-07T20:34:40.003386Z",
     "iopub.status.idle": "2023-03-07T20:34:40.013609Z",
     "shell.execute_reply": "2023-03-07T20:34:40.012498Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.003688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вот ребята из английский фирма давный давно в девяностый решить построить такой суперкар чтоб всё охренель купить где то двигнуть и вточить по завет чамберлить поставить на стенд чтоб мощность померить и порвать дино стенд так что хватить уже про свой уникальность энтузиаст весь мир вращать глобус совместно'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec.loc[463648, 'clear_text'].replace('ххх', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.017513Z",
     "iopub.status.busy": "2023-03-07T20:34:40.016751Z",
     "iopub.status.idle": "2023-03-07T20:34:40.025980Z",
     "shell.execute_reply": "2023-03-07T20:34:40.024798Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.017486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1         всё юникс очень дружелюбный они просто очень р...\n",
       "2         а ты не чувствовать красота мир честно говорит...\n",
       "3         мышка почему у ты такой больший глаз уйти я ха...\n",
       "4         мальчик вы что больной бегать в палата к девоч...\n",
       "5         мы как разработчик жить с субейз под одбец хор...\n",
       "                                ...                        \n",
       "463644    угадать не гуголь что такой жопиздать намекнут...\n",
       "463645    посетить шальной мысль заняться себя жирок сбр...\n",
       "463646    всебожьярос судьба айтишник вообще незавидный ...\n",
       "463647    прибыть на место правоохранитель установить чт...\n",
       "463648    вот ребята из английский фирма давный давно в ...\n",
       "Name: clear_text, Length: 81497, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_rec.loc[:, 'clear_text']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.028895Z",
     "iopub.status.busy": "2023-03-07T20:34:40.027839Z",
     "iopub.status.idle": "2023-03-07T20:34:40.035300Z",
     "shell.execute_reply": "2023-03-07T20:34:40.034125Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.028857Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_text_files(data_json, dest_path):\n",
    "    f = open(dest_path, 'w')\n",
    "    data = ''\n",
    "    for texts in data_json:\n",
    "        summary = str(texts).strip()\n",
    "        data += summary + \"  \"\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.037367Z",
     "iopub.status.busy": "2023-03-07T20:34:40.036765Z",
     "iopub.status.idle": "2023-03-07T20:34:40.308893Z",
     "shell.execute_reply": "2023-03-07T20:34:40.307565Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.037329Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.15)\n",
    "\n",
    "build_text_files(train,'train_dataset.txt')\n",
    "build_text_files(test,'test_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.311100Z",
     "iopub.status.busy": "2023-03-07T20:34:40.310471Z",
     "iopub.status.idle": "2023-03-07T20:34:40.317183Z",
     "shell.execute_reply": "2023-03-07T20:34:40.315985Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.311051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 69272\n",
      "Test dataset length: 12225\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset length: \"+ str(len(train)))\n",
    "print(\"Test dataset length: \"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:40.319568Z",
     "iopub.status.busy": "2023-03-07T20:34:40.319099Z",
     "iopub.status.idle": "2023-03-07T20:34:41.380874Z",
     "shell.execute_reply": "2023-03-07T20:34:41.379746Z",
     "shell.execute_reply.started": "2023-03-07T20:34:40.319528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"bankholdup/rugpt3_song_writer\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"bankholdup/rugpt3_song_writer\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"bankholdup/rugpt3_song_writer\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:41.383323Z",
     "iopub.status.busy": "2023-03-07T20:34:41.382566Z",
     "iopub.status.idle": "2023-03-07T20:34:41.677512Z",
     "shell.execute_reply": "2023-03-07T20:34:41.676334Z",
     "shell.execute_reply.started": "2023-03-07T20:34:41.383277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading features from cached file cached_lm_GPT2TokenizerFast_128_train_dataset.txt [took 0.252 s]\n",
      "Loading features from cached file cached_lm_GPT2TokenizerFast_128_test_dataset.txt [took 0.031 s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:41.682809Z",
     "iopub.status.busy": "2023-03-07T20:34:41.682270Z",
     "iopub.status.idle": "2023-03-07T20:34:45.536035Z",
     "shell.execute_reply": "2023-03-07T20:34:45.534569Z",
     "shell.execute_reply.started": "2023-03-07T20:34:41.682777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"bankholdup/rugpt3_song_writer\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bankholdup--rugpt3_song_writer/snapshots/b36e2b2198ad85d47b3685a9340f9d7404153d33/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at bankholdup/rugpt3_song_writer.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:45.538123Z",
     "iopub.status.busy": "2023-03-07T20:34:45.537709Z",
     "iopub.status.idle": "2023-03-07T20:34:45.546920Z",
     "shell.execute_reply": "2023-03-07T20:34:45.545696Z",
     "shell.execute_reply.started": "2023-03-07T20:34:45.538075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "    \"phrase\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:45.549307Z",
     "iopub.status.busy": "2023-03-07T20:34:45.548510Z",
     "iopub.status.idle": "2023-03-07T20:34:45.826578Z",
     "shell.execute_reply": "2023-03-07T20:34:45.825529Z",
     "shell.execute_reply.started": "2023-03-07T20:34:45.548830Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T20:34:45.829855Z",
     "iopub.status.busy": "2023-03-07T20:34:45.829480Z",
     "iopub.status.idle": "2023-03-07T21:12:26.882486Z",
     "shell.execute_reply": "2023-03-07T21:12:26.881318Z",
     "shell.execute_reply.started": "2023-03-07T20:34:45.829816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19245' max='19245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19245/19245 37:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.983200</td>\n",
       "      <td>4.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.534500</td>\n",
       "      <td>4.798376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.118600</td>\n",
       "      <td>4.828309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19245, training_loss=4.590447980603728, metrics={'train_runtime': 2261.0217, 'train_samples_per_second': 34.044, 'train_steps_per_second': 8.512, 'total_flos': 5028173217792000.0, 'train_loss': 4.590447980603728, 'epoch': 3.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T21:12:26.884592Z",
     "iopub.status.busy": "2023-03-07T21:12:26.884210Z",
     "iopub.status.idle": "2023-03-07T21:12:26.890896Z",
     "shell.execute_reply": "2023-03-07T21:12:26.889865Z",
     "shell.execute_reply.started": "2023-03-07T21:12:26.884546Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(prefix):\n",
    "    tokens = tokenizer(prefix, return_tensors='pt').to('cuda')\n",
    "    size = tokens['input_ids'].shape[1]\n",
    "\n",
    "    output = model.generate(\n",
    "        **tokens, \n",
    "        #end_token=end_token_id,\n",
    "        do_sample=False,\n",
    "        max_length=size+50, \n",
    "        early_stopping=True,\n",
    "        length_penalty=2.0,\n",
    "        repetition_penalty=8., \n",
    "        temperature=0.5,\n",
    "        num_beams=3,\n",
    "        no_repeat_ngram_size=5\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0])\n",
    "    result = decoded[len(prefix):]\n",
    "    return prefix + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T21:12:26.893175Z",
     "iopub.status.busy": "2023-03-07T21:12:26.892495Z",
     "iopub.status.idle": "2023-03-07T21:12:27.487491Z",
     "shell.execute_reply": "2023-03-07T21:12:27.486333Z",
     "shell.execute_reply.started": "2023-03-07T21:12:26.893139Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привет! у нас тут на работе в туалете висит табличка с надписью не курить  ххх а я вот думаю что делать если при загрузке винды из за того что она перестала загружаться то надо ее переустановить или почистить от вирусов\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"привет!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T21:12:27.489313Z",
     "iopub.status.busy": "2023-03-07T21:12:27.488954Z",
     "iopub.status.idle": "2023-03-07T21:12:28.075560Z",
     "shell.execute_reply": "2023-03-07T21:12:28.074401Z",
     "shell.execute_reply.started": "2023-03-07T21:12:27.489276Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Погода была прекрасная и солнечная а я в это время на работе  ххх у меня есть знакомая которая считает что если человек не может ходить по дому то он ненормальный потому что ему нельзя гулять с незнакомыми людьми которые могут быть опасны для его здоровья но при\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Погода была прекрасная\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T21:12:28.077560Z",
     "iopub.status.busy": "2023-03-07T21:12:28.076987Z",
     "iopub.status.idle": "2023-03-07T21:12:28.665287Z",
     "shell.execute_reply": "2023-03-07T21:12:28.664104Z",
     "shell.execute_reply.started": "2023-03-07T21:12:28.077519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как сдать экзамен?  ххх у нас на работе есть чувак который постоянно ходит в наушниках и слушает все что я ему говорю ну ты же музыкант он не может слушать музыку без наушников а если бы мог то это был бы человек с музыкальным слухом\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Как сдать экзамен?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

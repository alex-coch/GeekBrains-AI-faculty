{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdvVXtdRtjYw"
      },
      "source": [
        "# Урок 9. Языковое моделирование\n",
        "\n",
        "## Задание\n",
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf58s6MgtjY3"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMu8332RtjY3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings # Не показывать предупреждения.\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnOgfO6MtjY7"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'evgenyi_onegin.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQ2N00AtjY8",
        "outputId": "bb7ee17f-5aea-498a-c414-fd17e6b4a944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 286984 characters\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-fYnLHztjY9",
        "outputId": "68c69487-30c7-4062-b712-c137771d5d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Александр Сергеевич Пушкин\n",
            "\n",
            "                                Евгений Онегин\n",
            "                                Роман в стихах\n",
            "\n",
            "                        Не мысля гордый свет забавить,\n",
            "                        Вниманье дружбы возлюбя,\n",
            "                        Хотел бы я тебе представить\n",
            "                     \n"
          ]
        }
      ],
      "source": [
        "print(text[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE58Gcp-tjY-",
        "outputId": "c9f29c2b-fb9e-4ce0-d2e9-3590b1d59322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Отсортируем все символы в датасете и удалим повтряющиеся.\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqByGXcttjY_"
      },
      "outputs": [],
      "source": [
        "#  Сделаем перевод номеров симоволов в текст.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtlRtLo7tjZA",
        "outputId": "9211099e-e7d5-4046-f1ef-0c7cdbc600d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 71, 110, 104, ..., 104, 121,   0]),\n",
              " 'Александр Сергеевич Пушкин\\n\\n  ',\n",
              " 286984,\n",
              " 286984)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_as_int, text[:30], len(text_as_int), len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbaFJj2StjZB"
      },
      "source": [
        "### train and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSVegj02tjZB",
        "outputId": "3a283dfa-b759-44e7-94f4-ade4f7287046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "А\n",
            "л\n",
            "е\n",
            "к\n",
            "с\n"
          ]
        }
      ],
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-hgM8BWtjZB",
        "outputId": "7cb51d4c-0134-47fd-cb0d-d441def9a361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char_dataset.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwLMV7E5tjZC",
        "outputId": "0f754aeb-b602-426d-c104-66ffbb7ba4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
            "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
            "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
            "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
            "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
          ]
        }
      ],
      "source": [
        "# Выполним разбиение текста на последовательности длинной 100 символов.\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Выведем первые 5 батчей на экран.\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_1sa77ytjZC"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1] # Предсказываем по одному символу.\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkOZOET8tjZD",
        "outputId": "ce5c8a9b-30b7-464d-9346-bc880ad27302"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset\n",
        "\n",
        "# Разделим его на тренировочную и тестовую выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNvd3ztwtjZD"
      },
      "source": [
        "Print the first example input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiTbcvLbtjZD",
        "outputId": "7fe3533f-a93f-4154-a356-5b7a1e03538a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
            "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkZdNHZ9tjZE",
        "outputId": "653b7a2e-1295-459a-fc87-213fc76327dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6y7kieFtjZE"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 128\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9jbXNZptjZF"
      },
      "outputs": [],
      "source": [
        "class RNNgenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units): #, batch_size):\n",
        "        super(RNNgenerator, self).__init__()\n",
        "\n",
        "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim) #, batch_input_shape=[batch_size, None])\n",
        "\n",
        "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "        self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=False,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # self.lin_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        emb_x = self.emb(x)\n",
        "        x = self.gru1(emb_x)\n",
        "        x = self.gru2(x)\n",
        "        x = self.gru3(x)\n",
        "\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "model = RNNgenerator(vocab_size,\n",
        "                     embedding_dim,\n",
        "                     rnn_units=rnn_units\n",
        "                     ) #,\n",
        "                    #  batch_size= BATCH_SIZE)\n",
        "\n",
        "# model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYUZPDTGtjZF"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgilcPmotjZG"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8zrx3xFtjZG"
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikxmNuIjtjZG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o153P-DtjZG"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYnVIjSHtjZH"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './RNN_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath=checkpoint_prefix,\n",
        "                                save_freq=28,\n",
        "                                save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ2_dZrFtjZH"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAO2UskmtjZH"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3dyMKD7tjZH",
        "outputId": "d383d684-7830-47eb-aedf-4217b0a861d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/280\n",
            "44/44 [==============================] - 22s 245ms/step - loss: 2.2132 - accuracy: 0.5441\n",
            "Epoch 2/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 1.6393 - accuracy: 0.5810\n",
            "Epoch 3/280\n",
            "44/44 [==============================] - 10s 203ms/step - loss: 1.4694 - accuracy: 0.5994\n",
            "Epoch 4/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 1.3574 - accuracy: 0.6167\n",
            "Epoch 5/280\n",
            "44/44 [==============================] - 10s 204ms/step - loss: 1.3173 - accuracy: 0.6285\n",
            "Epoch 6/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 1.2537 - accuracy: 0.6401\n",
            "Epoch 7/280\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 1.2091 - accuracy: 0.6512\n",
            "Epoch 8/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 1.1765 - accuracy: 0.6605\n",
            "Epoch 9/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 1.1249 - accuracy: 0.6729\n",
            "Epoch 10/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 1.0676 - accuracy: 0.6873\n",
            "Epoch 11/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 1.0369 - accuracy: 0.6997\n",
            "Epoch 12/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.9745 - accuracy: 0.7145\n",
            "Epoch 13/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.9192 - accuracy: 0.7286\n",
            "Epoch 14/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.8673 - accuracy: 0.7434\n",
            "Epoch 15/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.8020 - accuracy: 0.7612\n",
            "Epoch 16/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.7445 - accuracy: 0.7787\n",
            "Epoch 17/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.8214 - accuracy: 0.7674\n",
            "Epoch 18/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.6742 - accuracy: 0.8036\n",
            "Epoch 19/280\n",
            "44/44 [==============================] - 10s 213ms/step - loss: 0.5998 - accuracy: 0.8283\n",
            "Epoch 20/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.5256 - accuracy: 0.8535\n",
            "Epoch 21/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.4779 - accuracy: 0.8735\n",
            "Epoch 22/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.4166 - accuracy: 0.8929\n",
            "Epoch 23/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.3513 - accuracy: 0.9124\n",
            "Epoch 24/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.3201 - accuracy: 0.9220\n",
            "Epoch 25/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.2858 - accuracy: 0.9293\n",
            "Epoch 26/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.2532 - accuracy: 0.9365\n",
            "Epoch 27/280\n",
            "44/44 [==============================] - 11s 221ms/step - loss: 0.2319 - accuracy: 0.9408\n",
            "Epoch 28/280\n",
            "44/44 [==============================] - 10s 217ms/step - loss: 0.2153 - accuracy: 0.9446\n",
            "Epoch 29/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.2401 - accuracy: 0.9413\n",
            "Epoch 30/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.1984 - accuracy: 0.9492\n",
            "Epoch 31/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.1903 - accuracy: 0.9515\n",
            "Epoch 32/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.1667 - accuracy: 0.9580\n",
            "Epoch 33/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.1549 - accuracy: 0.9614\n",
            "Epoch 34/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.1433 - accuracy: 0.9652\n",
            "Epoch 35/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.1390 - accuracy: 0.9662\n",
            "Epoch 36/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.1293 - accuracy: 0.9690\n",
            "Epoch 37/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.1198 - accuracy: 0.9716\n",
            "Epoch 38/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.1131 - accuracy: 0.9731\n",
            "Epoch 39/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.1080 - accuracy: 0.9741\n",
            "Epoch 40/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.1255 - accuracy: 0.9694\n",
            "Epoch 41/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.1382 - accuracy: 0.9644\n",
            "Epoch 42/280\n",
            "44/44 [==============================] - 11s 230ms/step - loss: 0.1249 - accuracy: 0.9689\n",
            "Epoch 43/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.1065 - accuracy: 0.9743\n",
            "Epoch 44/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0992 - accuracy: 0.9758\n",
            "Epoch 45/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0959 - accuracy: 0.9762\n",
            "Epoch 46/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0926 - accuracy: 0.9770\n",
            "Epoch 47/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.1316 - accuracy: 0.9680\n",
            "Epoch 48/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.1211 - accuracy: 0.9696\n",
            "Epoch 49/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.1115 - accuracy: 0.9724\n",
            "Epoch 50/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0974 - accuracy: 0.9761\n",
            "Epoch 51/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0918 - accuracy: 0.9769\n",
            "Epoch 52/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0898 - accuracy: 0.9773\n",
            "Epoch 53/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0879 - accuracy: 0.9775\n",
            "Epoch 54/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0857 - accuracy: 0.9779\n",
            "Epoch 55/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0847 - accuracy: 0.9781\n",
            "Epoch 56/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0835 - accuracy: 0.9784\n",
            "Epoch 57/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0823 - accuracy: 0.9786\n",
            "Epoch 58/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0820 - accuracy: 0.9787\n",
            "Epoch 59/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0813 - accuracy: 0.9789\n",
            "Epoch 60/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0905 - accuracy: 0.9770\n",
            "Epoch 61/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.1608 - accuracy: 0.9577\n",
            "Epoch 62/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.1435 - accuracy: 0.9617\n",
            "Epoch 63/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.1478 - accuracy: 0.9605\n",
            "Epoch 64/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.1400 - accuracy: 0.9635\n",
            "Epoch 65/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.1183 - accuracy: 0.9704\n",
            "Epoch 66/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.1422 - accuracy: 0.9628\n",
            "Epoch 67/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.1000 - accuracy: 0.9752\n",
            "Epoch 68/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0872 - accuracy: 0.9786\n",
            "Epoch 69/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0808 - accuracy: 0.9797\n",
            "Epoch 70/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0785 - accuracy: 0.9800\n",
            "Epoch 71/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0765 - accuracy: 0.9801\n",
            "Epoch 72/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0753 - accuracy: 0.9806\n",
            "Epoch 73/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0747 - accuracy: 0.9806\n",
            "Epoch 74/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0738 - accuracy: 0.9808\n",
            "Epoch 75/280\n",
            "44/44 [==============================] - 10s 207ms/step - loss: 0.0728 - accuracy: 0.9810\n",
            "Epoch 76/280\n",
            "44/44 [==============================] - 11s 222ms/step - loss: 0.0726 - accuracy: 0.9810\n",
            "Epoch 77/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.0728 - accuracy: 0.9809\n",
            "Epoch 78/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.1458 - accuracy: 0.9655\n",
            "Epoch 79/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0983 - accuracy: 0.9757\n",
            "Epoch 80/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0871 - accuracy: 0.9784\n",
            "Epoch 81/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0797 - accuracy: 0.9800\n",
            "Epoch 82/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.0762 - accuracy: 0.9805\n",
            "Epoch 83/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0740 - accuracy: 0.9812\n",
            "Epoch 84/280\n",
            "44/44 [==============================] - 11s 226ms/step - loss: 0.0729 - accuracy: 0.9812\n",
            "Epoch 85/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0720 - accuracy: 0.9812\n",
            "Epoch 86/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0713 - accuracy: 0.9811\n",
            "Epoch 87/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0710 - accuracy: 0.9812\n",
            "Epoch 88/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0704 - accuracy: 0.9815\n",
            "Epoch 89/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.0703 - accuracy: 0.9813\n",
            "Epoch 90/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0698 - accuracy: 0.9816\n",
            "Epoch 91/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0696 - accuracy: 0.9815\n",
            "Epoch 92/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0690 - accuracy: 0.9815\n",
            "Epoch 93/280\n",
            "44/44 [==============================] - 11s 226ms/step - loss: 0.0692 - accuracy: 0.9814\n",
            "Epoch 94/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0692 - accuracy: 0.9814\n",
            "Epoch 95/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0694 - accuracy: 0.9814\n",
            "Epoch 96/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0688 - accuracy: 0.9817\n",
            "Epoch 97/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0685 - accuracy: 0.9816\n",
            "Epoch 98/280\n",
            "44/44 [==============================] - 11s 226ms/step - loss: 0.0684 - accuracy: 0.9815\n",
            "Epoch 99/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0681 - accuracy: 0.9818\n",
            "Epoch 100/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.0687 - accuracy: 0.9816\n",
            "Epoch 101/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0681 - accuracy: 0.9817\n",
            "Epoch 102/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0681 - accuracy: 0.9818\n",
            "Epoch 103/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0686 - accuracy: 0.9816\n",
            "Epoch 104/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0682 - accuracy: 0.9817\n",
            "Epoch 105/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0681 - accuracy: 0.9817\n",
            "Epoch 106/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0680 - accuracy: 0.9818\n",
            "Epoch 107/280\n",
            "44/44 [==============================] - 11s 228ms/step - loss: 0.0677 - accuracy: 0.9817\n",
            "Epoch 108/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0675 - accuracy: 0.9817\n",
            "Epoch 109/280\n",
            "44/44 [==============================] - 11s 225ms/step - loss: 0.0671 - accuracy: 0.9818\n",
            "Epoch 110/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 0.0676 - accuracy: 0.9816\n",
            "Epoch 111/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0678 - accuracy: 0.9818\n",
            "Epoch 112/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0679 - accuracy: 0.9816\n",
            "Epoch 113/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0678 - accuracy: 0.9817\n",
            "Epoch 114/280\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 0.0673 - accuracy: 0.9819\n",
            "Epoch 115/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0674 - accuracy: 0.9816\n",
            "Epoch 116/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0672 - accuracy: 0.9817\n",
            "Epoch 117/280\n",
            "44/44 [==============================] - 10s 213ms/step - loss: 0.0670 - accuracy: 0.9820\n",
            "Epoch 118/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0669 - accuracy: 0.9818\n",
            "Epoch 119/280\n",
            "44/44 [==============================] - 11s 231ms/step - loss: 0.0669 - accuracy: 0.9817\n",
            "Epoch 120/280\n",
            "44/44 [==============================] - 10s 213ms/step - loss: 0.0673 - accuracy: 0.9818\n",
            "Epoch 121/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0673 - accuracy: 0.9817\n",
            "Epoch 122/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0669 - accuracy: 0.9818\n",
            "Epoch 123/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0667 - accuracy: 0.9818\n",
            "Epoch 124/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0667 - accuracy: 0.9818\n",
            "Epoch 125/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0669 - accuracy: 0.9816\n",
            "Epoch 126/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0670 - accuracy: 0.9818\n",
            "Epoch 127/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.0673 - accuracy: 0.9816\n",
            "Epoch 128/280\n",
            "44/44 [==============================] - 10s 228ms/step - loss: 0.0676 - accuracy: 0.9816\n",
            "Epoch 129/280\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 0.2482 - accuracy: 0.9400\n",
            "Epoch 130/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 1.0298 - accuracy: 0.7419\n",
            "Epoch 131/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.7722 - accuracy: 0.7817\n",
            "Epoch 132/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.4997 - accuracy: 0.8466\n",
            "Epoch 133/280\n",
            "44/44 [==============================] - 11s 220ms/step - loss: 0.3125 - accuracy: 0.9054\n",
            "Epoch 134/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.1993 - accuracy: 0.9463\n",
            "Epoch 135/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.1371 - accuracy: 0.9680\n",
            "Epoch 136/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.1041 - accuracy: 0.9772\n",
            "Epoch 137/280\n",
            "44/44 [==============================] - 11s 230ms/step - loss: 0.1284 - accuracy: 0.9688\n",
            "Epoch 138/280\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 0.1194 - accuracy: 0.9689\n",
            "Epoch 139/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0900 - accuracy: 0.9790\n",
            "Epoch 140/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0784 - accuracy: 0.9813\n",
            "Epoch 141/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0741 - accuracy: 0.9815\n",
            "Epoch 142/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0723 - accuracy: 0.9818\n",
            "Epoch 143/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0708 - accuracy: 0.9817\n",
            "Epoch 144/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0700 - accuracy: 0.9819\n",
            "Epoch 145/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0692 - accuracy: 0.9819\n",
            "Epoch 146/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0687 - accuracy: 0.9818\n",
            "Epoch 147/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0679 - accuracy: 0.9820\n",
            "Epoch 148/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0678 - accuracy: 0.9820\n",
            "Epoch 149/280\n",
            "44/44 [==============================] - 11s 229ms/step - loss: 0.0674 - accuracy: 0.9820\n",
            "Epoch 150/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0673 - accuracy: 0.9819\n",
            "Epoch 151/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0672 - accuracy: 0.9818\n",
            "Epoch 152/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0671 - accuracy: 0.9819\n",
            "Epoch 153/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0668 - accuracy: 0.9819\n",
            "Epoch 154/280\n",
            "44/44 [==============================] - 11s 228ms/step - loss: 0.0670 - accuracy: 0.9819\n",
            "Epoch 155/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0666 - accuracy: 0.9818\n",
            "Epoch 156/280\n",
            "44/44 [==============================] - 11s 229ms/step - loss: 0.0661 - accuracy: 0.9819\n",
            "Epoch 157/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0659 - accuracy: 0.9820\n",
            "Epoch 158/280\n",
            "44/44 [==============================] - 11s 223ms/step - loss: 0.0662 - accuracy: 0.9818\n",
            "Epoch 159/280\n",
            "44/44 [==============================] - 10s 207ms/step - loss: 0.0661 - accuracy: 0.9820\n",
            "Epoch 160/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0662 - accuracy: 0.9819\n",
            "Epoch 161/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0660 - accuracy: 0.9819\n",
            "Epoch 162/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0659 - accuracy: 0.9819\n",
            "Epoch 163/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0658 - accuracy: 0.9820\n",
            "Epoch 164/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0657 - accuracy: 0.9820\n",
            "Epoch 165/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0658 - accuracy: 0.9819\n",
            "Epoch 166/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0657 - accuracy: 0.9820\n",
            "Epoch 167/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0653 - accuracy: 0.9819\n",
            "Epoch 168/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0657 - accuracy: 0.9818\n",
            "Epoch 169/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0656 - accuracy: 0.9820\n",
            "Epoch 170/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0656 - accuracy: 0.9820\n",
            "Epoch 171/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0656 - accuracy: 0.9821\n",
            "Epoch 172/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0655 - accuracy: 0.9819\n",
            "Epoch 173/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0657 - accuracy: 0.9821\n",
            "Epoch 174/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0655 - accuracy: 0.9820\n",
            "Epoch 175/280\n",
            "44/44 [==============================] - 11s 221ms/step - loss: 0.0655 - accuracy: 0.9819\n",
            "Epoch 176/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0655 - accuracy: 0.9819\n",
            "Epoch 177/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0654 - accuracy: 0.9819\n",
            "Epoch 178/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0657 - accuracy: 0.9819\n",
            "Epoch 179/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0656 - accuracy: 0.9821\n",
            "Epoch 180/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0655 - accuracy: 0.9820\n",
            "Epoch 181/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0655 - accuracy: 0.9819\n",
            "Epoch 182/280\n",
            "44/44 [==============================] - 11s 230ms/step - loss: 0.0652 - accuracy: 0.9820\n",
            "Epoch 183/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0653 - accuracy: 0.9819\n",
            "Epoch 184/280\n",
            "44/44 [==============================] - 11s 228ms/step - loss: 0.0654 - accuracy: 0.9818\n",
            "Epoch 185/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0653 - accuracy: 0.9820\n",
            "Epoch 186/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0654 - accuracy: 0.9819\n",
            "Epoch 187/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0650 - accuracy: 0.9820\n",
            "Epoch 188/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0652 - accuracy: 0.9819\n",
            "Epoch 189/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0651 - accuracy: 0.9821\n",
            "Epoch 190/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0655 - accuracy: 0.9818\n",
            "Epoch 191/280\n",
            "44/44 [==============================] - 11s 224ms/step - loss: 0.0652 - accuracy: 0.9820\n",
            "Epoch 192/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0655 - accuracy: 0.9820\n",
            "Epoch 193/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0652 - accuracy: 0.9818\n",
            "Epoch 194/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0654 - accuracy: 0.9819\n",
            "Epoch 195/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0653 - accuracy: 0.9820\n",
            "Epoch 196/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0656 - accuracy: 0.9818\n",
            "Epoch 197/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0657 - accuracy: 0.9819\n",
            "Epoch 198/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.0661 - accuracy: 0.9819\n",
            "Epoch 199/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.2169 - accuracy: 0.9393\n",
            "Epoch 200/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.7020 - accuracy: 0.8022\n",
            "Epoch 201/280\n",
            "44/44 [==============================] - 10s 217ms/step - loss: 0.6418 - accuracy: 0.8085\n",
            "Epoch 202/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.4571 - accuracy: 0.8554\n",
            "Epoch 203/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.3183 - accuracy: 0.8994\n",
            "Epoch 204/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.2189 - accuracy: 0.9352\n",
            "Epoch 205/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.1536 - accuracy: 0.9598\n",
            "Epoch 206/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.1125 - accuracy: 0.9740\n",
            "Epoch 207/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0891 - accuracy: 0.9800\n",
            "Epoch 208/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.0773 - accuracy: 0.9817\n",
            "Epoch 209/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0723 - accuracy: 0.9820\n",
            "Epoch 210/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0703 - accuracy: 0.9819\n",
            "Epoch 211/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0692 - accuracy: 0.9819\n",
            "Epoch 212/280\n",
            "44/44 [==============================] - 11s 230ms/step - loss: 0.0685 - accuracy: 0.9819\n",
            "Epoch 213/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0677 - accuracy: 0.9819\n",
            "Epoch 214/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0673 - accuracy: 0.9821\n",
            "Epoch 215/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0669 - accuracy: 0.9820\n",
            "Epoch 216/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0666 - accuracy: 0.9820\n",
            "Epoch 217/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.0662 - accuracy: 0.9822\n",
            "Epoch 218/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.0661 - accuracy: 0.9821\n",
            "Epoch 219/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0659 - accuracy: 0.9820\n",
            "Epoch 220/280\n",
            "44/44 [==============================] - 10s 207ms/step - loss: 0.0657 - accuracy: 0.9821\n",
            "Epoch 221/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0655 - accuracy: 0.9821\n",
            "Epoch 222/280\n",
            "44/44 [==============================] - 10s 215ms/step - loss: 0.0655 - accuracy: 0.9820\n",
            "Epoch 223/280\n",
            "44/44 [==============================] - 11s 225ms/step - loss: 0.0655 - accuracy: 0.9821\n",
            "Epoch 224/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0652 - accuracy: 0.9821\n",
            "Epoch 225/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0651 - accuracy: 0.9821\n",
            "Epoch 226/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0653 - accuracy: 0.9820\n",
            "Epoch 227/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0650 - accuracy: 0.9822\n",
            "Epoch 228/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0653 - accuracy: 0.9821\n",
            "Epoch 229/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.0651 - accuracy: 0.9819\n",
            "Epoch 230/280\n",
            "44/44 [==============================] - 11s 228ms/step - loss: 0.0651 - accuracy: 0.9820\n",
            "Epoch 231/280\n",
            "44/44 [==============================] - 10s 218ms/step - loss: 0.0648 - accuracy: 0.9823\n",
            "Epoch 232/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0651 - accuracy: 0.9821\n",
            "Epoch 233/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0646 - accuracy: 0.9821\n",
            "Epoch 234/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0647 - accuracy: 0.9820\n",
            "Epoch 235/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0645 - accuracy: 0.9820\n",
            "Epoch 236/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 0.0648 - accuracy: 0.9819\n",
            "Epoch 237/280\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0645 - accuracy: 0.9821\n",
            "Epoch 238/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0645 - accuracy: 0.9820\n",
            "Epoch 239/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0646 - accuracy: 0.9819\n",
            "Epoch 240/280\n",
            "44/44 [==============================] - 10s 228ms/step - loss: 0.0645 - accuracy: 0.9821\n",
            "Epoch 241/280\n",
            "44/44 [==============================] - 10s 216ms/step - loss: 0.0646 - accuracy: 0.9821\n",
            "Epoch 242/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0648 - accuracy: 0.9821\n",
            "Epoch 243/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0647 - accuracy: 0.9821\n",
            "Epoch 244/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0644 - accuracy: 0.9819\n",
            "Epoch 245/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0646 - accuracy: 0.9822\n",
            "Epoch 246/280\n",
            "44/44 [==============================] - 10s 209ms/step - loss: 0.0645 - accuracy: 0.9821\n",
            "Epoch 247/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0644 - accuracy: 0.9821\n",
            "Epoch 248/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0647 - accuracy: 0.9820\n",
            "Epoch 249/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0647 - accuracy: 0.9821\n",
            "Epoch 250/280\n",
            "44/44 [==============================] - 10s 213ms/step - loss: 0.0642 - accuracy: 0.9820\n",
            "Epoch 251/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0646 - accuracy: 0.9820\n",
            "Epoch 252/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0658 - accuracy: 0.9818\n",
            "Epoch 253/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0679 - accuracy: 0.9813\n",
            "Epoch 254/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.0690 - accuracy: 0.9812\n",
            "Epoch 255/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.0695 - accuracy: 0.9812\n",
            "Epoch 256/280\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0698 - accuracy: 0.9813\n",
            "Epoch 257/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0700 - accuracy: 0.9815\n",
            "Epoch 258/280\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0712 - accuracy: 0.9814\n",
            "Epoch 259/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.0727 - accuracy: 0.9810\n",
            "Epoch 260/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.0782 - accuracy: 0.9801\n",
            "Epoch 261/280\n",
            "44/44 [==============================] - 10s 225ms/step - loss: 0.1400 - accuracy: 0.9595\n",
            "Epoch 262/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.5284 - accuracy: 0.8467\n",
            "Epoch 263/280\n",
            "44/44 [==============================] - 11s 221ms/step - loss: 0.6896 - accuracy: 0.8035\n",
            "Epoch 264/280\n",
            "44/44 [==============================] - 10s 210ms/step - loss: 0.5766 - accuracy: 0.8258\n",
            "Epoch 265/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.4525 - accuracy: 0.8569\n",
            "Epoch 266/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.3403 - accuracy: 0.8906\n",
            "Epoch 267/280\n",
            "44/44 [==============================] - 10s 214ms/step - loss: 0.2492 - accuracy: 0.9225\n",
            "Epoch 268/280\n",
            "44/44 [==============================] - 10s 227ms/step - loss: 0.1841 - accuracy: 0.9473\n",
            "Epoch 269/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.1373 - accuracy: 0.9648\n",
            "Epoch 270/280\n",
            "44/44 [==============================] - 11s 224ms/step - loss: 0.1061 - accuracy: 0.9761\n",
            "Epoch 271/280\n",
            "44/44 [==============================] - 10s 207ms/step - loss: 0.0863 - accuracy: 0.9807\n",
            "Epoch 272/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0762 - accuracy: 0.9820\n",
            "Epoch 273/280\n",
            "44/44 [==============================] - 11s 232ms/step - loss: 0.0715 - accuracy: 0.9820\n",
            "Epoch 274/280\n",
            "44/44 [==============================] - 10s 212ms/step - loss: 0.0696 - accuracy: 0.9821\n",
            "Epoch 275/280\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0684 - accuracy: 0.9821\n",
            "Epoch 276/280\n",
            "44/44 [==============================] - 10s 211ms/step - loss: 0.0674 - accuracy: 0.9821\n",
            "Epoch 277/280\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0670 - accuracy: 0.9822\n",
            "Epoch 278/280\n",
            "44/44 [==============================] - 10s 208ms/step - loss: 0.0666 - accuracy: 0.9822\n",
            "Epoch 279/280\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0664 - accuracy: 0.9822\n",
            "Epoch 280/280\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0660 - accuracy: 0.9821\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[checkpoint_callback]\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0fRF6g9DtjZI",
        "outputId": "c891a7b8-1f40-4858-b858-206659a13954"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEeUlEQVR4nO3deZxU5Z3v8W/tvVY30PQGDbSAIItAULE1iSYSkWEcTXIzxnHGZYy5STDR4GQm5CaayWvuMDcZo5OJifF6DZNJXOIk0YkxJgTFtUXZFFARkJ1eaKD3rZZz/6g6p6ubrqa3qlPL5/161Qu6lu6nT3dXfev3/J7nOAzDMAQAAGATp90DAAAA2Y0wAgAAbEUYAQAAtiKMAAAAWxFGAACArQgjAADAVoQRAABgK8IIAACwldvuAQxHOBzW8ePHVVhYKIfDYfdwAADAMBiGoba2NlVWVsrpjF//SIswcvz4cVVVVdk9DAAAMApHjhzR1KlT496eFmGksLBQUuSb8fv9No8GAAAMR2trq6qqqqzX8XjSIoyYUzN+v58wAgBAmjlbiwUNrAAAwFaEEQAAYCvCCAAAsBVhBAAA2IowAgAAbEUYAQAAtiKMAAAAWxFGAACArQgjAADAVoQRAABgK8IIAACwFWEEAADYKi1OlJcoD7/8gY6e7tL1F03TnPKhzygIAAASI6srI7/bWaf1rx3UoZMddg8FAICsldVhxOOMfPuhsGHzSAAAyF5ZHUZcTockKUAYAQDANlkdRtyuSBgJhsI2jwQAgOyV3WEkWhkJUhkBAMA22R1GXJFvPxgijAAAYJesDiMec5omzDQNAAB2yeow4nJSGQEAwG5ZHUY8TiojAADYLavDiLWahgZWAABsk9VhhGkaAADsl9VhxMM+IwAA2C6rw4iLfUYAALBdVocRj7nPCGEEAADbZHUYsXZgpWcEAADbEEbE0l4AAOyU3WEkOk0ToDICAIBtsjqMmA2sISojAADYJqvDSN/SXiojAADYJavDiDu66VmA1TQAANgmu8OIi2kaAADslt1hxEkDKwAAdsvuMGJVRggjAADYJbvDSHQ1TYBz0wAAYJvsDiMuztoLAIDdsjuMOJmmAQDAboQRSQFW0wAAYJusDiPmWXupjAAAYJ+sDiMuq4GVMAIAgF2yOoy4re3gmaYBAMAuIwoj69at04UXXqjCwkKVlpbq2muv1Z49e876uCeffFJz585VTk6OFi5cqGeffXbUAx5P5qZnTNMAAGCfEYWRF198UatXr9brr7+uDRs2KBAI6Morr1RHR0fcx7z22mu6/vrrdeutt2r79u269tprde2112rXrl1jHvxYmZURGlgBALCPwzCMUZcFTpw4odLSUr344ov66Ec/Ouh9rrvuOnV0dOiZZ56xrrv44ou1ePFiPfjgg8P6Oq2trSoqKlJLS4v8fv9oh3uGnUdbdPUPX1FFUY5q114xbp8XAAAM//V7TD0jLS0tkqSJEyfGvU9tba2WL1/e77oVK1aotrY27mN6enrU2tra75IIZgNrkGkaAABsM+owEg6Hdeedd+rSSy/VggUL4t6vvr5eZWVl/a4rKytTfX193MesW7dORUVF1qWqqmq0wxyShwZWAABsN+owsnr1au3atUuPP/74eI5HkrR27Vq1tLRYlyNHjoz715BitoOnMgIAgG3co3nQ7bffrmeeeUYvvfSSpk6dOuR9y8vL1dDQ0O+6hoYGlZeXx32Mz+eTz+cbzdBGxNyBlXPTAABgnxFVRgzD0O23367f/OY3ev7551VdXX3Wx9TU1Gjjxo39rtuwYYNqampGNtIEsPYZYTUNAAC2GVFlZPXq1Xr00Uf19NNPq7Cw0Or7KCoqUm5uriTpxhtv1JQpU7Ru3TpJ0h133KHLLrtM9957r1atWqXHH39cW7Zs0UMPPTTO38rI0cAKAID9RlQZ+fGPf6yWlhZdfvnlqqiosC5PPPGEdZ/Dhw+rrq7O+viSSy7Ro48+qoceekiLFi3Sf/3Xf+mpp54asuk1WTzRTc8Mg43PAACwy4gqI8PZkmTTpk1nXPeZz3xGn/nMZ0bypZLCnKaRIlM1LqfLxtEAAJCdsvvcNM6+b58mVgAA7JHdYSS2MkIYAQDAFtkdRpz9p2kAAEDyZXUYcTgcrKgBAMBmWR1GpL7qSIAt4QEAsAVhJBpGWNoLAIA9CCPR89MEaGAFAMAWWR9GzDP3UhkBAMAeWR9GXPSMAABgq6wPI+bGZ6ymAQDAHoQRa5qGyggAAHYgjFjTNFRGAACwQ9aHEU90NQ3bwQMAYI+sDyN9O7AyTQMAgB2yPoy4qYwAAGArwgjnpgEAwFaEEaZpAACwVdaHERpYAQCwV9aHERfTNAAA2Crrw4h5bpog28EDAGCLrA8jbAcPAIC9sj6MuKiMAABgq6wPIx56RgAAsFXWhxEX0zQAANgq68MIDawAANgr68OI28VZewEAsBNhJDpNE2KaBgAAWxBGog2sAbaDBwDAFlkfRsylvSGmaQAAsEXWhxEPq2kAALBV1oeRvgZWpmkAALADYSTaM0IDKwAA9iCMuCKHgKW9AADYgzBiVUaYpgEAwA6EEWtpL5URAADsQBiJTtOwHTwAAPYgjNDACgCArQgjNLACAGCrrA8j1ll7aWAFAMAWWR9GXNFpmiCVEQAAbJH1YcTNdvAAANiKMGJWRggjAADYgjBi9oywtBcAAFtkfRjxWPuMUBkBAMAOWR9GrAZWVtMAAGCLrA8jfUt7qYwAAGCHrA8j1moapmkAALBF1ocRpmkAALBX1ocRGlgBALBX1ocRrztyCHqCVEYAALBD1ocRf45bktTeE+TMvQAA2CDrw0hhjsf6f3t30MaRAACQnbI+jHjdTuV4IoehtTtg82gAAMg+WR9GpL7qCGEEAIDkI4yor2+ktYtpGgAAko0wIsmfG6mMtFEZAQAg6Qgjip2moTICAECyEUbUN01DZQQAgOQjjCimMkLPCAAASUcYkeTPjTawUhkBACDpCCOS/Dk0sAIAYBfCiFjaCwCAnQgj6usZaeuhMgIAQLIRRhTTM0JlBACApCOMiJ4RAADsRBgRm54BAGAnwoj6pmnaugMyDMPm0QAAkF1GHEZeeuklXX311aqsrJTD4dBTTz015P03bdokh8NxxqW+vn60Yx53ZmUkEDLUHQjbPBoAALLLiMNIR0eHFi1apAceeGBEj9uzZ4/q6uqsS2lp6Ui/dMLke11yOiL/Z+MzAACSyz3SB6xcuVIrV64c8RcqLS1VcXHxiB+XDA6HQ4U5HrV0BdTWHVCZP8fuIQEAkDWS1jOyePFiVVRU6BOf+IReffXVIe/b09Oj1tbWfpdEM/tGWljeCwBAUiU8jFRUVOjBBx/Ur371K/3qV79SVVWVLr/8cm3bti3uY9atW6eioiLrUlVVlehhqtDH8l4AAOww4mmakZozZ47mzJljfXzJJZdo//79uu+++/Sf//mfgz5m7dq1WrNmjfVxa2trwgNJ38nyqIwAAJBMCQ8jg7nooov0yiuvxL3d5/PJ5/MlcURsfAYAgF1s2Wdkx44dqqiosONLx2VtfEbPCAAASTXiykh7e7v27dtnfXzgwAHt2LFDEydO1LRp07R27VodO3ZMP/vZzyRJ999/v6qrqzV//nx1d3fr4Ycf1vPPP68//vGP4/ddjIO+BlYqIwAAJNOIw8iWLVv0sY99zPrY7O246aabtH79etXV1enw4cPW7b29vbrrrrt07Ngx5eXl6fzzz9ef/vSnfp8jFUzM80qSTnX02DwSAACyi8NIg/3PW1tbVVRUpJaWFvn9/oR8jcffOKyv/3qnPj63VI/cfGFCvgYAANlkuK/fnJsmanJhpGH2RBuVEQAAkokwElVSEAkjTe2EEQAAkokwEmVWRpraexQOp/zMFQAAGYMwEjWpINLAGggZrKgBACCJCCNRPrdLRbmRvUaYqgEAIHkIIzFoYgUAIPkIIzEmR5tYT1AZAQAgaQgjMUqojAAAkHSEkRhURgAASD7CSIySwsiKmqa2XptHAgBA9iCMxKAyAgBA8hFGYrCaBgCA5COMxGBLeAAAko8wEqM0Whk52d6jEFvCAwCQFISRGBPzvXI4pLAhne6kiRUAgGQgjMRwu5wq9+dIkvY2tNs8GgAAsgNhZIALZ0yUJNV+cNLmkQAAkB0IIwNcMnOSJKl2f5PNIwEAIDsQRga4ZGaJJGn74WZ19gZtHg0AAJmPMDJA1cRcTSnOVTBs6M2Dp+0eDgAAGY8wMoDD4bCmal5jqgYAgIQjjAyiJhpG3jxwyuaRAACQ+Qgjg5hfWSQpsrzXMNj8DACARCKMDGJGSZ6cDqmtJ6hGzlMDAEBCEUYG4XO7NGNSviQ2PwMAINEII3HMLC2QJO1tbLN5JAAAZDbCSByzo2FkXyOVEQAAEokwEsfsMrMyQhgBACCRCCNxzJpcKEnaTxgBACChCCNxzCyNNLCe7OjVyXZW1AAAkCiEkTjyvG5NKc6VRN8IAACJRBgZwrnRvpH36llRAwBAohBGhrC4aoIkaeshTpgHAECiEEaGcMGMSBjZcpBz1AAAkCiEkSEsriqWy+nQ8ZZuHW/usns4AABkJMLIEPJ9bs2r8EuStjBVAwBAQhBGzsKcqtnKVA0AAAlBGDmLC6ZPlCS9eZDKCAAAiUAYOYsLo5WR9+pb2fwMAIAEIIycRak/R/Mr/Qob0sZ3G+0eDgAAGYcwMgwr5pdLkv6wu97mkQAAkHkII8NghpGX9zWpvSdo82gAAMgshJFhOLesQDMm5ak3GNamPUzVAAAwnggjw+BwOKzqyAvvnbB5NAAAZBbCyDBdVB1Z4rvzWLO9AwEAIMMQRoZp4ZQiSdK+xnZ19tI3AgDAeCGMDFOpP0elhT6FDemd4612DwcAgIxBGBkBszqy81iLzSMBACBzEEZGYAFhBACAcUcYGYHzp0bCyC7CCAAA44YwMgI0sQIAMP4IIyMQ28T6bh1NrAAAjAfCyAjNq/RLkt6ta7N5JAAAZAbCyAjNLTfDCJURAADGA2FkhM6rKJQkvVdPZQQAgPFAGBmh8yoilZE99W0Khw2bRwMAQPojjIxQdUm+vC6n2nuCOtbcZfdwAABIe4SREfK4nJpdViBJeoe+EQAAxowwMgpmE+t7rKgBAGDMCCOj0NfESmUEAICxIoyMgtnEuuNIswyDJlYAAMaCMDIKS6dPUJ7XpbqWbu040mz3cAAASGuEkVHI8bi0/LwySdIzb9fZPBoAANIbYWSUVp1fIUl6dmcd+40AADAGhJFRuuzcySrwuVXX0q3tR07bPRwAANIWYWSUcjwufXxuqSTppfebbB4NkHyhsKGfv36IVWUAxowwMgbnTy2SJO1tZL8RZJ8tB0/pm0/t0j1P77Z7KADS3IjDyEsvvaSrr75alZWVcjgceuqpp876mE2bNulDH/qQfD6fZs2apfXr149iqKlnVmlkJ9a9De02jwRIvtbuoCTpVEevzSMBkO5GHEY6Ojq0aNEiPfDAA8O6/4EDB7Rq1Sp97GMf044dO3TnnXfqc5/7nP7whz+MeLCpZnZZZPOzA00d6g2GbR4NkFyhcOR3visQsnkkANKde6QPWLlypVauXDns+z/44IOqrq7WvffeK0k677zz9Morr+i+++7TihUrRvrlU0plUY7yvS519IZ06GSHFU6AbBCK5u9uwgiAMUp4z0htba2WL1/e77oVK1aotrY27mN6enrU2tra75KKHA6HZkUDyPtM1SDLhKK7D3f1EkYAjE3Cw0h9fb3Kysr6XVdWVqbW1lZ1dXUN+ph169apqKjIulRVVSV6mKN2rtk3QhMrskzsNA2nRQAwFim5mmbt2rVqaWmxLkeOHLF7SHHNLjPDCJURZBdzmiZsSL0heqYAjN6Ie0ZGqry8XA0NDf2ua2hokN/vV25u7qCP8fl88vl8iR7auDD7RPY2UBlBdjErI5LU3RuWz+2ycTQA0lnCKyM1NTXauHFjv+s2bNigmpqaRH/ppJgdnaY50NShAO8OkUVif91ZUQNgLEYcRtrb27Vjxw7t2LFDUmTp7o4dO3T48GFJkSmWG2+80br/F77wBX3wwQf6+7//e7333nv60Y9+pF/+8pf66le/Oj7fgc2mFOeqwOdWIGTogxMddg8HSJpQTJ8IYQTAWIw4jGzZskVLlizRkiVLJElr1qzRkiVLdPfdd0uS6urqrGAiSdXV1frd736nDRs2aNGiRbr33nv18MMPp/2yXpPD4dC8Cr8kadexFptHAyRPKKY0wooaAGMx4p6Ryy+/fMjO+cF2V7388su1ffv2kX6ptDGv0q83Dp7S7uOt+vRSu0cDJEco5mmAygiAsUjJ1TTpZsGUyDlqdh2nMoLsEQ73pRE2PgMwFoSRcTC/MjJN8+7x1n5P0EAmC8b8rjNNA2AsCCPjYFZpgbxup9p6gjpyutPu4QBJEaaBFcA4IYyMA4/Lqbnlkf1Gdh1Lza3rgfEWDBFGAIwPwsg4MadqdtM3giwRu7SXnhEAY0EYGSfzKiNNrLuPUxlBdgjTMwJgnBBGxklsZYSThiEb9GtgpTICYAwII+PkvHK/nA6pqb1XjW09dg8HSDgaWAGMF8LIOMn1ujRzcuQ8NfSNIBvENrB2M00DYAwII+PInKphRQ2yAZURAOOFMDKOzJ1YqYwgG4T69YxwxmoAo0cYGUfzqIwgi7ADK4DxQhgZR/MrIpWRY81dau7stXk0QGJxbhoA44UwMo6K8jyqmpgrSXqH/UaQ4VjaC2C8EEbG2ZyyyFTN+w1tNo8ESKx+DaxM0wAYA8LIOJtVGlneu/9Eh80jARIrxDQNgHFCGBlnZhjZ19hu80iAxAoxTQNgnBBGxtnMyfmSpP0nCCPIbIQRAOOFMDLOZkYrI41tPWrtDtg8GiBxQvSMABgnhJFx5s/xqMzvk8RUDTJbbGWkJxjut9QXAEaCMJIA5jlq9kfDyD1P79Inf/SqeoK8e0TmCA0IH938fgMYJcJIAlhNrCfaFQobeuyNI9p+uFnv11MpQeYYGEaYqgEwWoSRBOirjHSovrVbvaHIeTtauughQeY4I4zQxApglAgjCdC310i7Dp/stK5v7mKLeGSO2AZWib1GAIweYSQBZkfDyKGTHf12Ym3upDKCzHFGzwhn7gUwSoSRBJhc6NPEfK/ChrTxvUbreqZpkEmYpgEwXggjCeBwODS3vFCSVLu/ybqeM/kik9DACmC8EEYSZG555IR5gVDfEzbTNMgkVEYAjBfCSILMrSg847pmpmmQQcyz9jockY9pYAUwWoSRBDkvWhmJ1UJlBBkkGK2M5HvdkpimATB6hJEEmV1WIKej/3Us7UUmMbd/z/e5JDFNA2D0CCMJkuNxqbokcgbfPG/kyZqeEWQSszJS4ItWRggjAEaJMJJAcysiUzULKoskRXpGDIOTiSEzhAaEkW6maQCMEmEkgT4+p1SStHJhuSSpNxhmYyhkDLOBNZ/KCIAxcts9gEz26aVT9Yn5ZSr0ufXPz76rQMhQc1evcr25dg8NGDOmaQCMFyojCebP8cjhcKgo1yuJvhFkjvDAMNJL1Q/A6BBGkqQ4zyOJMILMYZ4oryAn2jNCZQTAKBFGkqQ4NxJGWljeiwwRCtEzAmB8EEaShMoIMo1VGfGx6Vk6O9jUoZPtPXYPA1mOBtYksXpG2BIeGYIG1vTX1N6jy/91kyTp4L+ssncwyGpURpKEyggyTd8OrPSMpKtDJzus/3NW8dRhGIbeOHAqq04hQhhJEnpGkGnOmKYhjKQdn9tl/f/9hnYbR4JYtR+c1F/+pFb/66mddg8laQgjSWJWRlqYpkEGCIcNmZsJ0zOSvnpDfcux9zS02TgSxDp0slOStK8xewIiYSRJivLYZwSZIxRzWgNOlJe+gqG+n+P79YSRVNEafdPalEWNxYSRJCkpiISR+pZum0cCjJ15XhpJKmSfkbQVoDKSkswK+smOXgVD2bGZIGEkSaZPipzB98jpzn5P5EA6iv0dNhtYAyGj34sbUl/sz+v9hjZO5JkiWrsjYcQwpFNZ0lhMGEmSCn+OvG6nAiFDx5u77B4OMCb9p2n6dgigOpJeAjHTNM2dAZ1oy55pgVTW0hW0/p8tPxPCSJI4nQ5VTYicIO/wqU6bRwOMTSjmRSzP45LDEfk/fSPpZeAUAFM1qaE1ZqFDUzuVEYyzGdGpmoMxa/uBdBRbGXE5Hcr1RJpYuzlZXlrpHRhGaGJNCbGrLpuojGC8TZuUJ6lv2RaQrsyeEZfTIYejL4xQGUkvsatpJOkYU8gpwewZkaQTWbKihjCSRGZl5BCVEaQ5K4xE52dyCCNpaWDDcXt3MM49kUytMT0jVEYw7qZTGUGGMMOIM/oMkuuNhhE2PksrgQEr+9p7CCN2MwyjX88IlRGMu+lWZaSTJXRIa2YYcUfTiNUzQmUkrQSCAyojhBHb9QTD/Xp5smXjM8JIEk0pzpXL6VBXIJQ1y7WQmcwGVmd0FQ09I+kpGI686PmjG9e1Mk1ju4GnDMmW1wrCSBJ53U5NKY4s7z3IVA3SmHnGXrcr8hSSwzRNWjL3GZmYH9khur2b01XYrXVAGGFpLxKir2+EJlakr6DZMxJtYM31RJ5KqIykF7OBdYIZRpimsZ25kqYwupng6c7erNjZmDCSZDSxIhP0Le2NfEzPSHoyl/ZOiJ7Is41pGtuZ0zTTJuXJ5XREtoTvyPzqCGEkyaZPZOMzpL8zGliZpklLVmUkGkY6e0OcO8tm5rLeCXlea/osG/pGCCNJZlZG2BIe6cxqYI0+g7DPSHoKWJURj3UdUzX2MisjRbkeTS7wScqO5b2EkSSbURKtjDRRGUH6CsdZ2ksYSS9mZSTP55bPHflZttHEaiuzgdWf61ZJYSSMZMPGZ4SRJJs2MVIZae0OqjlLTg2NzNPXwBr5mJ6R9GQu7fU4HSqMLu+lMmIvs4HVn+PRpOg0DT0jGHc5HpfK/TmSWN6L9BWOOTeNRM9IuuoNRn6OHrdTBdHVG2wJb68WqzJCGEGCsbwX6S5ohZHoPiNM06QlszLidjpUmBPpG2FFjb3MBlZ/rkcTCyJhJBv2GiGM2IDlvUh3ZgPrwKW9XYHM3w8hk5g9I96Yykgb0zS2im1g7auMZH7PiNvuAWQj8xw1LO9FugoPOGuvOU3TzTRNWjFX07idThXkME2TCvp6RtzKi4b8bJimIYzYgMoI0l1wYM8I0zRpKRitjHhcfQ2srKaxV2xlxNzxJRumaQgjNpgRc/ZeIB0NbGClZyQ9mZURj8tpbT/Oahp7mUt7C3M88rgif1/ZUBkZVc/IAw88oBkzZignJ0fLli3TG2+8Efe+69evl8Ph6HfJyckZ9YAzgVkZaWrvyYpfMmSeMyojrKZJSwGrMtI3TUMDq726o31X+T6XJkU3PesKhNTZm9k/lxGHkSeeeEJr1qzRPffco23btmnRokVasWKFGhsb4z7G7/errq7Ouhw6dGhMg053hTkenTM5Uh1560izvYMBRiFsDD5Nwz4j6cUMI24Xq2lSgWEY6jWbil1O5Xtd8kY3ozuZ4VM1Iw4j3//+93Xbbbfplltu0bx58/Tggw8qLy9PjzzySNzHOBwOlZeXW5eysrIxDToTLKmaIEnafvi0zSMBRi50xll7maZJR2aFy+Ny9O0z0kPPiF16Y87O63E75XA4VJIle42MKIz09vZq69atWr58ed8ncDq1fPly1dbWxn1ce3u7pk+frqqqKl1zzTXavXv3kF+np6dHra2t/S6ZZvG0YknSdiojSENBazv4aM+IN/JU0hUIyTA40Vq66A32TdOwA6v9zJ+HFKmMSLL2GiGMxGhqalIoFDqjslFWVqb6+vpBHzNnzhw98sgjevrpp/Xzn/9c4XBYl1xyiY4ePRr366xbt05FRUXWpaqqaiTDTAtLqoolSTuONFvNgEC6OGMH1mhlxDD65ryR+oIx5xgqpGfEdoOGkfzo+Wky/GR5Cd/0rKamRjfeeKMWL16syy67TL/+9a81efJk/eQnP4n7mLVr16qlpcW6HDlyJNHDTLq55YXK8TjV1h3UB5w0D2kmNKBnJN/rVnTGhnfWaaRv0zOHCnyRnhH2GbFP3+omh5zRvy2maQZRUlIil8ulhoaGftc3NDSovLx8WJ/D4/FoyZIl2rdvX9z7+Hw++f3+fpdM43Y5tXBKkaRIdQRIJ6EBlRGn06ECL2X+dBOM3fSMHVhtZ1ZGzKqIJE0kjJzJ6/Vq6dKl2rhxo3VdOBzWxo0bVVNTM6zPEQqFtHPnTlVUVIxspBloybRIE+uOIzSxIr0MbGCVxA6eaag3dGbPCJue2ac3FGkA97hjwkiWnJ9mxJuerVmzRjfddJMuuOACXXTRRbr//vvV0dGhW265RZJ04403asqUKVq3bp0k6Tvf+Y4uvvhizZo1S83Nzfre976nQ4cO6XOf+9z4fidpaH5lpOLzfn27zSMBRiY0oIFVUsw7a17M0sVgO7B2B8IKhMLyuDh1WbL1DFIZKYn2jGT6+WlGHEauu+46nThxQnfffbfq6+u1ePFiPffcc1ZT6+HDh+V09h3I06dP67bbblN9fb0mTJigpUuX6rXXXtO8efPG77tIUzMnF0iS3m9sk2EYcsS8ywRSmVUZcVIZSWexO7Dm+/peDjp6girO89o1rKxlTdO4s2+aZlTbwd9+++26/fbbB71t06ZN/T6+7777dN99943my2S8mZML5HBIzZ0BnezoVUl0tz0g1ZkNrINWRggjaSN20zOPy6kcj1PdgbDaugkjdhg0jGTJNA11OBvlel2qmhDZGn5vA1M1SB+hUP8GVknsU5GGzKW95rSAP7oLq3myNiSXWakabJrmZIZP0xBGbDa7NDJVs+8EYQTpw6yM9Gtg5URraSUcNvp6f6IvfhOi1ZDTnZn9LjxVmQ2ssZWRSdHKSHcgrI4M/tsijNhsVlk0jDS02TwSYPgGb2Dl3CbpJBDu22DLHT07bHFe5Gd4upPKiB0GW9qb73MrL3oiyhNtmVsdIYzYbHZpoSRpbyOVEaSPwRpY+6ZpeCFLB+aUgBS722fkXXgzlRFb9AzSMyJJkwszfxdWwojNZkWnaQgjSCfWDqyOQcIIlZG0EIw5KZtZ4TKbVk93ECjtMFgDqyRrcQOVESSMGUZOtPXwbgRpw2pgddEzkq7MDc8cjr5G5AnWNA3PRXYwfybeAXu8TC6gMoIEK/C5VVmUI0naR3UEaWKwykgBJ1pLK+ZW8B6n09rjyGxg5Y2RPQLxKiOFkZ8LlREk1Kwy+kaQXobcgZUwkhYCMbuvmmhgtVf8ykjkDesJKiNIJGt5L2EEaWLoBlbCSDowG1jdMS98VEbsFbdnxKqMZO7PhTCSAmbTxIo0Ex5smsY8BT1hJC0EYk6SZ5qQT2XETvHCiNkzQmUECTWbvUaQZoKDNLCymia9WD0j/aZp2PTMTj3xpmnMpb30jCCRZk2O9Iwcb+nm9N1IC0M1sPaGwuoJhmwZF4avd7DKSDSMtHUHrcoJkicQjG4HH29pb3uPDMM443GZgDCSAoryPFby3X+iw+bRAGcXDp95bpp8b995N6mOpL5gzEnyTEW5Hpn5spmpmqQzt4P3xKmM9AbDasvQaVDCSIqw+kaYqkEaCA4SRlxOh/Kj21bTN5L6zJ+hx9n3MuByOqyT5dHEmnzxekZyPC4VRlerZeryXsJIimBFDdKJ1cAaE0Yk9hpJJ9Y0jbv/z3ACy3ttY4YRn/vMl+ZM7xshjKQIc68RwgjSgdXAOjCMsNdI2jB/hm5n/5cBmljtY+0zMkgYKSnM7BU1hJEUYVZGdh5rsebjgVQ12NJeSSrIYXlvugjEWblhVkaYpkm+wc7aa5qc4eenIYykiMVVxSrwudXY1qPtR5rtHg4wpNAgPSOSrHltztyb+gKDNLBKfStqmKZJvl5rufUQ0zRURpBIOR6XrjivVJL07M46m0cDDG2wBlaJvUbSSSDOCx/TNPbpjS6JH2yaxgwjDa2EESTYny2skCT9fmddxq4lR2aI28Bq9owwTZPygoOcm0aKmabpoDKSbPFW00hSuT9yfpq6lq6kjilZCCMp5LJzJyvf69Lxlm7tYKoGKSxuAyuVkbQx2HbwklScT2XELkM1sFYUR8NIc3dSx5QshJEUEpmqKZMkPber3ubRAPHFa2Dt6xkhjKS6wU6UJ0kTmaaxjbW0d5CekcqiXEnS8ZaujKycE0ZSzIr55ZKkDe802DwSIL7Bztor9VVGWrso8ae6QJxpGrM3IVNXbaQyM4x4BpumKYpURroD4YzcHZcwkmIumzNZXpdTHzR1sOcIUpYZRtwDwsjE/MgL2ckO3lWnusF2YJWkMn/kZ1jf2p2R78BTmVmtGmxpb47HpUnRKbTjGdg3QhhJMQU+t2pmTpJEdQSpyzxR3sDKSElB5MmSd9WpL97S3jJ/3zvw1i6m25KpZ4gGVimz+0YIIynoE/MifSMb3qFvBKmpb/fOwUv8Te1URlJdvAbWHI9LxdEVNQ1tmfeil8qGWtorSRXRvpFMXFFDGElBZhjZfqRZjTwZIAXFa2A1d4k81dFjTeUgNQWtfUYcZ9xWVhh5B17fwvNPMvXG2RXXVBntGzmegT8XwkgKKvPnaNHUIhmGtPHdRruHA5whXgPrxHyvHA4pbEin6BtJab1xKiOSVBZ90WtozbwXvVQ21D4jklRRHK2MNFMZQZL0TdXQN4LUE6+B1e1yWktDM3Xb6kwRjLO0V5LKrN0+CSPJEgobMouJ8SojFVRGkGyfmBdZ4vvKviZ1sGcDUky8BlZJKinI7HNoZIq+E+Wd+TM0l5HWE0aSxqyKSPErI5XF9Iwgyc4tK9C0iXnqDYb18t4Tdg8H6Cccfd4cWBmR2KciXcTb9EzqW1GTqedBSUXDCSNmZaS+pTvjzu5OGElRDofDmqr53U5W1SC1BKNpxOkYrDLCNE06iLeaRooNI1RGkqUnFFlJ43AMHvKlyM/F4YgEyaaOzPr7IoyksGsWV0qKnMX3yKlO63o2IoLdQnHO2itRGUkXZqAcbDWNeVI2VtMkj7X7qsspxyAh37zNXOl09HRmTdUQRlLY+VOL9ZHZJQqFDT344n5JkTP6zvnmc/rtW8dtHh2yWUdP5F1cvtd9xm19PSOspkllvUFzae9gq2n6+n7Ms/sisYY6L02s6pJ8SdIHJzoSPqZkIoykuC9/fLYk6cktR3W8uUvf3/C+ekNh/XLLEZtHhmwVCIXVFYiEkcKcocIIlZFUZlZGBpsSmJTvk8vpUNggVCaLtRV8nH4R06zSAknKuNOFEEZS3EXVE7WseqJ6Q2Hd8tM3tTf6C7j10GlrzhdIptjVXQWDhBGmadLDUD0jLqdDpYV956hB4p1tjxHTzMmRyghhBEl3z9Xz5XI6tKehzbquszekncdabBwVslVbdySM5Hicg76QURlJD4FQ/GkaSSqliTWpekNDbwVvmlVaKEn64ARhBEk2r9KvWz9cbX08O1qme/2Dk3YNCVmstTty+vLCHM+gt5cURlbTnOroZUv4FNZXGRm8WdLcejzTGiVTVU8wfqUqljlNc+hUZ7/lwOmOMJIm7lw+W1fMLdXNl8zQ9RdNkyRt/uCUzaNCNmqPVkYG6xeRIv0GzuiW8CczbPlhJmntGjpUzpwcedHbn2HvwFOVNU1zljBS5vepwOdWKGzo4MnMaWId/NkEKSfP69b/u/lCSdLu45HpmS0HT6k3GD5rWQ8YT+Y0TaFv8KcPl9OhifleNbX3qqmtV6XRpYhILS3RMGKeoXegmaWR3oT9GdabkKqG2zPicDg0c3K+3jraov2N7Tq3rDAZw0s4XsXS0Hnlfk3M96qjN6S/+X+baRREUrX3mJWRwV/EJFkB5HgGntArExiGYYWRotzBf46zJkde5KiMJMdwV9NI0swMXFFDGElDTqdD//qZ85XvdWnzgVNa/Yttdg8JWaQt2jNSEKcyIsU8WfJClpI6e0PWi1+8ysg50VUbTe29au5keW+imQ2svuGEkcmZ9/dFGElTH59bpqdWXyqvy6k3Dp7S9sOn7R4SskTrWXpGJOncaBh5P2YFGFKHWRXxuBzK9bgGvU++z201sVIdSbzeYTawSn1NrO83ZM7PhTCSxmaXFerqRZEt4x959aC9g0HWGM40zeyyzCsjZ5LmTnOKxht363Gpr8K1vzFzGiVT1XAbWCVpwZQiSZGw39UbSui4koUwkuZuuXSGpMj5a5ifRzJY0zRDVEZmR5vq9ja0Z9zZRTNBc1dk2qUod+g1DJk4HZCqeobZwCpFll2X+X0KhQ29fbQ5wSNLDsJImlswpUjLqicqFDZ0+6Pb1B1Ir5T82r4mfe8P72VMus8G5moa/xBhZPrEPHldTnUFQjpGSE45rdZKGu+Q9+urjBBGEm0kDawOh0NLqiZIkrYfaU7ksJKGMJIB/vcnF8if49a2w8264/HtabXR1D/+9h098MJ+/eD5vXYPBcN0tn1GJMntcloNkHsb6RtJNX3TNPGn2iRpFpWRpBnu0l7Th6YXS5K2HcqMfkHCSAaYVVqoh2+6UF6XU3/Y3aDv/Ha3DCP1A0kobOhAU2Qu+uGXP9DPXz+kb//3bu1NYNPjO8dbrWkGjI5ZGSnwneWFLPquem8GNdllCmuPkbOFkejP8MipTv5uEszaDn4YPSOStGRaX2UkHZ7vz4YwkiEuqp6o+65bLEn6j9pDWv3otmGtsOkOhGyrpBxv7lJvdEvqQMjQN5/apfWvHdRf/PBV/Wb7UUnSpj2N+spj260nz7HYeuiU/uwHL+vrv9455s+Vzfq2gx+638DcjCmTOv4zRbO5x0icZb2myYU+TZuYp7AhbTmYGe/AU9VIKyMLpxTJ7XToRFtPRmzZTxjJIKvOr9Ddfz5PkvTsznp98kev6eGXP4h7/32Nbfrw/3lBq37w8llf7BPRi/JBtCpSUuBTcZ5Hk/K9WjS1SF2BkNb88i29daRZf/9fb+u/3zquJ7ccGfPX2xotZ7605wRNlWPQt5rmbGGE5b2p6mwbnsWqOWeSJM6FlWidvcPfZ0SScjwuzav0S5K2ZcDWDoSRDPO3H67WM1/+sP4iuuT3n373rv71D3vOKOO1dAZ028+2qqm9R+/Vt+muX74V9wX61X1Nmnf3c7rrl28pGBq/EzMdiM5Df2hasV5fe4U2f+MK/fpLl+rKeWUyDOl//udWNUZ3l918YOzn4Tl4slOS1NYTZN+EMWgbRs+I1Lf88J26Vp3u6NWzO+v001cPpFVPU6Zq6RzeNI0kXTxzoiSpljCSUOaUddXEvGE/Zll15Gfz/HuNCRlTMhFGMtCCKUX6t88u1t9fNUeS9MMX9umbT+3q9yLw9V+/rQNNHSr358jrcupP7zZo/WsHB/18T20/prAh/WrbUd3x+A7rbJ9jZf7xVU/OV47HJbfLKZfToa9+4lxJUn3MqcvfPHhqzNWMg019eyVsP9w8ps+VrQzDGNY+I5I0dUKezqvwKxQ29IvNh/Tlx7brH3/7jr74862snrJZyzCnaSTp4mhlZNexFmuKDuPPnM4cyblmrlpQIUna+G5j2q2kHIgwkqEcDoe+dPks/e9PLpDDIf1i82H95U9qta+xTS++f0K/31Uvl9Ohh2+6QN/68/MkSff96X2d6ui/7bNhGHp1X5P18e921ulLv9imnuDYf/EPRCsV1ZPy+11/XoVfV8wtlRRp5sr1uNTcGdD7Y1yVcSj69aTMWQ6XbF0xPUZnq4xI0pXzyiRJ9/9pr/W4P77ToG8+tStxg8RZmfuMFOcOvbRXkiqKcjVjUqRv5M1xqFDiTKc7etXUHqkCm03Dw7GkqlgVRTlq7wnqpfdPJGp4SUEYyXA3LJuuH17/IeV7Xdp66LRW3P+y7nh8uyTpppoZWjClSH+1bLrmVfjV1h3UDzb2X2J7oKlDx1u65XU79eBfL5XX7dSGdxr05Ue3j7mD+0BT5J1AdUn+Gbd99RPnyp/j1i0fnqELZkS6xjd/MPonwu5ASMdb+pq82D5/dMwpGpcz/jbisa6cHwkjwWgQualmuiTpmbePszrDRubSXv8wpmkkqWZmpDry8t6ms9wTo7E3uo/LlOLcIc/5NJDT6dDKaHXk2Z11CRlbshBGssCq8yv0xzWXafl5pQqFDTV3BlRS4NWdn5gtKfLC8s1VkerIf75+SD95cb81JfLq/sg88dJpE3TVgnL99OYL5XU79cd3Gsa0BX1PMKRj0Q7w6slnhpEFU4r09rdXaO3K86x50c0HRj9nffR0pwwjci4OKdJU2RGdbsDw9S3rdQ+5jbhpXoVfU4pzJUV2jfzWn8/TOZPz1RMM64+7GxI6VsRnLe0dxjSNJC0/LxIqf73tKH83CWA2eZunURiJVeeXS5L+9G6jNYWajggjWWJKca4evulCPb36Ut18yQz95G+Wyh8z53/JrBJ99sIqhcKG1v3+PX3s3k1a9+y7+u1bxyVJH55dIkm6dFaJvhUNLv/y+3f1328dH1WF5MipToUNKd/r0uQC35D3XRads35130mrlDlSB5oiUzTnlhWqsihHYYPVAaPRNsxlvSaHw6FPf2iKJOm2j54jt8upaxZFPn46+ruF5AqFDStUDmc1jSR9bE6pZkzKU2t3UL/adjSRw8tK5t5KI+kXMS2pmqBzJuervSeoR145MN5DSxrCSJZZVFWsb//FfC2dPvGM29Z9aqH+z6cXKt/r0qGTnfrJSx/ojegc8aWzSqz7/fXF07VifpkCIUNfeWy7Pn7vi/rKY9v1wAv7tOGdBh0+2XnWZlPzBGrVk/PP+g57cVWxzpmcr5augL70i22jaqA9dDLSvDqjJF+XzZksSfraf73NidxGKLYyMlxfuWK2nv3KR3TzJTMkSdcsjqz0enVfkxrbuod4JBKhNWYZ/3DDiNPp0N9+uFqS9NNXD7I0fpyZzauzR9AvYnI6Hfrq8kjT//996QOdHtD3ly6G/4yCjOdwOHTdhdP05+dXatOeE3pud72ef7dBM0rytSC6nt283799dokefHG/HnrpAx1o6oisjHmr73PlelyaXVagMn+OJuV7NanAq0n5Pk0qiJwl9Du/3S1Jml9RdNZxeVxOPfQ3S3XtA6/pjQOndMPDm/Wda+ZrTlnhsKYKJOmgGUYm5emLl8/S7uOtevtoiz77UK3+9TOLdPmc0hEcqexlloH9Z1lJE8vtclr7IUiRQLi4qlg7jjRrzRNv6ZHo1B+Sw9zwLN/rGtbp6k3/Y+lU/esf9uhAU4e+v+F9/d2KOYkaYtYxe0Zmj6IyIkmrFlboR5v26926Vv3T797V9/7H+XI6h/fcmCoIIzhDvs+tVedXaNX5FQqHjUF/qXM8Lt25/FzdfMkMbTt8Wnvq2/V+Q5v21LdpX2O7ugIhvX20RVJL3K8zr8Kvu1acO6wxzSot1L9fv0Rf+sU2vXHglK66/2WVFPh0/tQiza/0q8yfo8mFPpUU+DQhz6OiXI/8uR7ryfZgdJpm+qR8FfjcWn/LRbrh4c16t65VN//0TX14VolWzC/Th6ZPUHVJvvK8/GkMZqTTNPH807UL9Jc/qdUr+5p028+26CtXzNbiqmK50uwJNB21DPMkeQPled26++r5+rsn39IPX9inXK9Ln/tItXzuszcyI763jjRb08+jqYxIkerIN/5srm585A39attRuZ0O3X31POWPoIJpN4eRBpvat7a2qqioSC0tLfL7/Wd/AGwVDIV18GSn9p9oV1N7j0629+pke4+aOnp1qr1XLV0Bzav0656r5511r4qBjp7u1Hd++442vtc4rM2z8r0uFeS4dbK9V8GwoV/+zxpdFG2I7Q6E9M/Pvquf1R4643G5Hle0muPVxHyv8rxueVwOed3OyMXlksftkM/ltK7zmP+P/huMnoUzz+tSrtelXI9LTqdDDkmRgo5DDoeiH/dd74herwEf9/v/SD/HILdFHz7gc/a/n6yvG7ntP147qO/9YY+uWVypf/vskhH97AZ68f0TunX9m9ZKG5/bqeqSfM0qLVC5P0fFeR4V5XlVnOtRcZ5HxbleFea45XI65HY55HI65HE65XI55HZGPnY7nXJGv18MbtOeRt380zc1r8KvZ+/4yIgf//0N71ur7iYX+lRzziTNnFygSQVelRR4NTFaAS3wueV1OeWJ/k14XI6s+bmEwoYOn+rUyfYeneroVXNnQN3BkHqDYQVChk629+jwqU4dPtWp9+oj/SILpxTpt1/+8Ji+7m+2H41sYGlEzqq9Yn65zqvwa8qEXJX7c1RelKMCn1s5HlfSgv9wX78JI0hL3YGQ3qlr1dtHmrWnoV0n2nrU1B65tHQG1DZIV3lRrkcv/8PHzphiOHSyQ8+8XafX9jfp7SMtgz4W/f31xdP0T9cuHPPn2X28RY+8clDP7qxT1zhu2tQXThxyu5zK8Tjlc7vkdTsVDhsKGYZCYcMKXWaAcTgkZzSQOR0OK8g5HZHpQp/bKUORF5tg2JDO8vQ5nCfX4TwDG8P4TMN9Jm/uDOhYc5dqzpmkxz5/8fAe1O/rGPr55sP60Qv7VNcysp4fb7/w7rDCu3ls+8J6389AMeHbIYeczoFh27xv/zAt6+caJ9D3C96xX8vR7zpDhgwj8rMMR/9j/t8wIr9r+T63gmFDrd0BHW/u0vv1beoYwcZ+Vy+q1D9cNUdTJwx/99V4/ri7Xv/87LvWjtPxeFwO5bhd8nlc0b8Pp/7ts0usnZPHC2EEWS0YCqutO6jmroDau4NyOiM7gp6tYc8wDHX0hnSyvUcnO3p1sr1Xpzp61B0IqzcYVm9owL/RSyAUVk+o/8dul1OGYairN6TO3pC6AiEZRuRlJfKcFn2SM/q+9hm3ybw99uPIA6z7Rh+nmNsH+zw64/MaMZ9/+Ap8bv3g+sX6+NyykT1wCKGwoWOnu7TvRJv2N3aoqSMSKk93Rt5VtnQF1NwZUHtPUMFwWKGwoUAo5Z+6UtrfXlqtu6+eN+rH9wRDev2DU9p1rEVHT3eqqb1XpzoiVdCT7b3qtPEknKkgx+NUaWGOJuR7NSHPo/xoddXjcqoo16Npk/JUNSFPs8sKxiWExAqHDb2094S2HTqtPQ1tqm/pVkNrjxrbujXUj+Tp1ZdqUVXxuI6FMAJgRAxj8KBiBhhJVqUhVYSjFYpIpSJsVSysf0OGekNhdQdC6okGRZfTIZcz+k5Yij45GzILHWHDsN4Bh6PffyhsKBgy1B0MyemIVF1cjsi79LOJvP8+653G4y6R+51lKsR8J79wSlHCS/WR0Bi2jn1gYJgP9b8+FDb6BXDzZ3JGiB4Q5sP9AvlZHhfzux02g33MfcP9PrdhHU+rUhbzfymyoV9nT1Bul1P5Prcqi3J0zuQCzSotSLkeqHA48jvcEwirOxhSdyDytxG5hLVwatGIVsoNx3Bfv9OnuwVAQjlinmCH/9JnL6fTIa/1hE8jZaqJBD+XcoaxWy8Sz+l0KM/r1gh7l5Midd7iAACArEQYAQAAtiKMAAAAW40qjDzwwAOaMWOGcnJytGzZMr3xxhtD3v/JJ5/U3LlzlZOTo4ULF+rZZ58d1WABAEDmGXEYeeKJJ7RmzRrdc8892rZtmxYtWqQVK1aosbFx0Pu/9tpruv7663Xrrbdq+/btuvbaa3Xttddq165dYx48AABIfyNe2rts2TJdeOGF+uEPfyhJCofDqqqq0pe//GV9/etfP+P+1113nTo6OvTMM89Y11188cVavHixHnzwwWF9TZb2AgCQfob7+j2iykhvb6+2bt2q5cuX930Cp1PLly9XbW3toI+pra3td39JWrFiRdz7AwCA7DKifUaampoUCoVUVtZ/58WysjK99957gz6mvr5+0PvX19fH/To9PT3q6emxPm5tbR3JMAEAQBpJydU069atU1FRkXWpqqqye0gAACBBRhRGSkpK5HK51NDQ0O/6hoYGlZeXD/qY8vLyEd1fktauXauWlhbrcuTIkZEMEwAApJERhRGv16ulS5dq48aN1nXhcFgbN25UTU3NoI+pqanpd39J2rBhQ9z7S5LP55Pf7+93AQAAmWnE56ZZs2aNbrrpJl1wwQW66KKLdP/996ujo0O33HKLJOnGG2/UlClTtG7dOknSHXfcocsuu0z33nuvVq1apccff1xbtmzRQw89NL7fCQAASEsjDiPXXXedTpw4obvvvlv19fVavHixnnvuOatJ9fDhw3LGnMrykksu0aOPPqpvfvOb+sY3vqHZs2frqaee0oIFC8bvuwAAAGlrxPuM2KGlpUXFxcU6cuQIUzYAAKSJ1tZWVVVVqbm5WUVFRXHvN+LKiB3a2tokiVU1AACkoba2tiHDSFpURsLhsI4fP67CwkI5HI5x+7xmYqPiMnocw7HjGI4dx3DsOIZjw/EbnGEYamtrU2VlZb8WjoHSojLidDo1derUhH1+VuyMHcdw7DiGY8cxHDuO4dhw/M40VEXElJKbngEAgOxBGAEAALbK6jDi8/l0zz33yOfz2T2UtMUxHDuO4dhxDMeOYzg2HL+xSYsGVgAAkLmyujICAADsRxgBAAC2IowAAABbEUYAAICtsjqMPPDAA5oxY4ZycnK0bNkyvfHGG3YPKSV9+9vflsPh6HeZO3eudXt3d7dWr16tSZMmqaCgQJ/+9KfV0NBg44jt99JLL+nqq69WZWWlHA6HnnrqqX63G4ahu+++WxUVFcrNzdXy5cu1d+/efvc5deqUbrjhBvn9fhUXF+vWW29Ve3t7Er8Le53tGN58881n/F5eddVV/e6Tzcdw3bp1uvDCC1VYWKjS0lJde+212rNnT7/7DOdv9/Dhw1q1apXy8vJUWlqqr33tawoGg8n8VmwznGN4+eWXn/F7+IUvfKHffbL5GA5X1oaRJ554QmvWrNE999yjbdu2adGiRVqxYoUaGxvtHlpKmj9/vurq6qzLK6+8Yt321a9+Vb/97W/15JNP6sUXX9Tx48f1qU99ysbR2q+jo0OLFi3SAw88MOjt3/3ud/WDH/xADz74oDZv3qz8/HytWLFC3d3d1n1uuOEG7d69Wxs2bNAzzzyjl156SZ///OeT9S3Y7mzHUJKuuuqqfr+Xjz32WL/bs/kYvvjii1q9erVef/11bdiwQYFAQFdeeaU6Ojqs+5ztbzcUCmnVqlXq7e3Va6+9pv/4j//Q+vXrdffdd9vxLSXdcI6hJN122239fg+/+93vWrdl+zEcNiNLXXTRRcbq1autj0OhkFFZWWmsW7fOxlGlpnvuucdYtGjRoLc1NzcbHo/HePLJJ63r3n33XUOSUVtbm6QRpjZJxm9+8xvr43A4bJSXlxvf+973rOuam5sNn89nPPbYY4ZhGMY777xjSDLefPNN6z6///3vDYfDYRw7dixpY08VA4+hYRjGTTfdZFxzzTVxH8Mx7K+xsdGQZLz44ouGYQzvb/fZZ581nE6nUV9fb93nxz/+seH3+42enp7kfgMpYOAxNAzDuOyyy4w77rgj7mM4hsOTlZWR3t5ebd26VcuXL7euczqdWr58uWpra20cWerau3evKisrdc455+iGG27Q4cOHJUlbt25VIBDodyznzp2radOmcSzjOHDggOrr6/sds6KiIi1btsw6ZrW1tSouLtYFF1xg3Wf58uVyOp3avHlz0secqjZt2qTS0lLNmTNHX/ziF3Xy5EnrNo5hfy0tLZKkiRMnShre325tba0WLlyosrIy6z4rVqxQa2urdu/encTRp4aBx9D0i1/8QiUlJVqwYIHWrl2rzs5O6zaO4fCkxYnyxltTU5NCoVC/Xw5JKisr03vvvWfTqFLXsmXLtH79es2ZM0d1dXX6x3/8R33kIx/Rrl27VF9fL6/Xq+Li4n6PKSsrU319vT0DTnHmcRns98+8rb6+XqWlpf1ud7vdmjhxIsc16qqrrtKnPvUpVVdXa//+/frGN76hlStXqra2Vi6Xi2MYIxwO684779Sll16qBQsWSNKw/nbr6+sH/T01b8smgx1DSfqrv/orTZ8+XZWVlXr77bf1D//wD9qzZ49+/etfS+IYDldWhhGMzMqVK63/n3/++Vq2bJmmT5+uX/7yl8rNzbVxZMhmn/3sZ63/L1y4UOeff75mzpypTZs26YorrrBxZKln9erV2rVrV79eL4xMvGMY24O0cOFCVVRU6IorrtD+/fs1c+bMZA8zbWXlNE1JSYlcLtcZXeMNDQ0qLy+3aVTpo7i4WOeee6727dun8vJy9fb2qrm5ud99OJbxmcdlqN+/8vLyM5qpg8GgTp06xXGN45xzzlFJSYn27dsniWNouv322/XMM8/ohRde0NSpU63rh/O3W15ePujvqXlbtoh3DAezbNkySer3e8gxPLusDCNer1dLly7Vxo0brevC4bA2btyompoaG0eWHtrb27V//35VVFRo6dKl8ng8/Y7lnj17dPjwYY5lHNXV1SovL+93zFpbW7V582brmNXU1Ki5uVlbt2617vP8888rHA5bT3bo7+jRozp58qQqKiokcQwNw9Dtt9+u3/zmN3r++edVXV3d7/bh/O3W1NRo586d/ULdhg0b5Pf7NW/evOR8IzY62zEczI4dOySp3+9hNh/DYbO7g9Yujz/+uOHz+Yz169cb77zzjvH5z3/eKC4u7tfxjIi77rrL2LRpk3HgwAHj1VdfNZYvX26UlJQYjY2NhmEYxhe+8AVj2rRpxvPPP29s2bLFqKmpMWpqamwetb3a2tqM7du3G9u3bzckGd///veN7du3G4cOHTIMwzD+5V/+xSguLjaefvpp4+233zauueYao7q62ujq6rI+x1VXXWUsWbLE2Lx5s/HKK68Ys2fPNq6//nq7vqWkG+oYtrW1GX/3d39n1NbWGgcOHDD+9Kc/GR/60IeM2bNnG93d3dbnyOZj+MUvftEoKioyNm3aZNTV1VmXzs5O6z5n+9sNBoPGggULjCuvvNLYsWOH8dxzzxmTJ0821q5da8e3lHRnO4b79u0zvvOd7xhbtmwxDhw4YDz99NPGOeecY3z0ox+1Pke2H8PhytowYhiG8e///u/GtGnTDK/Xa1x00UXG66+/bveQUtJ1111nVFRUGF6v15gyZYpx3XXXGfv27bNu7+rqMr70pS8ZEyZMMPLy8oxPfvKTRl1dnY0jtt8LL7xgSDrjctNNNxmGEVne+61vfcsoKyszfD6fccUVVxh79uzp9zlOnjxpXH/99UZBQYHh9/uNW265xWhra7Phu7HHUMews7PTuPLKK43JkycbHo/HmD59unHbbbed8WYim4/hYMdOkvHTn/7Uus9w/nYPHjxorFy50sjNzTVKSkqMu+66ywgEAkn+buxxtmN4+PBh46Mf/agxceJEw+fzGbNmzTK+9rWvGS0tLf0+TzYfw+FyGIZhJK8OAwAA0F9W9owAAIDUQRgBAAC2IowAAABbEUYAAICtCCMAAMBWhBEAAGArwggAALAVYQQAANiKMAIAAGxFGAEAALYijAAAAFsRRgAAgK3+P8MiB9ihaeVQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C4V11ilitjZI",
        "outputId": "52b26b6f-b48c-4a1b-cb0c-e594f3ed1ebe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./RNN_checkpoints/ckpt_280'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWrc98bbtjZJ"
      },
      "source": [
        "# Востановим модель из кеша."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jGbO66T5tjZJ"
      },
      "outputs": [],
      "source": [
        "model = RNNgenerator(vocab_size, embedding_dim, rnn_units)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-5zpWvtjZJ"
      },
      "source": [
        "## Генерация текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DJRTPk-AtjZJ"
      },
      "outputs": [],
      "source": [
        "# Number of characters to generate\n",
        "num_generate = 500\n",
        "\n",
        "# Low temperature results in more predictable text.\n",
        "# Higher temperature results in more surprising text.\n",
        "# Experiment to find the best setting.\n",
        "temperature = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gycS6379tjZK"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fuZ18syNtjZK",
        "outputId": "c969bafc-6491-4051-bbfe-dc91c650d010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "И вот идет уже вим Ненануташи    каны     бы,\n",
            "        Таму,\n",
            "     Так    борискатларысаточь     Додя     чалиту  найни         х         н?\n",
            "   о)\n",
            "    мушей          ез вз нанысими,\n",
            "           Ме\n",
            "       пи  нелалихочнаснилесь       Нобумравени    Пой,\n",
            "               зи               В   Таю\n",
            "           ном    Момныл плужный           ск,\n",
            "                             Изони   Алей         А,               буши                 каланый,\n",
            "     тал,\n",
            "            Еща     ны,\n",
            " Ещед,\n",
            "         ду кох\n",
            "   ужнней     Не Тазныли\n"
          ]
        }
      ],
      "source": [
        "text_ = generate_text(model, start_string=u\"И вот идет уже \")\n",
        "print(text_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhqahY9ptjZK"
      },
      "source": [
        "### На 200-ой эпохе вродебы к-во было не плохим. Посмотрим как пройдет генерация текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dBXQIOjutjZT",
        "outputId": "c4eb526c-cf06-4b5c-8a2d-b1b4c6d2aa61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n"
          ]
        }
      ],
      "source": [
        "model = RNNgenerator(vocab_size, embedding_dim, rnn_units)\n",
        "model.load_weights('./RNN_checkpoints/ckpt_200')\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "48ZiKVHFtjZT",
        "outputId": "d448eb7f-7d97-4333-bd90-d502243e3e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "И вот идет уже в.     У      Я               Тате  коглетый,\n",
            "     ный,\n",
            "           н,            боивогле    м Нево     и       .\n",
            "                          коешный           кари,\n",
            "    ГНетя.   ны,\n",
            "   XVI\n",
            "       даж      XXVаяриж  чт      Го                        ж        Серя          бланет  л           бы     с            Тараритономавей      ко,\n",
            "         коской....\n",
            " му ско    вый,  ветаный,\n",
            "       к ле      ты         сенеть                  бо вы,\n",
            "                  Блый              рх,     прный       си,\n"
          ]
        }
      ],
      "source": [
        "text_ = generate_text(model, start_string=u\"И вот идет уже \")\n",
        "print(text_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiXKoM_7tjZU"
      },
      "source": [
        "# Дальше можно не смотреть.\n",
        "\n",
        "> Хотел проверить, как поведет себя модель с установленным параметром \"return_state=True\".(подсмотрел в методичке по [tensorflow]( https://www.tensorflow.org/text/tutorials/text_generation)). Т.к. модель обучается очень долго, я просто загрузил веса из модели №1. Благо модели отличаются только указанным параметром. Но, результат получился не очень!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgFyIbz0tjZU"
      },
      "source": [
        "# Попробуем обучить модель с сохранением состояния."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NVY-l3P5tjZU"
      },
      "outputs": [],
      "source": [
        "class RNNgenerator_1(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, states=None, return_state=False):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    if states is None:\n",
        "      states = self.gru1.get_initial_state(x)\n",
        "\n",
        "    x, states = self.gru1(x, initial_state=states)\n",
        "    x, states = self.gru2(x, initial_state=states)\n",
        "    x, states = self.gru3(x, initial_state=states)\n",
        "\n",
        "    x = self.dense(x)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Io1JT2XUtjZU"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './RNN_checkpoints'\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath=checkpoint_prefix,\n",
        "                                save_freq=1,\n",
        "                                save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YITZOlAytjZV"
      },
      "outputs": [],
      "source": [
        "model_1 = RNNgenerator_1(\n",
        "                 vocab_size= vocab_size,\n",
        "                 embedding_dim=embedding_dim,\n",
        "                 rnn_units=rnn_units,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iExXOAm-tjZV"
      },
      "outputs": [],
      "source": [
        "model_1.compile(optimizer='adam', loss=loss, metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hbOCb4fgtjZV",
        "outputId": "b2a7b6ae-f8f3-4518-db2b-3aae03641fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc1397544f0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузим веса из чекпоинтов.\n",
        "\n",
        "# model_1.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model_1.load_weights('./RNN_checkpoints/ckpt_200')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B68D2dqTtjZV"
      },
      "source": [
        "## Генерация текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1hkjX-sNtjZV"
      },
      "outputs": [],
      "source": [
        "def generate_text_1(model, start_string, states, temperature):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions, states = model(input_eval, states=states, return_state=True)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SSc7sOjotjZV"
      },
      "outputs": [],
      "source": [
        "num_generate = 500\n",
        "temperature = 0.6\n",
        "states = None\n",
        "next_char = u\"И вот идет уже \"\n",
        "text_generated=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqdCmP0CtjZV"
      },
      "outputs": [],
      "source": [
        "text = generate_text_1(model_1, next_char, states, temperature)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hXTrtjtjZW"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lN7bNQN_tjZW"
      },
      "outputs": [],
      "source": [
        "class RNNgenerator_2(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, states_1=None, states_2=None, states_3=None, return_state=False):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    if states is None:\n",
        "      states_1 = self.gru1.get_initial_state(x)\n",
        "      states_2 = self.gru1.get_initial_state(x)\n",
        "      states_3 = self.gru1.get_initial_state(x)\n",
        "\n",
        "    x, states_1 = self.gru1(x, initial_state=states_1)\n",
        "    x, states_2 = self.gru2(x, initial_state=states_2)\n",
        "    x, states_3 = self.gru3(x, initial_state=states_3)\n",
        "\n",
        "    x = self.dense(x)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states_1, states_2, states_3\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7s7yRb-DtjZW"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './RNN_2_checkpoints'\n",
        "checkpoint_dir = './RNN_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath=checkpoint_prefix,\n",
        "                                save_freq=1,\n",
        "                                save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gc9jU8JjtjZW"
      },
      "outputs": [],
      "source": [
        "model_2 = RNNgenerator_2(\n",
        "                 vocab_size= vocab_size,\n",
        "                 embedding_dim=embedding_dim,\n",
        "                 rnn_units=rnn_units,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RQZFxbKbtjZW"
      },
      "outputs": [],
      "source": [
        "model_2.compile(optimizer='adam', loss=loss, metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUF__22dtjZW"
      },
      "outputs": [],
      "source": [
        "# model_2.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model_2.load_weights('./RNN_checkpoints/ckpt_200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj9LXBY0tjZW"
      },
      "outputs": [],
      "source": [
        "def generate_text_2(model, start_string, states_1, states_2, states_3, temperature):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions, states_1,states_2, states_3 = model(input_eval, states_1=states_1, states_2=states_2, states_3=states_3, return_state=True)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiG4hzs7tjZX"
      },
      "outputs": [],
      "source": [
        "num_generate = 500\n",
        "temperature = .5\n",
        "states_1 = None\n",
        "states_2 = None\n",
        "states_3 = None\n",
        "next_char = u\"И вот идет уже \"\n",
        "text_generated=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeKeVgHFtjZX"
      },
      "outputs": [],
      "source": [
        "text = generate_text_2(model_2, next_char, states_1, states_2, states_3, temperature)\n",
        "print(text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "6b7c3ebca6b5b4a4b8af7b3624595a453b0710866dad47574474daaa4a66fc12"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
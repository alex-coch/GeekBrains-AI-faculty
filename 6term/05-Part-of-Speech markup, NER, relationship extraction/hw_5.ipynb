{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca15cf06",
   "metadata": {
    "id": "ca15cf06"
   },
   "source": [
    "ДЗ № 5 Тема \"POS-tagger и NER\"\n",
    "---\n",
    "\n",
    "**Задание 1**. Написать теггер на данных с русским языком\n",
    "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
    "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "3. сравнить все реализованные методы сделать выводы\n",
    " \n",
    "**Задание 2**. Проверить насколько хорошо работает NER\n",
    "\n",
    "*данные брать из http://www.labinform.ru/pub/named_entities/*\n",
    "\n",
    "1. взять нер из nltk\n",
    "2. проверить deeppavlov\n",
    "3. написать свой нер попробовать разные подходы\n",
    " 1. передаём в сетку токен и его соседей\n",
    " 2. передаём в сетку только токен\n",
    "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00a386",
   "metadata": {
    "id": "3c00a386"
   },
   "source": [
    "https://github.com/guillaumegenthial/tf_ner - Simple and Efficient Tensorflow implementations of NER models with tf.estimator and tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36690fbb",
   "metadata": {
    "id": "36690fbb"
   },
   "source": [
    "# Задание 1\n",
    "\n",
    "## 1. Проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iqUbzl6EDWgE",
   "metadata": {
    "id": "iqUbzl6EDWgE"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e6a5e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:16:32.733659Z",
     "start_time": "2021-08-03T21:16:32.720603Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32e6a5e3",
    "outputId": "453c7e6e-0dd5-454f-fcbe-61a7a5f65c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyconll\n",
      "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyconll\n",
      "Successfully installed pyconll-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1dc7952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:58:34.858761Z",
     "start_time": "2021-08-03T21:58:33.335768Z"
    },
    "id": "c1dc7952"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pyconll\n",
    "import nltk\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1064425",
   "metadata": {
    "id": "a1064425"
   },
   "source": [
    "### Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0eef18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:10:16.509162Z",
     "start_time": "2021-08-03T22:08:16.088092Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0eef18d",
    "outputId": "8ceb4989-a573-453c-d125-53813a6dd853",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-08 11:27:53--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81039282 (77M) [text/plain]\n",
      "Saving to: ‘ru_syntagrus-ud-train.conllu’\n",
      "\n",
      "ru_syntagrus-ud-tra 100%[===================>]  77.28M   205MB/s    in 0.4s    \n",
      "\n",
      "2021-08-08 11:27:56 (205 MB/s) - ‘ru_syntagrus-ud-train.conllu’ saved [81039282/81039282]\n",
      "\n",
      "--2021-08-08 11:27:56--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10902738 (10M) [text/plain]\n",
      "Saving to: ‘ru_syntagrus-ud-dev.conllu’\n",
      "\n",
      "ru_syntagrus-ud-dev 100%[===================>]  10.40M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2021-08-08 11:27:57 (121 MB/s) - ‘ru_syntagrus-ud-dev.conllu’ saved [10902738/10902738]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
    "!wget -O ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49640fc3",
   "metadata": {
    "id": "49640fc3"
   },
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae578fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:35:31.178252Z",
     "start_time": "2021-08-03T21:35:31.047244Z"
    },
    "id": "cae578fb"
   },
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('ru_syntagrus-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "n-vU3knc3EW6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-vU3knc3EW6",
    "outputId": "35c2b148-a5ae-4af5-9566-39811ee10e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анкета NOUN\n",
      ". PUNCT\n",
      "\n",
      "Начальник NOUN\n",
      "областного ADJ\n",
      "управления NOUN\n",
      "связи NOUN\n",
      "Семен PROPN\n",
      "Еремеевич PROPN\n",
      "был AUX\n",
      "человек NOUN\n",
      "простой ADJ\n",
      ", PUNCT\n",
      "приходил VERB\n",
      "на ADP\n",
      "работу NOUN\n",
      "всегда ADV\n",
      "вовремя ADV\n",
      ", PUNCT\n",
      "здоровался VERB\n",
      "с ADP\n",
      "секретаршей NOUN\n",
      "за ADP\n",
      "руку NOUN\n",
      "и CCONJ\n",
      "иногда ADV\n",
      "даже PART\n",
      "писал VERB\n",
      "в ADP\n",
      "стенгазету NOUN\n",
      "заметки NOUN\n",
      "под ADP\n",
      "псевдонимом NOUN\n",
      "\" PUNCT\n",
      "Муха NOUN\n",
      "\" PUNCT\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in full_train[:2]:\n",
    "    for token in sent:\n",
    "        print(token.form, token.upos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3YL77fK6_gly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YL77fK6_gly",
    "outputId": "fe07882f-8be6-48d1-d71e-6a1a89e0e41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая длина предложения 205\n",
      "Наибольшая длина токена 47\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
    "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
    "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
    "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "R-oyn_wB8EiR",
   "metadata": {
    "id": "R-oyn_wB8EiR"
   },
   "outputs": [],
   "source": [
    "# Заполним данными\n",
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JHjsQd738bMI",
   "metadata": {
    "id": "JHjsQd738bMI"
   },
   "source": [
    "### Проверим UnigramTagger, BigramTagger, TrigramTagger и их комбинации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r6jt3RQW8c7g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6jt3RQW8c7g",
    "outputId": "2055c584-9abd-4078-e0df-db48e620475c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Unigram Tagger: 0.877,\n",
      "Bigram Tagger: 0.696,\n",
      "Trigram Tagger: 0.248,\n",
      "Bigram and Unigram Tagger: 0.883,\n",
      "Trigram, Bigram and Unigram Tagger: 0.882,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "unigram_acc = unigram_tagger.evaluate(fdata_test)\n",
    "\n",
    "bigram_tagger = BigramTagger(fdata_train)\n",
    "bigram_acc = bigram_tagger.evaluate(fdata_test)\n",
    "\n",
    "trigram_tagger = TrigramTagger(fdata_train)\n",
    "trigram_acc = trigram_tagger.evaluate(fdata_test)\n",
    "\n",
    "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
    "bigram_unigram_acc = bigram_tagger.evaluate(fdata_test)\n",
    "\n",
    "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
    "trigram_bigram_unigram_acc = trigram_tagger.evaluate(fdata_test)\n",
    "\n",
    "print(f'Accuracy:\\nUnigram Tagger: {round(unigram_acc, 3)},\\nBigram Tagger: {round(bigram_acc, 3)},\\n'\n",
    "      f'Trigram Tagger: {round(trigram_acc, 3)},\\nBigram and Unigram Tagger: {round(bigram_unigram_acc, 3)},\\n'\n",
    "      f'Trigram, Bigram and Unigram Tagger: {round(trigram_bigram_unigram_acc, 3)},\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AUVi7HMfD0mU",
   "metadata": {
    "id": "AUVi7HMfD0mU"
   },
   "source": [
    "## 2. Написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "XVuTWgSEAAFp",
   "metadata": {
    "id": "XVuTWgSEAAFp"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6DxvBMYmFlgU",
   "metadata": {
    "id": "6DxvBMYmFlgU"
   },
   "outputs": [],
   "source": [
    "# Переведём тренировочный датасет в списки слов и списки POS-разметки\n",
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8JjtiMGOaG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef8JjtiMGOaG",
    "outputId": "85b08c35-3ed6-4bb1-f9f0-b98cacd64a35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Анкета',\n",
       "  '.',\n",
       "  'Начальник',\n",
       "  'областного',\n",
       "  'управления',\n",
       "  'связи',\n",
       "  'Семен',\n",
       "  'Еремеевич',\n",
       "  'был',\n",
       "  'человек'],\n",
       " ['NOUN',\n",
       "  'PUNCT',\n",
       "  'NOUN',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'NOUN',\n",
       "  'PROPN',\n",
       "  'PROPN',\n",
       "  'AUX',\n",
       "  'NOUN'])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok[:10], train_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fWGgk4dqHuuK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWGgk4dqHuuK",
    "outputId": "4f81bf72-ef05-4981-861f-d378cf222e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13,  7, ...,  9,  7, 13])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "train_enc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "qHPmdkKSH58O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHPmdkKSH58O",
    "outputId": "7bce60cd-cee4-4a81-87e2-fa35b21f2a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13,  1, ..., 10, 16, 13])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_enc_labels = le.transform(test_label)\n",
    "test_enc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "v_mpkHSOH_EE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_mpkHSOH_EE",
    "outputId": "2f3d8b97-aad9-4866-9aeb-8857087b56b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
       "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
       "       'VERB', 'X'], dtype='<U6')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "htts0ak8ICwd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htts0ak8ICwd",
    "outputId": "b21e6afe-9cf9-421f-c8df-c6e565f285b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> 0.9437872813668992\n",
      "<class 'sklearn.feature_extraction.text.HashingVectorizer'> 0.947140498095912\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'> 0.9487749806221144\n"
     ]
    }
   ],
   "source": [
    "for vectorizer in [CountVectorizer, HashingVectorizer, TfidfVectorizer]:\n",
    "\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    coder = vectorizer(ngram_range=(1, 5), analyzer='char')\n",
    "    \n",
    "\n",
    "    X_train = coder.fit_transform(train_tok)\n",
    "    X_test = coder.transform(test_tok)\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)    \n",
    "    \n",
    "    lr = LogisticRegression(random_state=0, max_iter = 100, n_jobs=7)\n",
    "    lr.fit(X_train, train_enc_labels)\n",
    "\n",
    "    pred = lr.predict(X_test)\n",
    "\n",
    "    print(vectorizer, accuracy_score(test_enc_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WFuCz6mTpgXU",
   "metadata": {
    "id": "WFuCz6mTpgXU"
   },
   "source": [
    "# Задание 2. Проверить насколько хорошо работает NER\n",
    "\n",
    "*данные брать из http://www.labinform.ru/pub/named_entities/*\n",
    "\n",
    "1. взять нер из nltk\n",
    "2. проверить deeppavlov\n",
    "3. написать свой нер попробовать разные подходы\n",
    " 1. передаём в сетку токен и его соседей\n",
    " 2. передаём в сетку только токен\n",
    "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdLzLabypie4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdLzLabypie4",
    "outputId": "1260b3c0-07c7-4162-b29e-d7576eb4bb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting corus\n",
      "  Downloading corus-0.9.0-py3-none-any.whl (83 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |████                            | 10 kB 36.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 20 kB 30.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 30 kB 18.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 40 kB 15.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 51 kB 8.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 61 kB 8.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 71 kB 8.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 81 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 83 kB 1.9 MB/s \n",
      "\u001b[?25hInstalling collected packages: corus\n",
      "Successfully installed corus-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install corus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Yk0diNYdpi0H",
   "metadata": {
    "id": "Yk0diNYdpi0H"
   },
   "outputs": [],
   "source": [
    "import corus\n",
    "from corus import load_ne5\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "u3tBTbGJso5J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3tBTbGJso5J",
    "outputId": "d42bda61-4902-4f29-ccd8-64da795ba955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "CQlC_-eYpjK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQlC_-eYpjK9",
    "outputId": "2bf31fb7-eaa3-4e3c-b860-e8c28b468c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-08 13:08:07--  http://www.labinform.ru/pub/named_entities/collection5.zip\n",
      "Resolving www.labinform.ru (www.labinform.ru)... 80.240.100.4\n",
      "Connecting to www.labinform.ru (www.labinform.ru)|80.240.100.4|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1899530 (1.8M) [application/zip]\n",
      "Saving to: ‘collection5.zip’\n",
      "\n",
      "collection5.zip     100%[===================>]   1.81M   371KB/s    in 5.7s    \n",
      "\n",
      "2021-08-08 13:08:13 (323 KB/s) - ‘collection5.zip’ saved [1899530/1899530]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "MrjV92iHrs-U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrjV92iHrs-U",
    "outputId": "40dfe137-ae0d-49fc-ef77-ea2b22852e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  collection5.zip\n",
      "   creating: Collection5/\n",
      "  inflating: Collection5/001.ann     \n",
      "  inflating: Collection5/001.txt     \n",
      "  inflating: Collection5/002.ann     \n",
      "  inflating: Collection5/002.txt     \n",
      "  inflating: Collection5/003.ann     \n",
      "  inflating: Collection5/003.txt     \n",
      "  inflating: Collection5/004.ann     \n",
      "  inflating: Collection5/004.txt     \n",
      "  inflating: Collection5/005.ann     \n",
      "  inflating: Collection5/005.txt     \n",
      "  inflating: Collection5/006.ann     \n",
      "  inflating: Collection5/006.txt     \n",
      "  inflating: Collection5/007.ann     \n",
      "  inflating: Collection5/007.txt     \n",
      "  inflating: Collection5/008.ann     \n",
      "  inflating: Collection5/008.txt     \n",
      "  inflating: Collection5/009.ann     \n",
      "  inflating: Collection5/009.txt     \n",
      "  inflating: Collection5/010.ann     \n",
      "  inflating: Collection5/010.txt     \n",
      "  inflating: Collection5/011.ann     \n",
      "  inflating: Collection5/011.txt     \n",
      "  inflating: Collection5/012.ann     \n",
      "  inflating: Collection5/012.txt     \n",
      "  inflating: Collection5/013.ann     \n",
      "  inflating: Collection5/013.txt     \n",
      "  inflating: Collection5/014.ann     \n",
      "  inflating: Collection5/014.txt     \n",
      "  inflating: Collection5/015 (!).ann  \n",
      "  inflating: Collection5/015 (!).txt  \n",
      "  inflating: Collection5/016.ann     \n",
      "  inflating: Collection5/016.txt     \n",
      "  inflating: Collection5/017.ann     \n",
      "  inflating: Collection5/017.txt     \n",
      "  inflating: Collection5/018.ann     \n",
      "  inflating: Collection5/018.txt     \n",
      "  inflating: Collection5/019.ann     \n",
      "  inflating: Collection5/019.txt     \n",
      "  inflating: Collection5/020.ann     \n",
      "  inflating: Collection5/020.txt     \n",
      "  inflating: Collection5/021.ann     \n",
      "  inflating: Collection5/021.txt     \n",
      "  inflating: Collection5/022.ann     \n",
      "  inflating: Collection5/022.txt     \n",
      "  inflating: Collection5/023.ann     \n",
      "  inflating: Collection5/023.txt     \n",
      "  inflating: Collection5/025.ann     \n",
      "  inflating: Collection5/025.txt     \n",
      "  inflating: Collection5/026.ann     \n",
      "  inflating: Collection5/026.txt     \n",
      "  inflating: Collection5/027.ann     \n",
      "  inflating: Collection5/027.txt     \n",
      "  inflating: Collection5/028.ann     \n",
      "  inflating: Collection5/028.txt     \n",
      "  inflating: Collection5/029.ann     \n",
      "  inflating: Collection5/029.txt     \n",
      "  inflating: Collection5/030.ann     \n",
      "  inflating: Collection5/030.txt     \n",
      "  inflating: Collection5/031.ann     \n",
      "  inflating: Collection5/031.txt     \n",
      "  inflating: Collection5/032.ann     \n",
      "  inflating: Collection5/032.txt     \n",
      "  inflating: Collection5/033.ann     \n",
      "  inflating: Collection5/033.txt     \n",
      "  inflating: Collection5/034.ann     \n",
      "  inflating: Collection5/034.txt     \n",
      "  inflating: Collection5/035.ann     \n",
      "  inflating: Collection5/035.txt     \n",
      "  inflating: Collection5/036.ann     \n",
      "  inflating: Collection5/036.txt     \n",
      "  inflating: Collection5/037.ann     \n",
      "  inflating: Collection5/037.txt     \n",
      "  inflating: Collection5/038.ann     \n",
      "  inflating: Collection5/038.txt     \n",
      "  inflating: Collection5/039.ann     \n",
      "  inflating: Collection5/039.txt     \n",
      "  inflating: Collection5/03_12_12a.ann  \n",
      "  inflating: Collection5/03_12_12a.txt  \n",
      "  inflating: Collection5/03_12_12b.ann  \n",
      "  inflating: Collection5/03_12_12b.txt  \n",
      "  inflating: Collection5/03_12_12c.ann  \n",
      "  inflating: Collection5/03_12_12c.txt  \n",
      "  inflating: Collection5/03_12_12d.ann  \n",
      "  inflating: Collection5/03_12_12d.txt  \n",
      "  inflating: Collection5/03_12_12g.ann  \n",
      "  inflating: Collection5/03_12_12g.txt  \n",
      "  inflating: Collection5/03_12_12h.ann  \n",
      "  inflating: Collection5/03_12_12h.txt  \n",
      "  inflating: Collection5/040.ann     \n",
      "  inflating: Collection5/040.txt     \n",
      "  inflating: Collection5/041.ann     \n",
      "  inflating: Collection5/041.txt     \n",
      "  inflating: Collection5/042.ann     \n",
      "  inflating: Collection5/042.txt     \n",
      "  inflating: Collection5/043.ann     \n",
      "  inflating: Collection5/043.txt     \n",
      "  inflating: Collection5/044.ann     \n",
      "  inflating: Collection5/044.txt     \n",
      "  inflating: Collection5/045.ann     \n",
      "  inflating: Collection5/045.txt     \n",
      "  inflating: Collection5/046.ann     \n",
      "  inflating: Collection5/046.txt     \n",
      "  inflating: Collection5/047.ann     \n",
      "  inflating: Collection5/047.txt     \n",
      "  inflating: Collection5/048.ann     \n",
      "  inflating: Collection5/048.txt     \n",
      "  inflating: Collection5/049.ann     \n",
      "  inflating: Collection5/049.txt     \n",
      "  inflating: Collection5/04_02_13a_abdulatipov.ann  \n",
      "  inflating: Collection5/04_02_13a_abdulatipov.txt  \n",
      "  inflating: Collection5/04_03_13a_sorokin.ann  \n",
      "  inflating: Collection5/04_03_13a_sorokin.txt  \n",
      "  inflating: Collection5/04_12_12b.ann  \n",
      "  inflating: Collection5/04_12_12b.txt  \n",
      "  inflating: Collection5/04_12_12d.ann  \n",
      "  inflating: Collection5/04_12_12d.txt  \n",
      "  inflating: Collection5/04_12_12f.ann  \n",
      "  inflating: Collection5/04_12_12f.txt  \n",
      "  inflating: Collection5/04_12_12g.ann  \n",
      "  inflating: Collection5/04_12_12g.txt  \n",
      "  inflating: Collection5/04_12_12h_corr.ann  \n",
      "  inflating: Collection5/04_12_12h_corr.txt  \n",
      "  inflating: Collection5/050.ann     \n",
      "  inflating: Collection5/050.txt     \n",
      "  inflating: Collection5/051.ann     \n",
      "  inflating: Collection5/051.txt     \n",
      "  inflating: Collection5/052.ann     \n",
      "  inflating: Collection5/052.txt     \n",
      "  inflating: Collection5/053.ann     \n",
      "  inflating: Collection5/053.txt     \n",
      "  inflating: Collection5/054.ann     \n",
      "  inflating: Collection5/054.txt     \n",
      "  inflating: Collection5/055.ann     \n",
      "  inflating: Collection5/055.txt     \n",
      "  inflating: Collection5/056.ann     \n",
      "  inflating: Collection5/056.txt     \n",
      "  inflating: Collection5/057.ann     \n",
      "  inflating: Collection5/057.txt     \n",
      "  inflating: Collection5/058.ann     \n",
      "  inflating: Collection5/058.txt     \n",
      "  inflating: Collection5/059.ann     \n",
      "  inflating: Collection5/059.txt     \n",
      "  inflating: Collection5/060.ann     \n",
      "  inflating: Collection5/060.txt     \n",
      "  inflating: Collection5/061.ann     \n",
      "  inflating: Collection5/061.txt     \n",
      "  inflating: Collection5/062.ann     \n",
      "  inflating: Collection5/062.txt     \n",
      "  inflating: Collection5/063.ann     \n",
      "  inflating: Collection5/063.txt     \n",
      "  inflating: Collection5/064.ann     \n",
      "  inflating: Collection5/064.txt     \n",
      "  inflating: Collection5/065.ann     \n",
      "  inflating: Collection5/065.txt     \n",
      "  inflating: Collection5/066.ann     \n",
      "  inflating: Collection5/066.txt     \n",
      "  inflating: Collection5/067.ann     \n",
      "  inflating: Collection5/067.txt     \n",
      "  inflating: Collection5/068.ann     \n",
      "  inflating: Collection5/068.txt     \n",
      "  inflating: Collection5/069.ann     \n",
      "  inflating: Collection5/069.txt     \n",
      "  inflating: Collection5/070.ann     \n",
      "  inflating: Collection5/070.txt     \n",
      "  inflating: Collection5/071.ann     \n",
      "  inflating: Collection5/071.txt     \n",
      "  inflating: Collection5/072.ann     \n",
      "  inflating: Collection5/072.txt     \n",
      "  inflating: Collection5/073.ann     \n",
      "  inflating: Collection5/073.txt     \n",
      "  inflating: Collection5/074.ann     \n",
      "  inflating: Collection5/074.txt     \n",
      "  inflating: Collection5/075.ann     \n",
      "  inflating: Collection5/075.txt     \n",
      "  inflating: Collection5/076.ann     \n",
      "  inflating: Collection5/076.txt     \n",
      "  inflating: Collection5/077.ann     \n",
      "  inflating: Collection5/077.txt     \n",
      "  inflating: Collection5/078.ann     \n",
      "  inflating: Collection5/078.txt     \n",
      "  inflating: Collection5/079.ann     \n",
      "  inflating: Collection5/079.txt     \n",
      "  inflating: Collection5/080.ann     \n",
      "  inflating: Collection5/080.txt     \n",
      "  inflating: Collection5/081.ann     \n",
      "  inflating: Collection5/081.txt     \n",
      "  inflating: Collection5/082.ann     \n",
      "  inflating: Collection5/082.txt     \n",
      "  inflating: Collection5/083.ann     \n",
      "  inflating: Collection5/083.txt     \n",
      "  inflating: Collection5/084.ann     \n",
      "  inflating: Collection5/084.txt     \n",
      "  inflating: Collection5/085.ann     \n",
      "  inflating: Collection5/085.txt     \n",
      "  inflating: Collection5/086.ann     \n",
      "  inflating: Collection5/086.txt     \n",
      "  inflating: Collection5/087.ann     \n",
      "  inflating: Collection5/087.txt     \n",
      "  inflating: Collection5/088.ann     \n",
      "  inflating: Collection5/088.txt     \n",
      "  inflating: Collection5/089.ann     \n",
      "  inflating: Collection5/089.txt     \n",
      "  inflating: Collection5/090.ann     \n",
      "  inflating: Collection5/090.txt     \n",
      "  inflating: Collection5/091.ann     \n",
      "  inflating: Collection5/091.txt     \n",
      "  inflating: Collection5/092.ann     \n",
      "  inflating: Collection5/092.txt     \n",
      "  inflating: Collection5/093.ann     \n",
      "  inflating: Collection5/093.txt     \n",
      "  inflating: Collection5/094.ann     \n",
      "  inflating: Collection5/094.txt     \n",
      "  inflating: Collection5/095.ann     \n",
      "  inflating: Collection5/095.txt     \n",
      "  inflating: Collection5/096.ann     \n",
      "  inflating: Collection5/096.txt     \n",
      "  inflating: Collection5/097.ann     \n",
      "  inflating: Collection5/097.txt     \n",
      "  inflating: Collection5/098.ann     \n",
      "  inflating: Collection5/098.txt     \n",
      "  inflating: Collection5/099.ann     \n",
      "  inflating: Collection5/099.txt     \n",
      "  inflating: Collection5/09_01_13.ann  \n",
      "  inflating: Collection5/09_01_13.txt  \n",
      "  inflating: Collection5/09_01_13a.ann  \n",
      "  inflating: Collection5/09_01_13a.txt  \n",
      "  inflating: Collection5/09_01_13c.ann  \n",
      "  inflating: Collection5/09_01_13c.txt  \n",
      "  inflating: Collection5/09_01_13d.ann  \n",
      "  inflating: Collection5/09_01_13d.txt  \n",
      "  inflating: Collection5/09_01_13e.ann  \n",
      "  inflating: Collection5/09_01_13e.txt  \n",
      "  inflating: Collection5/09_01_13h.ann  \n",
      "  inflating: Collection5/09_01_13h.txt  \n",
      "  inflating: Collection5/09_01_13i.ann  \n",
      "  inflating: Collection5/09_01_13i.txt  \n",
      "  inflating: Collection5/100.ann     \n",
      "  inflating: Collection5/100.txt     \n",
      "  inflating: Collection5/1000.ann    \n",
      "  inflating: Collection5/1000.txt    \n",
      "  inflating: Collection5/1001.ann    \n",
      "  inflating: Collection5/1001.txt    \n",
      "  inflating: Collection5/1002.ann    \n",
      "  inflating: Collection5/1002.txt    \n",
      "  inflating: Collection5/1003.ann    \n",
      "  inflating: Collection5/1003.txt    \n",
      "  inflating: Collection5/1004.ann    \n",
      "  inflating: Collection5/1004.txt    \n",
      "  inflating: Collection5/1005.ann    \n",
      "  inflating: Collection5/1005.txt    \n",
      "  inflating: Collection5/1006.ann    \n",
      "  inflating: Collection5/1006.txt    \n",
      "  inflating: Collection5/1007.ann    \n",
      "  inflating: Collection5/1007.txt    \n",
      "  inflating: Collection5/1008.ann    \n",
      "  inflating: Collection5/1008.txt    \n",
      "  inflating: Collection5/1009.ann    \n",
      "  inflating: Collection5/1009.txt    \n",
      "  inflating: Collection5/101.ann     \n",
      "  inflating: Collection5/101.txt     \n",
      "  inflating: Collection5/1010.ann    \n",
      "  inflating: Collection5/1010.txt    \n",
      "  inflating: Collection5/1011.ann    \n",
      "  inflating: Collection5/1011.txt    \n",
      "  inflating: Collection5/1012.ann    \n",
      "  inflating: Collection5/1012.txt    \n",
      "  inflating: Collection5/1013.ann    \n",
      "  inflating: Collection5/1013.txt    \n",
      "  inflating: Collection5/1014.ann    \n",
      "  inflating: Collection5/1014.txt    \n",
      "  inflating: Collection5/1015.ann    \n",
      "  inflating: Collection5/1015.txt    \n",
      "  inflating: Collection5/1016.ann    \n",
      "  inflating: Collection5/1016.txt    \n",
      "  inflating: Collection5/1017.ann    \n",
      "  inflating: Collection5/1017.txt    \n",
      "  inflating: Collection5/1018.ann    \n",
      "  inflating: Collection5/1018.txt    \n",
      "  inflating: Collection5/1019.ann    \n",
      "  inflating: Collection5/1019.txt    \n",
      "  inflating: Collection5/102.ann     \n",
      "  inflating: Collection5/102.txt     \n",
      "  inflating: Collection5/1020.ann    \n",
      "  inflating: Collection5/1020.txt    \n",
      "  inflating: Collection5/1021.ann    \n",
      "  inflating: Collection5/1021.txt    \n",
      "  inflating: Collection5/1022.ann    \n",
      "  inflating: Collection5/1022.txt    \n",
      "  inflating: Collection5/1023.ann    \n",
      "  inflating: Collection5/1023.txt    \n",
      "  inflating: Collection5/1024.ann    \n",
      "  inflating: Collection5/1024.txt    \n",
      "  inflating: Collection5/1025.ann    \n",
      "  inflating: Collection5/1025.txt    \n",
      "  inflating: Collection5/1026.ann    \n",
      "  inflating: Collection5/1026.txt    \n",
      "  inflating: Collection5/1027.ann    \n",
      "  inflating: Collection5/1027.txt    \n",
      "  inflating: Collection5/1028.ann    \n",
      "  inflating: Collection5/1028.txt    \n",
      "  inflating: Collection5/1029.ann    \n",
      "  inflating: Collection5/1029.txt    \n",
      "  inflating: Collection5/103.ann     \n",
      "  inflating: Collection5/103.txt     \n",
      "  inflating: Collection5/1030.ann    \n",
      "  inflating: Collection5/1030.txt    \n",
      "  inflating: Collection5/1031.ann    \n",
      "  inflating: Collection5/1031.txt    \n",
      "  inflating: Collection5/1032.ann    \n",
      "  inflating: Collection5/1032.txt    \n",
      "  inflating: Collection5/1033.ann    \n",
      "  inflating: Collection5/1033.txt    \n",
      "  inflating: Collection5/1034.ann    \n",
      "  inflating: Collection5/1034.txt    \n",
      "  inflating: Collection5/1035.ann    \n",
      "  inflating: Collection5/1035.txt    \n",
      "  inflating: Collection5/1036.ann    \n",
      "  inflating: Collection5/1036.txt    \n",
      "  inflating: Collection5/1037.ann    \n",
      "  inflating: Collection5/1037.txt    \n",
      "  inflating: Collection5/1038.ann    \n",
      "  inflating: Collection5/1038.txt    \n",
      "  inflating: Collection5/1039.ann    \n",
      "  inflating: Collection5/1039.txt    \n",
      "  inflating: Collection5/104.ann     \n",
      "  inflating: Collection5/104.txt     \n",
      "  inflating: Collection5/1040.ann    \n",
      "  inflating: Collection5/1040.txt    \n",
      "  inflating: Collection5/1041.ann    \n",
      "  inflating: Collection5/1041.txt    \n",
      "  inflating: Collection5/1042.ann    \n",
      "  inflating: Collection5/1042.txt    \n",
      "  inflating: Collection5/1043.ann    \n",
      "  inflating: Collection5/1043.txt    \n",
      "  inflating: Collection5/1044.ann    \n",
      "  inflating: Collection5/1044.txt    \n",
      "  inflating: Collection5/1045.ann    \n",
      "  inflating: Collection5/1045.txt    \n",
      "  inflating: Collection5/1046.ann    \n",
      "  inflating: Collection5/1046.txt    \n",
      "  inflating: Collection5/1047.ann    \n",
      "  inflating: Collection5/1047.txt    \n",
      "  inflating: Collection5/1048.ann    \n",
      "  inflating: Collection5/1048.txt    \n",
      "  inflating: Collection5/1049.ann    \n",
      "  inflating: Collection5/1049.txt    \n",
      "  inflating: Collection5/105.ann     \n",
      "  inflating: Collection5/105.txt     \n",
      "  inflating: Collection5/1050.ann    \n",
      "  inflating: Collection5/1050.txt    \n",
      "  inflating: Collection5/106.ann     \n",
      "  inflating: Collection5/106.txt     \n",
      "  inflating: Collection5/107.ann     \n",
      "  inflating: Collection5/107.txt     \n",
      "  inflating: Collection5/108.ann     \n",
      "  inflating: Collection5/108.txt     \n",
      "  inflating: Collection5/109.ann     \n",
      "  inflating: Collection5/109.txt     \n",
      "  inflating: Collection5/10_01_13a.ann  \n",
      "  inflating: Collection5/10_01_13a.txt  \n",
      "  inflating: Collection5/10_01_13d.ann  \n",
      "  inflating: Collection5/10_01_13d.txt  \n",
      "  inflating: Collection5/10_01_13i.ann  \n",
      "  inflating: Collection5/10_01_13i.txt  \n",
      "  inflating: Collection5/110.ann     \n",
      "  inflating: Collection5/110.txt     \n",
      "  inflating: Collection5/1100.ann    \n",
      "  inflating: Collection5/1100.txt    \n",
      "  inflating: Collection5/1101.ann    \n",
      "  inflating: Collection5/1101.txt    \n",
      "  inflating: Collection5/1102.ann    \n",
      "  inflating: Collection5/1102.txt    \n",
      "  inflating: Collection5/1103.ann    \n",
      "  inflating: Collection5/1103.txt    \n",
      "  inflating: Collection5/1104.ann    \n",
      "  inflating: Collection5/1104.txt    \n",
      "  inflating: Collection5/1105.ann    \n",
      "  inflating: Collection5/1105.txt    \n",
      "  inflating: Collection5/1106.ann    \n",
      "  inflating: Collection5/1106.txt    \n",
      "  inflating: Collection5/1107.ann    \n",
      "  inflating: Collection5/1107.txt    \n",
      "  inflating: Collection5/1108.ann    \n",
      "  inflating: Collection5/1108.txt    \n",
      "  inflating: Collection5/1109.ann    \n",
      "  inflating: Collection5/1109.txt    \n",
      "  inflating: Collection5/111.ann     \n",
      "  inflating: Collection5/111.txt     \n",
      "  inflating: Collection5/1110.ann    \n",
      "  inflating: Collection5/1110.txt    \n",
      "  inflating: Collection5/1111.ann    \n",
      "  inflating: Collection5/1111.txt    \n",
      "  inflating: Collection5/1112.ann    \n",
      "  inflating: Collection5/1112.txt    \n",
      "  inflating: Collection5/1113.ann    \n",
      "  inflating: Collection5/1113.txt    \n",
      "  inflating: Collection5/1114.ann    \n",
      "  inflating: Collection5/1114.txt    \n",
      "  inflating: Collection5/1115.ann    \n",
      "  inflating: Collection5/1115.txt    \n",
      "  inflating: Collection5/1116.ann    \n",
      "  inflating: Collection5/1116.txt    \n",
      "  inflating: Collection5/1117.ann    \n",
      "  inflating: Collection5/1117.txt    \n",
      "  inflating: Collection5/1118.ann    \n",
      "  inflating: Collection5/1118.txt    \n",
      "  inflating: Collection5/1119.ann    \n",
      "  inflating: Collection5/1119.txt    \n",
      "  inflating: Collection5/112.ann     \n",
      "  inflating: Collection5/112.txt     \n",
      "  inflating: Collection5/1120.ann    \n",
      "  inflating: Collection5/1120.txt    \n",
      "  inflating: Collection5/1121.ann    \n",
      "  inflating: Collection5/1121.txt    \n",
      "  inflating: Collection5/1122.ann    \n",
      "  inflating: Collection5/1122.txt    \n",
      "  inflating: Collection5/1123.ann    \n",
      "  inflating: Collection5/1123.txt    \n",
      "  inflating: Collection5/1124.ann    \n",
      "  inflating: Collection5/1124.txt    \n",
      "  inflating: Collection5/1125.ann    \n",
      "  inflating: Collection5/1125.txt    \n",
      "  inflating: Collection5/1126.ann    \n",
      "  inflating: Collection5/1126.txt    \n",
      "  inflating: Collection5/1127.ann    \n",
      "  inflating: Collection5/1127.txt    \n",
      "  inflating: Collection5/1128.ann    \n",
      "  inflating: Collection5/1128.txt    \n",
      "  inflating: Collection5/113.ann     \n",
      "  inflating: Collection5/113.txt     \n",
      "  inflating: Collection5/1130.ann    \n",
      "  inflating: Collection5/1130.txt    \n",
      "  inflating: Collection5/1131.ann    \n",
      "  inflating: Collection5/1131.txt    \n",
      "  inflating: Collection5/1132.ann    \n",
      "  inflating: Collection5/1132.txt    \n",
      "  inflating: Collection5/1133.ann    \n",
      "  inflating: Collection5/1133.txt    \n",
      "  inflating: Collection5/1134.ann    \n",
      "  inflating: Collection5/1134.txt    \n",
      "  inflating: Collection5/1135.ann    \n",
      "  inflating: Collection5/1135.txt    \n",
      "  inflating: Collection5/1136.ann    \n",
      "  inflating: Collection5/1136.txt    \n",
      "  inflating: Collection5/1137.ann    \n",
      "  inflating: Collection5/1137.txt    \n",
      "  inflating: Collection5/1138.ann    \n",
      "  inflating: Collection5/1138.txt    \n",
      "  inflating: Collection5/1139.ann    \n",
      "  inflating: Collection5/1139.txt    \n",
      "  inflating: Collection5/114.ann     \n",
      "  inflating: Collection5/114.txt     \n",
      "  inflating: Collection5/1140.ann    \n",
      "  inflating: Collection5/1140.txt    \n",
      "  inflating: Collection5/1141.ann    \n",
      "  inflating: Collection5/1141.txt    \n",
      "  inflating: Collection5/1142.ann    \n",
      "  inflating: Collection5/1142.txt    \n",
      "  inflating: Collection5/1143.ann    \n",
      "  inflating: Collection5/1143.txt    \n",
      "  inflating: Collection5/1144.ann    \n",
      "  inflating: Collection5/1144.txt    \n",
      "  inflating: Collection5/1145.ann    \n",
      "  inflating: Collection5/1145.txt    \n",
      "  inflating: Collection5/1146.ann    \n",
      "  inflating: Collection5/1146.txt    \n",
      "  inflating: Collection5/1147.ann    \n",
      "  inflating: Collection5/1147.txt    \n",
      "  inflating: Collection5/1148.ann    \n",
      "  inflating: Collection5/1148.txt    \n",
      "  inflating: Collection5/1149.ann    \n",
      "  inflating: Collection5/1149.txt    \n",
      "  inflating: Collection5/115.ann     \n",
      "  inflating: Collection5/115.txt     \n",
      "  inflating: Collection5/1150.ann    \n",
      "  inflating: Collection5/1150.txt    \n",
      "  inflating: Collection5/1151.ann    \n",
      "  inflating: Collection5/1151.txt    \n",
      "  inflating: Collection5/1152.ann    \n",
      "  inflating: Collection5/1152.txt    \n",
      "  inflating: Collection5/1153.ann    \n",
      "  inflating: Collection5/1153.txt    \n",
      "  inflating: Collection5/1154.ann    \n",
      "  inflating: Collection5/1154.txt    \n",
      "  inflating: Collection5/1155.ann    \n",
      "  inflating: Collection5/1155.txt    \n",
      "  inflating: Collection5/1156.ann    \n",
      "  inflating: Collection5/1156.txt    \n",
      "  inflating: Collection5/1157.ann    \n",
      "  inflating: Collection5/1157.txt    \n",
      "  inflating: Collection5/1158.ann    \n",
      "  inflating: Collection5/1158.txt    \n",
      "  inflating: Collection5/1159.ann    \n",
      "  inflating: Collection5/1159.txt    \n",
      "  inflating: Collection5/116.ann     \n",
      "  inflating: Collection5/116.txt     \n",
      "  inflating: Collection5/1160.ann    \n",
      "  inflating: Collection5/1160.txt    \n",
      "  inflating: Collection5/1161.ann    \n",
      "  inflating: Collection5/1161.txt    \n",
      "  inflating: Collection5/1162.ann    \n",
      "  inflating: Collection5/1162.txt    \n",
      "  inflating: Collection5/1163.ann    \n",
      "  inflating: Collection5/1163.txt    \n",
      "  inflating: Collection5/1164.ann    \n",
      "  inflating: Collection5/1164.txt    \n",
      "  inflating: Collection5/1165.ann    \n",
      "  inflating: Collection5/1165.txt    \n",
      "  inflating: Collection5/1166.ann    \n",
      "  inflating: Collection5/1166.txt    \n",
      "  inflating: Collection5/1167.ann    \n",
      "  inflating: Collection5/1167.txt    \n",
      "  inflating: Collection5/1168.ann    \n",
      "  inflating: Collection5/1168.txt    \n",
      "  inflating: Collection5/1169.ann    \n",
      "  inflating: Collection5/1169.txt    \n",
      "  inflating: Collection5/117.ann     \n",
      "  inflating: Collection5/117.txt     \n",
      "  inflating: Collection5/1170.ann    \n",
      "  inflating: Collection5/1170.txt    \n",
      "  inflating: Collection5/1171.ann    \n",
      "  inflating: Collection5/1171.txt    \n",
      "  inflating: Collection5/1172.ann    \n",
      "  inflating: Collection5/1172.txt    \n",
      "  inflating: Collection5/1173.ann    \n",
      "  inflating: Collection5/1173.txt    \n",
      "  inflating: Collection5/1174.ann    \n",
      "  inflating: Collection5/1174.txt    \n",
      "  inflating: Collection5/1175.ann    \n",
      "  inflating: Collection5/1175.txt    \n",
      "  inflating: Collection5/1176.ann    \n",
      "  inflating: Collection5/1176.txt    \n",
      "  inflating: Collection5/1177.ann    \n",
      "  inflating: Collection5/1177.txt    \n",
      "  inflating: Collection5/1178.ann    \n",
      "  inflating: Collection5/1178.txt    \n",
      "  inflating: Collection5/1179.ann    \n",
      "  inflating: Collection5/1179.txt    \n",
      "  inflating: Collection5/118.ann     \n",
      "  inflating: Collection5/118.txt     \n",
      "  inflating: Collection5/1180.ann    \n",
      "  inflating: Collection5/1180.txt    \n",
      "  inflating: Collection5/1181.ann    \n",
      "  inflating: Collection5/1181.txt    \n",
      "  inflating: Collection5/1182.ann    \n",
      "  inflating: Collection5/1182.txt    \n",
      "  inflating: Collection5/1183.ann    \n",
      "  inflating: Collection5/1183.txt    \n",
      "  inflating: Collection5/1184.ann    \n",
      "  inflating: Collection5/1184.txt    \n",
      "  inflating: Collection5/1185.ann    \n",
      "  inflating: Collection5/1185.txt    \n",
      "  inflating: Collection5/1186.ann    \n",
      "  inflating: Collection5/1186.txt    \n",
      "  inflating: Collection5/1187.ann    \n",
      "  inflating: Collection5/1187.txt    \n",
      "  inflating: Collection5/1188.ann    \n",
      "  inflating: Collection5/1188.txt    \n",
      "  inflating: Collection5/1189.ann    \n",
      "  inflating: Collection5/1189.txt    \n",
      "  inflating: Collection5/119.ann     \n",
      "  inflating: Collection5/119.txt     \n",
      "  inflating: Collection5/1190.ann    \n",
      "  inflating: Collection5/1190.txt    \n",
      "  inflating: Collection5/1191.ann    \n",
      "  inflating: Collection5/1191.txt    \n",
      "  inflating: Collection5/1192.ann    \n",
      "  inflating: Collection5/1192.txt    \n",
      "  inflating: Collection5/1193.ann    \n",
      "  inflating: Collection5/1193.txt    \n",
      "  inflating: Collection5/1194.ann    \n",
      "  inflating: Collection5/1194.txt    \n",
      "  inflating: Collection5/1195.ann    \n",
      "  inflating: Collection5/1195.txt    \n",
      "  inflating: Collection5/1196.ann    \n",
      "  inflating: Collection5/1196.txt    \n",
      "  inflating: Collection5/1197.ann    \n",
      "  inflating: Collection5/1197.txt    \n",
      "  inflating: Collection5/1198.ann    \n",
      "  inflating: Collection5/1198.txt    \n",
      "  inflating: Collection5/1199.ann    \n",
      "  inflating: Collection5/1199.txt    \n",
      "  inflating: Collection5/11_01_13b.ann  \n",
      "  inflating: Collection5/11_01_13b.txt  \n",
      "  inflating: Collection5/11_01_13e.ann  \n",
      "  inflating: Collection5/11_01_13e.txt  \n",
      "  inflating: Collection5/120.ann     \n",
      "  inflating: Collection5/120.txt     \n",
      "  inflating: Collection5/1200.ann    \n",
      "  inflating: Collection5/1200.txt    \n",
      "  inflating: Collection5/121.ann     \n",
      "  inflating: Collection5/121.txt     \n",
      "  inflating: Collection5/122.ann     \n",
      "  inflating: Collection5/122.txt     \n",
      "  inflating: Collection5/123.ann     \n",
      "  inflating: Collection5/123.txt     \n",
      "  inflating: Collection5/124.ann     \n",
      "  inflating: Collection5/124.txt     \n",
      "  inflating: Collection5/125.ann     \n",
      "  inflating: Collection5/125.txt     \n",
      "  inflating: Collection5/126.ann     \n",
      "  inflating: Collection5/126.txt     \n",
      "  inflating: Collection5/127.ann     \n",
      "  inflating: Collection5/127.txt     \n",
      "  inflating: Collection5/128.ann     \n",
      "  inflating: Collection5/128.txt     \n",
      "  inflating: Collection5/129.ann     \n",
      "  inflating: Collection5/129.txt     \n",
      "  inflating: Collection5/130.ann     \n",
      "  inflating: Collection5/130.txt     \n",
      "  inflating: Collection5/131.ann     \n",
      "  inflating: Collection5/131.txt     \n",
      "  inflating: Collection5/132.ann     \n",
      "  inflating: Collection5/132.txt     \n",
      "  inflating: Collection5/133.ann     \n",
      "  inflating: Collection5/133.txt     \n",
      "  inflating: Collection5/134.ann     \n",
      "  inflating: Collection5/134.txt     \n",
      "  inflating: Collection5/135.ann     \n",
      "  inflating: Collection5/135.txt     \n",
      "  inflating: Collection5/136.ann     \n",
      "  inflating: Collection5/136.txt     \n",
      "  inflating: Collection5/137.ann     \n",
      "  inflating: Collection5/137.txt     \n",
      "  inflating: Collection5/138.ann     \n",
      "  inflating: Collection5/138.txt     \n",
      "  inflating: Collection5/139.ann     \n",
      "  inflating: Collection5/139.txt     \n",
      "  inflating: Collection5/140.ann     \n",
      "  inflating: Collection5/140.txt     \n",
      "  inflating: Collection5/141.ann     \n",
      "  inflating: Collection5/141.txt     \n",
      "  inflating: Collection5/142.ann     \n",
      "  inflating: Collection5/142.txt     \n",
      "  inflating: Collection5/143.ann     \n",
      "  inflating: Collection5/143.txt     \n",
      "  inflating: Collection5/144.ann     \n",
      "  inflating: Collection5/144.txt     \n",
      "  inflating: Collection5/145.ann     \n",
      "  inflating: Collection5/145.txt     \n",
      "  inflating: Collection5/146.ann     \n",
      "  inflating: Collection5/146.txt     \n",
      "  inflating: Collection5/147.ann     \n",
      "  inflating: Collection5/147.txt     \n",
      "  inflating: Collection5/148.ann     \n",
      "  inflating: Collection5/148.txt     \n",
      "  inflating: Collection5/149.ann     \n",
      "  inflating: Collection5/149.txt     \n",
      "  inflating: Collection5/14_01_13c.ann  \n",
      "  inflating: Collection5/14_01_13c.txt  \n",
      "  inflating: Collection5/14_01_13g.ann  \n",
      "  inflating: Collection5/14_01_13g.txt  \n",
      "  inflating: Collection5/14_01_13i.ann  \n",
      "  inflating: Collection5/14_01_13i.txt  \n",
      "  inflating: Collection5/150.ann     \n",
      "  inflating: Collection5/150.txt     \n",
      "  inflating: Collection5/151.ann     \n",
      "  inflating: Collection5/151.txt     \n",
      "  inflating: Collection5/152.ann     \n",
      "  inflating: Collection5/152.txt     \n",
      "  inflating: Collection5/153.ann     \n",
      "  inflating: Collection5/153.txt     \n",
      "  inflating: Collection5/154.ann     \n",
      "  inflating: Collection5/154.txt     \n",
      "  inflating: Collection5/155.ann     \n",
      "  inflating: Collection5/155.txt     \n",
      "  inflating: Collection5/156.ann     \n",
      "  inflating: Collection5/156.txt     \n",
      "  inflating: Collection5/157.ann     \n",
      "  inflating: Collection5/157.txt     \n",
      "  inflating: Collection5/158.ann     \n",
      "  inflating: Collection5/158.txt     \n",
      "  inflating: Collection5/159.ann     \n",
      "  inflating: Collection5/159.txt     \n",
      "  inflating: Collection5/15_01_13a.ann  \n",
      "  inflating: Collection5/15_01_13a.txt  \n",
      "  inflating: Collection5/15_01_13b.ann  \n",
      "  inflating: Collection5/15_01_13b.txt  \n",
      "  inflating: Collection5/15_01_13e.ann  \n",
      "  inflating: Collection5/15_01_13e.txt  \n",
      "  inflating: Collection5/15_01_13f.ann  \n",
      "  inflating: Collection5/15_01_13f.txt  \n",
      "  inflating: Collection5/160.ann     \n",
      "  inflating: Collection5/160.txt     \n",
      "  inflating: Collection5/161.ann     \n",
      "  inflating: Collection5/161.txt     \n",
      "  inflating: Collection5/162.ann     \n",
      "  inflating: Collection5/162.txt     \n",
      "  inflating: Collection5/163.ann     \n",
      "  inflating: Collection5/163.txt     \n",
      "  inflating: Collection5/164.ann     \n",
      "  inflating: Collection5/164.txt     \n",
      "  inflating: Collection5/165.ann     \n",
      "  inflating: Collection5/165.txt     \n",
      "  inflating: Collection5/166.ann     \n",
      "  inflating: Collection5/166.txt     \n",
      "  inflating: Collection5/167.ann     \n",
      "  inflating: Collection5/167.txt     \n",
      "  inflating: Collection5/168.ann     \n",
      "  inflating: Collection5/168.txt     \n",
      "  inflating: Collection5/169.ann     \n",
      "  inflating: Collection5/169.txt     \n",
      "  inflating: Collection5/170.ann     \n",
      "  inflating: Collection5/170.txt     \n",
      "  inflating: Collection5/171.ann     \n",
      "  inflating: Collection5/171.txt     \n",
      "  inflating: Collection5/172.ann     \n",
      "  inflating: Collection5/172.txt     \n",
      "  inflating: Collection5/173.ann     \n",
      "  inflating: Collection5/173.txt     \n",
      "  inflating: Collection5/174.ann     \n",
      "  inflating: Collection5/174.txt     \n",
      "  inflating: Collection5/175.ann     \n",
      "  inflating: Collection5/175.txt     \n",
      "  inflating: Collection5/176.ann     \n",
      "  inflating: Collection5/176.txt     \n",
      "  inflating: Collection5/177.ann     \n",
      "  inflating: Collection5/177.txt     \n",
      "  inflating: Collection5/178.ann     \n",
      "  inflating: Collection5/178.txt     \n",
      "  inflating: Collection5/179.ann     \n",
      "  inflating: Collection5/179.txt     \n",
      "  inflating: Collection5/180.ann     \n",
      "  inflating: Collection5/180.txt     \n",
      "  inflating: Collection5/181.ann     \n",
      "  inflating: Collection5/181.txt     \n",
      "  inflating: Collection5/182.ann     \n",
      "  inflating: Collection5/182.txt     \n",
      "  inflating: Collection5/183.ann     \n",
      "  inflating: Collection5/183.txt     \n",
      "  inflating: Collection5/184.ann     \n",
      "  inflating: Collection5/184.txt     \n",
      "  inflating: Collection5/185.ann     \n",
      "  inflating: Collection5/185.txt     \n",
      "  inflating: Collection5/186.ann     \n",
      "  inflating: Collection5/186.txt     \n",
      "  inflating: Collection5/187.ann     \n",
      "  inflating: Collection5/187.txt     \n",
      "  inflating: Collection5/188.ann     \n",
      "  inflating: Collection5/188.txt     \n",
      "  inflating: Collection5/189.ann     \n",
      "  inflating: Collection5/189.txt     \n",
      "  inflating: Collection5/190.ann     \n",
      "  inflating: Collection5/190.txt     \n",
      "  inflating: Collection5/191.ann     \n",
      "  inflating: Collection5/191.txt     \n",
      "  inflating: Collection5/192.ann     \n",
      "  inflating: Collection5/192.txt     \n",
      "  inflating: Collection5/193.ann     \n",
      "  inflating: Collection5/193.txt     \n",
      "  inflating: Collection5/194.ann     \n",
      "  inflating: Collection5/194.txt     \n",
      "  inflating: Collection5/195.ann     \n",
      "  inflating: Collection5/195.txt     \n",
      "  inflating: Collection5/196.ann     \n",
      "  inflating: Collection5/196.txt     \n",
      "  inflating: Collection5/197.ann     \n",
      "  inflating: Collection5/197.txt     \n",
      "  inflating: Collection5/198.ann     \n",
      "  inflating: Collection5/198.txt     \n",
      "  inflating: Collection5/199.ann     \n",
      "  inflating: Collection5/199.txt     \n",
      "  inflating: Collection5/19_11_12d.ann  \n",
      "  inflating: Collection5/19_11_12d.txt  \n",
      "  inflating: Collection5/19_11_12h.ann  \n",
      "  inflating: Collection5/19_11_12h.txt  \n",
      "  inflating: Collection5/200.ann     \n",
      "  inflating: Collection5/200.txt     \n",
      "  inflating: Collection5/2001.ann    \n",
      "  inflating: Collection5/2001.txt    \n",
      "  inflating: Collection5/2002.ann    \n",
      "  inflating: Collection5/2002.txt    \n",
      "  inflating: Collection5/2003.ann    \n",
      "  inflating: Collection5/2003.txt    \n",
      "  inflating: Collection5/2004.ann    \n",
      "  inflating: Collection5/2004.txt    \n",
      "  inflating: Collection5/2005.ann    \n",
      "  inflating: Collection5/2005.txt    \n",
      "  inflating: Collection5/2006.ann    \n",
      "  inflating: Collection5/2006.txt    \n",
      "  inflating: Collection5/2007.ann    \n",
      "  inflating: Collection5/2007.txt    \n",
      "  inflating: Collection5/2008.ann    \n",
      "  inflating: Collection5/2008.txt    \n",
      "  inflating: Collection5/2009.ann    \n",
      "  inflating: Collection5/2009.txt    \n",
      "  inflating: Collection5/201.ann     \n",
      "  inflating: Collection5/201.txt     \n",
      "  inflating: Collection5/2010.ann    \n",
      "  inflating: Collection5/2010.txt    \n",
      "  inflating: Collection5/2011.ann    \n",
      "  inflating: Collection5/2011.txt    \n",
      "  inflating: Collection5/2012.ann    \n",
      "  inflating: Collection5/2012.txt    \n",
      "  inflating: Collection5/2013.ann    \n",
      "  inflating: Collection5/2013.txt    \n",
      "  inflating: Collection5/2014.ann    \n",
      "  inflating: Collection5/2014.txt    \n",
      "  inflating: Collection5/2015.ann    \n",
      "  inflating: Collection5/2015.txt    \n",
      "  inflating: Collection5/2016.ann    \n",
      "  inflating: Collection5/2016.txt    \n",
      "  inflating: Collection5/2017.ann    \n",
      "  inflating: Collection5/2017.txt    \n",
      "  inflating: Collection5/2018.ann    \n",
      "  inflating: Collection5/2018.txt    \n",
      "  inflating: Collection5/2019.ann    \n",
      "  inflating: Collection5/2019.txt    \n",
      "  inflating: Collection5/202.ann     \n",
      "  inflating: Collection5/202.txt     \n",
      "  inflating: Collection5/2020.ann    \n",
      "  inflating: Collection5/2020.txt    \n",
      "  inflating: Collection5/2021.ann    \n",
      "  inflating: Collection5/2021.txt    \n",
      "  inflating: Collection5/2022.ann    \n",
      "  inflating: Collection5/2022.txt    \n",
      "  inflating: Collection5/2023.ann    \n",
      "  inflating: Collection5/2023.txt    \n",
      "  inflating: Collection5/2024.ann    \n",
      "  inflating: Collection5/2024.txt    \n",
      "  inflating: Collection5/2025.ann    \n",
      "  inflating: Collection5/2025.txt    \n",
      "  inflating: Collection5/2026.ann    \n",
      "  inflating: Collection5/2026.txt    \n",
      "  inflating: Collection5/2027.ann    \n",
      "  inflating: Collection5/2027.txt    \n",
      "  inflating: Collection5/2028.ann    \n",
      "  inflating: Collection5/2028.txt    \n",
      "  inflating: Collection5/2029.ann    \n",
      "  inflating: Collection5/2029.txt    \n",
      "  inflating: Collection5/203.ann     \n",
      "  inflating: Collection5/203.txt     \n",
      "  inflating: Collection5/2030.ann    \n",
      "  inflating: Collection5/2030.txt    \n",
      "  inflating: Collection5/2031.ann    \n",
      "  inflating: Collection5/2031.txt    \n",
      "  inflating: Collection5/2032.ann    \n",
      "  inflating: Collection5/2032.txt    \n",
      "  inflating: Collection5/2034.ann    \n",
      "  inflating: Collection5/2034.txt    \n",
      "  inflating: Collection5/2035.ann    \n",
      "  inflating: Collection5/2035.txt    \n",
      "  inflating: Collection5/2036.ann    \n",
      "  inflating: Collection5/2036.txt    \n",
      "  inflating: Collection5/2037.ann    \n",
      "  inflating: Collection5/2037.txt    \n",
      "  inflating: Collection5/2038.ann    \n",
      "  inflating: Collection5/2038.txt    \n",
      "  inflating: Collection5/2039.ann    \n",
      "  inflating: Collection5/2039.txt    \n",
      "  inflating: Collection5/204.ann     \n",
      "  inflating: Collection5/204.txt     \n",
      "  inflating: Collection5/2040.ann    \n",
      "  inflating: Collection5/2040.txt    \n",
      "  inflating: Collection5/2041.ann    \n",
      "  inflating: Collection5/2041.txt    \n",
      "  inflating: Collection5/2042.ann    \n",
      "  inflating: Collection5/2042.txt    \n",
      "  inflating: Collection5/2043.ann    \n",
      "  inflating: Collection5/2043.txt    \n",
      "  inflating: Collection5/2044.ann    \n",
      "  inflating: Collection5/2044.txt    \n",
      "  inflating: Collection5/2045.ann    \n",
      "  inflating: Collection5/2045.txt    \n",
      "  inflating: Collection5/2046.ann    \n",
      "  inflating: Collection5/2046.txt    \n",
      "  inflating: Collection5/2047.ann    \n",
      "  inflating: Collection5/2047.txt    \n",
      "  inflating: Collection5/2048.ann    \n",
      "  inflating: Collection5/2048.txt    \n",
      "  inflating: Collection5/2049.ann    \n",
      "  inflating: Collection5/2049.txt    \n",
      "  inflating: Collection5/205.ann     \n",
      "  inflating: Collection5/205.txt     \n",
      "  inflating: Collection5/2050.ann    \n",
      "  inflating: Collection5/2050.txt    \n",
      "  inflating: Collection5/206.ann     \n",
      "  inflating: Collection5/206.txt     \n",
      "  inflating: Collection5/207.ann     \n",
      "  inflating: Collection5/207.txt     \n",
      "  inflating: Collection5/208.ann     \n",
      "  inflating: Collection5/208.txt     \n",
      "  inflating: Collection5/209.ann     \n",
      "  inflating: Collection5/209.txt     \n",
      "  inflating: Collection5/20_11_12a.ann  \n",
      "  inflating: Collection5/20_11_12a.txt  \n",
      "  inflating: Collection5/20_11_12b.ann  \n",
      "  inflating: Collection5/20_11_12b.txt  \n",
      "  inflating: Collection5/20_11_12c.ann  \n",
      "  inflating: Collection5/20_11_12c.txt  \n",
      "  inflating: Collection5/20_11_12d.ann  \n",
      "  inflating: Collection5/20_11_12d.txt  \n",
      "  inflating: Collection5/20_11_12i.ann  \n",
      "  inflating: Collection5/20_11_12i.txt  \n",
      "  inflating: Collection5/210.ann     \n",
      "  inflating: Collection5/210.txt     \n",
      "  inflating: Collection5/211.ann     \n",
      "  inflating: Collection5/211.txt     \n",
      "  inflating: Collection5/212.ann     \n",
      "  inflating: Collection5/212.txt     \n",
      "  inflating: Collection5/213.ann     \n",
      "  inflating: Collection5/213.txt     \n",
      "  inflating: Collection5/214.ann     \n",
      "  inflating: Collection5/214.txt     \n",
      "  inflating: Collection5/215.ann     \n",
      "  inflating: Collection5/215.txt     \n",
      "  inflating: Collection5/216.ann     \n",
      "  inflating: Collection5/216.txt     \n",
      "  inflating: Collection5/217.ann     \n",
      "  inflating: Collection5/217.txt     \n",
      "  inflating: Collection5/218.ann     \n",
      "  inflating: Collection5/218.txt     \n",
      "  inflating: Collection5/219.ann     \n",
      "  inflating: Collection5/219.txt     \n",
      "  inflating: Collection5/21_11_12c.ann  \n",
      "  inflating: Collection5/21_11_12c.txt  \n",
      "  inflating: Collection5/21_11_12h.ann  \n",
      "  inflating: Collection5/21_11_12h.txt  \n",
      "  inflating: Collection5/21_11_12i.ann  \n",
      "  inflating: Collection5/21_11_12i.txt  \n",
      "  inflating: Collection5/21_11_12j.ann  \n",
      "  inflating: Collection5/21_11_12j.txt  \n",
      "  inflating: Collection5/220.ann     \n",
      "  inflating: Collection5/220.txt     \n",
      "  inflating: Collection5/221.ann     \n",
      "  inflating: Collection5/221.txt     \n",
      "  inflating: Collection5/222.ann     \n",
      "  inflating: Collection5/222.txt     \n",
      "  inflating: Collection5/223.ann     \n",
      "  inflating: Collection5/223.txt     \n",
      "  inflating: Collection5/224.ann     \n",
      "  inflating: Collection5/224.txt     \n",
      "  inflating: Collection5/225.ann     \n",
      "  inflating: Collection5/225.txt     \n",
      "  inflating: Collection5/226.ann     \n",
      "  inflating: Collection5/226.txt     \n",
      "  inflating: Collection5/227.ann     \n",
      "  inflating: Collection5/227.txt     \n",
      "  inflating: Collection5/228.ann     \n",
      "  inflating: Collection5/228.txt     \n",
      "  inflating: Collection5/229.ann     \n",
      "  inflating: Collection5/229.txt     \n",
      "  inflating: Collection5/22_11_12a.ann  \n",
      "  inflating: Collection5/22_11_12a.txt  \n",
      "  inflating: Collection5/22_11_12c.ann  \n",
      "  inflating: Collection5/22_11_12c.txt  \n",
      "  inflating: Collection5/22_11_12d.ann  \n",
      "  inflating: Collection5/22_11_12d.txt  \n",
      "  inflating: Collection5/22_11_12g.ann  \n",
      "  inflating: Collection5/22_11_12g.txt  \n",
      "  inflating: Collection5/22_11_12h.ann  \n",
      "  inflating: Collection5/22_11_12h.txt  \n",
      "  inflating: Collection5/22_11_12i.ann  \n",
      "  inflating: Collection5/22_11_12i.txt  \n",
      "  inflating: Collection5/22_11_12j.ann  \n",
      "  inflating: Collection5/22_11_12j.txt  \n",
      "  inflating: Collection5/230.ann     \n",
      "  inflating: Collection5/230.txt     \n",
      "  inflating: Collection5/231.ann     \n",
      "  inflating: Collection5/231.txt     \n",
      "  inflating: Collection5/232.ann     \n",
      "  inflating: Collection5/232.txt     \n",
      "  inflating: Collection5/233.ann     \n",
      "  inflating: Collection5/233.txt     \n",
      "  inflating: Collection5/234.ann     \n",
      "  inflating: Collection5/234.txt     \n",
      "  inflating: Collection5/235.ann     \n",
      "  inflating: Collection5/235.txt     \n",
      "  inflating: Collection5/236.ann     \n",
      "  inflating: Collection5/236.txt     \n",
      "  inflating: Collection5/237.ann     \n",
      "  inflating: Collection5/237.txt     \n",
      "  inflating: Collection5/238.ann     \n",
      "  inflating: Collection5/238.txt     \n",
      "  inflating: Collection5/239.ann     \n",
      "  inflating: Collection5/239.txt     \n",
      "  inflating: Collection5/23_11_12a.ann  \n",
      "  inflating: Collection5/23_11_12a.txt  \n",
      "  inflating: Collection5/23_11_12b.ann  \n",
      "  inflating: Collection5/23_11_12b.txt  \n",
      "  inflating: Collection5/23_11_12c.ann  \n",
      "  inflating: Collection5/23_11_12c.txt  \n",
      "  inflating: Collection5/23_11_12d.ann  \n",
      "  inflating: Collection5/23_11_12d.txt  \n",
      "  inflating: Collection5/23_11_12e.ann  \n",
      "  inflating: Collection5/23_11_12e.txt  \n",
      "  inflating: Collection5/23_11_12f.ann  \n",
      "  inflating: Collection5/23_11_12f.txt  \n",
      "  inflating: Collection5/240.ann     \n",
      "  inflating: Collection5/240.txt     \n",
      "  inflating: Collection5/241.ann     \n",
      "  inflating: Collection5/241.txt     \n",
      "  inflating: Collection5/242.ann     \n",
      "  inflating: Collection5/242.txt     \n",
      "  inflating: Collection5/243.ann     \n",
      "  inflating: Collection5/243.txt     \n",
      "  inflating: Collection5/244.ann     \n",
      "  inflating: Collection5/244.txt     \n",
      "  inflating: Collection5/245.ann     \n",
      "  inflating: Collection5/245.txt     \n",
      "  inflating: Collection5/246.ann     \n",
      "  inflating: Collection5/246.txt     \n",
      "  inflating: Collection5/247.ann     \n",
      "  inflating: Collection5/247.txt     \n",
      "  inflating: Collection5/248.ann     \n",
      "  inflating: Collection5/248.txt     \n",
      "  inflating: Collection5/249.ann     \n",
      "  inflating: Collection5/249.txt     \n",
      "  inflating: Collection5/250.ann     \n",
      "  inflating: Collection5/250.txt     \n",
      "  inflating: Collection5/251.ann     \n",
      "  inflating: Collection5/251.txt     \n",
      "  inflating: Collection5/252.ann     \n",
      "  inflating: Collection5/252.txt     \n",
      "  inflating: Collection5/253.ann     \n",
      "  inflating: Collection5/253.txt     \n",
      "  inflating: Collection5/254.ann     \n",
      "  inflating: Collection5/254.txt     \n",
      "  inflating: Collection5/255.ann     \n",
      "  inflating: Collection5/255.txt     \n",
      "  inflating: Collection5/256.ann     \n",
      "  inflating: Collection5/256.txt     \n",
      "  inflating: Collection5/257.ann     \n",
      "  inflating: Collection5/257.txt     \n",
      "  inflating: Collection5/258.ann     \n",
      "  inflating: Collection5/258.txt     \n",
      "  inflating: Collection5/259.ann     \n",
      "  inflating: Collection5/259.txt     \n",
      "  inflating: Collection5/25_12_12a.ann  \n",
      "  inflating: Collection5/25_12_12a.txt  \n",
      "  inflating: Collection5/25_12_12c.ann  \n",
      "  inflating: Collection5/25_12_12c.txt  \n",
      "  inflating: Collection5/25_12_12d.ann  \n",
      "  inflating: Collection5/25_12_12d.txt  \n",
      "  inflating: Collection5/25_12_12e.ann  \n",
      "  inflating: Collection5/25_12_12e.txt  \n",
      "  inflating: Collection5/260.ann     \n",
      "  inflating: Collection5/260.txt     \n",
      "  inflating: Collection5/261.ann     \n",
      "  inflating: Collection5/261.txt     \n",
      "  inflating: Collection5/262.ann     \n",
      "  inflating: Collection5/262.txt     \n",
      "  inflating: Collection5/263.ann     \n",
      "  inflating: Collection5/263.txt     \n",
      "  inflating: Collection5/264.ann     \n",
      "  inflating: Collection5/264.txt     \n",
      "  inflating: Collection5/265.ann     \n",
      "  inflating: Collection5/265.txt     \n",
      "  inflating: Collection5/266.ann     \n",
      "  inflating: Collection5/266.txt     \n",
      "  inflating: Collection5/267.ann     \n",
      "  inflating: Collection5/267.txt     \n",
      "  inflating: Collection5/268.ann     \n",
      "  inflating: Collection5/268.txt     \n",
      "  inflating: Collection5/269.ann     \n",
      "  inflating: Collection5/269.txt     \n",
      "  inflating: Collection5/26_11_12b.ann  \n",
      "  inflating: Collection5/26_11_12b.txt  \n",
      "  inflating: Collection5/26_11_12c.ann  \n",
      "  inflating: Collection5/26_11_12c.txt  \n",
      "  inflating: Collection5/26_11_12e.ann  \n",
      "  inflating: Collection5/26_11_12e.txt  \n",
      "  inflating: Collection5/26_11_12f.ann  \n",
      "  inflating: Collection5/26_11_12f.txt  \n",
      "  inflating: Collection5/270.ann     \n",
      "  inflating: Collection5/270.txt     \n",
      "  inflating: Collection5/271.ann     \n",
      "  inflating: Collection5/271.txt     \n",
      "  inflating: Collection5/272.ann     \n",
      "  inflating: Collection5/272.txt     \n",
      "  inflating: Collection5/273.ann     \n",
      "  inflating: Collection5/273.txt     \n",
      "  inflating: Collection5/274.ann     \n",
      "  inflating: Collection5/274.txt     \n",
      "  inflating: Collection5/275.ann     \n",
      "  inflating: Collection5/275.txt     \n",
      "  inflating: Collection5/276.ann     \n",
      "  inflating: Collection5/276.txt     \n",
      "  inflating: Collection5/277.ann     \n",
      "  inflating: Collection5/277.txt     \n",
      "  inflating: Collection5/278.ann     \n",
      "  inflating: Collection5/278.txt     \n",
      "  inflating: Collection5/279.ann     \n",
      "  inflating: Collection5/279.txt     \n",
      "  inflating: Collection5/27_11_12a.ann  \n",
      "  inflating: Collection5/27_11_12a.txt  \n",
      "  inflating: Collection5/27_11_12c.ann  \n",
      "  inflating: Collection5/27_11_12c.txt  \n",
      "  inflating: Collection5/27_11_12d.ann  \n",
      "  inflating: Collection5/27_11_12d.txt  \n",
      "  inflating: Collection5/27_11_12e.ann  \n",
      "  inflating: Collection5/27_11_12e.txt  \n",
      "  inflating: Collection5/27_11_12j.ann  \n",
      "  inflating: Collection5/27_11_12j.txt  \n",
      "  inflating: Collection5/280.ann     \n",
      "  inflating: Collection5/280.txt     \n",
      "  inflating: Collection5/281.ann     \n",
      "  inflating: Collection5/281.txt     \n",
      "  inflating: Collection5/282.ann     \n",
      "  inflating: Collection5/282.txt     \n",
      "  inflating: Collection5/283.ann     \n",
      "  inflating: Collection5/283.txt     \n",
      "  inflating: Collection5/284.ann     \n",
      "  inflating: Collection5/284.txt     \n",
      "  inflating: Collection5/285.ann     \n",
      "  inflating: Collection5/285.txt     \n",
      "  inflating: Collection5/286.ann     \n",
      "  inflating: Collection5/286.txt     \n",
      "  inflating: Collection5/287.ann     \n",
      "  inflating: Collection5/287.txt     \n",
      "  inflating: Collection5/288.ann     \n",
      "  inflating: Collection5/288.txt     \n",
      "  inflating: Collection5/289.ann     \n",
      "  inflating: Collection5/289.txt     \n",
      "  inflating: Collection5/28_11_12a.ann  \n",
      "  inflating: Collection5/28_11_12a.txt  \n",
      "  inflating: Collection5/28_11_12f.ann  \n",
      "  inflating: Collection5/28_11_12f.txt  \n",
      "  inflating: Collection5/28_11_12g.ann  \n",
      "  inflating: Collection5/28_11_12g.txt  \n",
      "  inflating: Collection5/28_11_12h.ann  \n",
      "  inflating: Collection5/28_11_12h.txt  \n",
      "  inflating: Collection5/28_11_12i.ann  \n",
      "  inflating: Collection5/28_11_12i.txt  \n",
      "  inflating: Collection5/28_11_12j.ann  \n",
      "  inflating: Collection5/28_11_12j.txt  \n",
      "  inflating: Collection5/290.ann     \n",
      "  inflating: Collection5/290.txt     \n",
      "  inflating: Collection5/291.ann     \n",
      "  inflating: Collection5/291.txt     \n",
      "  inflating: Collection5/292.ann     \n",
      "  inflating: Collection5/292.txt     \n",
      "  inflating: Collection5/293.ann     \n",
      "  inflating: Collection5/293.txt     \n",
      "  inflating: Collection5/294.ann     \n",
      "  inflating: Collection5/294.txt     \n",
      "  inflating: Collection5/295.ann     \n",
      "  inflating: Collection5/295.txt     \n",
      "  inflating: Collection5/296.ann     \n",
      "  inflating: Collection5/296.txt     \n",
      "  inflating: Collection5/297.ann     \n",
      "  inflating: Collection5/297.txt     \n",
      "  inflating: Collection5/298.ann     \n",
      "  inflating: Collection5/298.txt     \n",
      "  inflating: Collection5/299.ann     \n",
      "  inflating: Collection5/299.txt     \n",
      "  inflating: Collection5/29_11_12a.ann  \n",
      "  inflating: Collection5/29_11_12a.txt  \n",
      "  inflating: Collection5/29_11_12b.ann  \n",
      "  inflating: Collection5/29_11_12b.txt  \n",
      "  inflating: Collection5/300.ann     \n",
      "  inflating: Collection5/300.txt     \n",
      "  inflating: Collection5/301.ann     \n",
      "  inflating: Collection5/301.txt     \n",
      "  inflating: Collection5/302.ann     \n",
      "  inflating: Collection5/302.txt     \n",
      "  inflating: Collection5/303.ann     \n",
      "  inflating: Collection5/303.txt     \n",
      "  inflating: Collection5/304.ann     \n",
      "  inflating: Collection5/304.txt     \n",
      "  inflating: Collection5/305.ann     \n",
      "  inflating: Collection5/305.txt     \n",
      "  inflating: Collection5/306.ann     \n",
      "  inflating: Collection5/306.txt     \n",
      "  inflating: Collection5/307.ann     \n",
      "  inflating: Collection5/307.txt     \n",
      "  inflating: Collection5/308.ann     \n",
      "  inflating: Collection5/308.txt     \n",
      "  inflating: Collection5/309.ann     \n",
      "  inflating: Collection5/309.txt     \n",
      "  inflating: Collection5/30_11_12b.ann  \n",
      "  inflating: Collection5/30_11_12b.txt  \n",
      "  inflating: Collection5/30_11_12h.ann  \n",
      "  inflating: Collection5/30_11_12h.txt  \n",
      "  inflating: Collection5/30_11_12i.ann  \n",
      "  inflating: Collection5/30_11_12i.txt  \n",
      "  inflating: Collection5/310.ann     \n",
      "  inflating: Collection5/310.txt     \n",
      "  inflating: Collection5/311.ann     \n",
      "  inflating: Collection5/311.txt     \n",
      "  inflating: Collection5/312.ann     \n",
      "  inflating: Collection5/312.txt     \n",
      "  inflating: Collection5/313.ann     \n",
      "  inflating: Collection5/313.txt     \n",
      "  inflating: Collection5/314.ann     \n",
      "  inflating: Collection5/314.txt     \n",
      "  inflating: Collection5/315.ann     \n",
      "  inflating: Collection5/315.txt     \n",
      "  inflating: Collection5/316.ann     \n",
      "  inflating: Collection5/316.txt     \n",
      "  inflating: Collection5/317.ann     \n",
      "  inflating: Collection5/317.txt     \n",
      "  inflating: Collection5/318.ann     \n",
      "  inflating: Collection5/318.txt     \n",
      "  inflating: Collection5/319.ann     \n",
      "  inflating: Collection5/319.txt     \n",
      "  inflating: Collection5/320.ann     \n",
      "  inflating: Collection5/320.txt     \n",
      "  inflating: Collection5/321.ann     \n",
      "  inflating: Collection5/321.txt     \n",
      "  inflating: Collection5/322.ann     \n",
      "  inflating: Collection5/322.txt     \n",
      "  inflating: Collection5/323.ann     \n",
      "  inflating: Collection5/323.txt     \n",
      "  inflating: Collection5/324.ann     \n",
      "  inflating: Collection5/324.txt     \n",
      "  inflating: Collection5/325.ann     \n",
      "  inflating: Collection5/325.txt     \n",
      "  inflating: Collection5/326.ann     \n",
      "  inflating: Collection5/326.txt     \n",
      "  inflating: Collection5/327.ann     \n",
      "  inflating: Collection5/327.txt     \n",
      "  inflating: Collection5/328.ann     \n",
      "  inflating: Collection5/328.txt     \n",
      "  inflating: Collection5/329.ann     \n",
      "  inflating: Collection5/329.txt     \n",
      "  inflating: Collection5/330.ann     \n",
      "  inflating: Collection5/330.txt     \n",
      "  inflating: Collection5/331.ann     \n",
      "  inflating: Collection5/331.txt     \n",
      "  inflating: Collection5/332.ann     \n",
      "  inflating: Collection5/332.txt     \n",
      "  inflating: Collection5/333.ann     \n",
      "  inflating: Collection5/333.txt     \n",
      "  inflating: Collection5/334.ann     \n",
      "  inflating: Collection5/334.txt     \n",
      "  inflating: Collection5/335.ann     \n",
      "  inflating: Collection5/335.txt     \n",
      "  inflating: Collection5/336.ann     \n",
      "  inflating: Collection5/336.txt     \n",
      "  inflating: Collection5/337.ann     \n",
      "  inflating: Collection5/337.txt     \n",
      "  inflating: Collection5/338.ann     \n",
      "  inflating: Collection5/338.txt     \n",
      "  inflating: Collection5/339.ann     \n",
      "  inflating: Collection5/339.txt     \n",
      "  inflating: Collection5/340.ann     \n",
      "  inflating: Collection5/340.txt     \n",
      "  inflating: Collection5/341.ann     \n",
      "  inflating: Collection5/341.txt     \n",
      "  inflating: Collection5/342.ann     \n",
      "  inflating: Collection5/342.txt     \n",
      "  inflating: Collection5/343.ann     \n",
      "  inflating: Collection5/343.txt     \n",
      "  inflating: Collection5/344.ann     \n",
      "  inflating: Collection5/344.txt     \n",
      "  inflating: Collection5/345.ann     \n",
      "  inflating: Collection5/345.txt     \n",
      "  inflating: Collection5/346.ann     \n",
      "  inflating: Collection5/346.txt     \n",
      "  inflating: Collection5/347.ann     \n",
      "  inflating: Collection5/347.txt     \n",
      "  inflating: Collection5/348.ann     \n",
      "  inflating: Collection5/348.txt     \n",
      "  inflating: Collection5/349.ann     \n",
      "  inflating: Collection5/349.txt     \n",
      "  inflating: Collection5/350.ann     \n",
      "  inflating: Collection5/350.txt     \n",
      "  inflating: Collection5/351.ann     \n",
      "  inflating: Collection5/351.txt     \n",
      "  inflating: Collection5/352.ann     \n",
      "  inflating: Collection5/352.txt     \n",
      "  inflating: Collection5/353.ann     \n",
      "  inflating: Collection5/353.txt     \n",
      "  inflating: Collection5/354.ann     \n",
      "  inflating: Collection5/354.txt     \n",
      "  inflating: Collection5/355.ann     \n",
      "  inflating: Collection5/355.txt     \n",
      "  inflating: Collection5/356.ann     \n",
      "  inflating: Collection5/356.txt     \n",
      "  inflating: Collection5/357.ann     \n",
      "  inflating: Collection5/357.txt     \n",
      "  inflating: Collection5/358.ann     \n",
      "  inflating: Collection5/358.txt     \n",
      "  inflating: Collection5/359.ann     \n",
      "  inflating: Collection5/359.txt     \n",
      "  inflating: Collection5/360.ann     \n",
      "  inflating: Collection5/360.txt     \n",
      "  inflating: Collection5/361.ann     \n",
      "  inflating: Collection5/361.txt     \n",
      "  inflating: Collection5/362.ann     \n",
      "  inflating: Collection5/362.txt     \n",
      "  inflating: Collection5/363.ann     \n",
      "  inflating: Collection5/363.txt     \n",
      "  inflating: Collection5/364.ann     \n",
      "  inflating: Collection5/364.txt     \n",
      "  inflating: Collection5/365.ann     \n",
      "  inflating: Collection5/365.txt     \n",
      "  inflating: Collection5/366.ann     \n",
      "  inflating: Collection5/366.txt     \n",
      "  inflating: Collection5/367.ann     \n",
      "  inflating: Collection5/367.txt     \n",
      "  inflating: Collection5/368.ann     \n",
      "  inflating: Collection5/368.txt     \n",
      "  inflating: Collection5/369.ann     \n",
      "  inflating: Collection5/369.txt     \n",
      "  inflating: Collection5/370.ann     \n",
      "  inflating: Collection5/370.txt     \n",
      "  inflating: Collection5/371.ann     \n",
      "  inflating: Collection5/371.txt     \n",
      "  inflating: Collection5/372.ann     \n",
      "  inflating: Collection5/372.txt     \n",
      "  inflating: Collection5/373.ann     \n",
      "  inflating: Collection5/373.txt     \n",
      "  inflating: Collection5/374.ann     \n",
      "  inflating: Collection5/374.txt     \n",
      "  inflating: Collection5/375.ann     \n",
      "  inflating: Collection5/375.txt     \n",
      "  inflating: Collection5/376.ann     \n",
      "  inflating: Collection5/376.txt     \n",
      "  inflating: Collection5/377.ann     \n",
      "  inflating: Collection5/377.txt     \n",
      "  inflating: Collection5/378.ann     \n",
      "  inflating: Collection5/378.txt     \n",
      "  inflating: Collection5/379.ann     \n",
      "  inflating: Collection5/379.txt     \n",
      "  inflating: Collection5/380.ann     \n",
      "  inflating: Collection5/380.txt     \n",
      "  inflating: Collection5/381.ann     \n",
      "  inflating: Collection5/381.txt     \n",
      "  inflating: Collection5/382.ann     \n",
      "  inflating: Collection5/382.txt     \n",
      "  inflating: Collection5/383.ann     \n",
      "  inflating: Collection5/383.txt     \n",
      "  inflating: Collection5/384.ann     \n",
      "  inflating: Collection5/384.txt     \n",
      "  inflating: Collection5/385.ann     \n",
      "  inflating: Collection5/385.txt     \n",
      "  inflating: Collection5/386.ann     \n",
      "  inflating: Collection5/386.txt     \n",
      "  inflating: Collection5/387.ann     \n",
      "  inflating: Collection5/387.txt     \n",
      "  inflating: Collection5/388.ann     \n",
      "  inflating: Collection5/388.txt     \n",
      "  inflating: Collection5/389.ann     \n",
      "  inflating: Collection5/389.txt     \n",
      "  inflating: Collection5/390.ann     \n",
      "  inflating: Collection5/390.txt     \n",
      "  inflating: Collection5/391.ann     \n",
      "  inflating: Collection5/391.txt     \n",
      "  inflating: Collection5/392.ann     \n",
      "  inflating: Collection5/392.txt     \n",
      "  inflating: Collection5/393.ann     \n",
      "  inflating: Collection5/393.txt     \n",
      "  inflating: Collection5/394.ann     \n",
      "  inflating: Collection5/394.txt     \n",
      "  inflating: Collection5/395.ann     \n",
      "  inflating: Collection5/395.txt     \n",
      "  inflating: Collection5/396.ann     \n",
      "  inflating: Collection5/396.txt     \n",
      "  inflating: Collection5/397.ann     \n",
      "  inflating: Collection5/397.txt     \n",
      "  inflating: Collection5/398.ann     \n",
      "  inflating: Collection5/398.txt     \n",
      "  inflating: Collection5/399.ann     \n",
      "  inflating: Collection5/399.txt     \n",
      "  inflating: Collection5/400.ann     \n",
      "  inflating: Collection5/400.txt     \n",
      "  inflating: Collection5/401.ann     \n",
      "  inflating: Collection5/401.txt     \n",
      "  inflating: Collection5/402.ann     \n",
      "  inflating: Collection5/402.txt     \n",
      "  inflating: Collection5/403.ann     \n",
      "  inflating: Collection5/403.txt     \n",
      "  inflating: Collection5/404.ann     \n",
      "  inflating: Collection5/404.txt     \n",
      "  inflating: Collection5/405.ann     \n",
      "  inflating: Collection5/405.txt     \n",
      "  inflating: Collection5/406.ann     \n",
      "  inflating: Collection5/406.txt     \n",
      "  inflating: Collection5/407.ann     \n",
      "  inflating: Collection5/407.txt     \n",
      "  inflating: Collection5/408.ann     \n",
      "  inflating: Collection5/408.txt     \n",
      "  inflating: Collection5/409.ann     \n",
      "  inflating: Collection5/409.txt     \n",
      "  inflating: Collection5/410.ann     \n",
      "  inflating: Collection5/410.txt     \n",
      "  inflating: Collection5/411.ann     \n",
      "  inflating: Collection5/411.txt     \n",
      "  inflating: Collection5/412.ann     \n",
      "  inflating: Collection5/412.txt     \n",
      "  inflating: Collection5/413.ann     \n",
      "  inflating: Collection5/413.txt     \n",
      "  inflating: Collection5/414.ann     \n",
      "  inflating: Collection5/414.txt     \n",
      "  inflating: Collection5/415.ann     \n",
      "  inflating: Collection5/415.txt     \n",
      "  inflating: Collection5/416.ann     \n",
      "  inflating: Collection5/416.txt     \n",
      "  inflating: Collection5/417.ann     \n",
      "  inflating: Collection5/417.txt     \n",
      "  inflating: Collection5/418.ann     \n",
      "  inflating: Collection5/418.txt     \n",
      "  inflating: Collection5/419.ann     \n",
      "  inflating: Collection5/419.txt     \n",
      "  inflating: Collection5/420.ann     \n",
      "  inflating: Collection5/420.txt     \n",
      "  inflating: Collection5/421.ann     \n",
      "  inflating: Collection5/421.txt     \n",
      "  inflating: Collection5/422.ann     \n",
      "  inflating: Collection5/422.txt     \n",
      "  inflating: Collection5/423.ann     \n",
      "  inflating: Collection5/423.txt     \n",
      "  inflating: Collection5/424.ann     \n",
      "  inflating: Collection5/424.txt     \n",
      "  inflating: Collection5/425.ann     \n",
      "  inflating: Collection5/425.txt     \n",
      "  inflating: Collection5/426.ann     \n",
      "  inflating: Collection5/426.txt     \n",
      "  inflating: Collection5/427.ann     \n",
      "  inflating: Collection5/427.txt     \n",
      "  inflating: Collection5/428.ann     \n",
      "  inflating: Collection5/428.txt     \n",
      "  inflating: Collection5/429.ann     \n",
      "  inflating: Collection5/429.txt     \n",
      "  inflating: Collection5/430.ann     \n",
      "  inflating: Collection5/430.txt     \n",
      "  inflating: Collection5/431.ann     \n",
      "  inflating: Collection5/431.txt     \n",
      "  inflating: Collection5/432.ann     \n",
      "  inflating: Collection5/432.txt     \n",
      "  inflating: Collection5/433.ann     \n",
      "  inflating: Collection5/433.txt     \n",
      "  inflating: Collection5/434.ann     \n",
      "  inflating: Collection5/434.txt     \n",
      "  inflating: Collection5/435.ann     \n",
      "  inflating: Collection5/435.txt     \n",
      "  inflating: Collection5/436.ann     \n",
      "  inflating: Collection5/436.txt     \n",
      "  inflating: Collection5/437.ann     \n",
      "  inflating: Collection5/437.txt     \n",
      "  inflating: Collection5/438.ann     \n",
      "  inflating: Collection5/438.txt     \n",
      "  inflating: Collection5/439.ann     \n",
      "  inflating: Collection5/439.txt     \n",
      "  inflating: Collection5/440.ann     \n",
      "  inflating: Collection5/440.txt     \n",
      "  inflating: Collection5/441.ann     \n",
      "  inflating: Collection5/441.txt     \n",
      "  inflating: Collection5/442.ann     \n",
      "  inflating: Collection5/442.txt     \n",
      "  inflating: Collection5/443.ann     \n",
      "  inflating: Collection5/443.txt     \n",
      "  inflating: Collection5/444.ann     \n",
      "  inflating: Collection5/444.txt     \n",
      "  inflating: Collection5/445.ann     \n",
      "  inflating: Collection5/445.txt     \n",
      "  inflating: Collection5/446.ann     \n",
      "  inflating: Collection5/446.txt     \n",
      "  inflating: Collection5/447.ann     \n",
      "  inflating: Collection5/447.txt     \n",
      "  inflating: Collection5/448.ann     \n",
      "  inflating: Collection5/448.txt     \n",
      "  inflating: Collection5/449.ann     \n",
      "  inflating: Collection5/449.txt     \n",
      "  inflating: Collection5/450.ann     \n",
      "  inflating: Collection5/450.txt     \n",
      "  inflating: Collection5/451.ann     \n",
      "  inflating: Collection5/451.txt     \n",
      "  inflating: Collection5/452.ann     \n",
      "  inflating: Collection5/452.txt     \n",
      "  inflating: Collection5/453.ann     \n",
      "  inflating: Collection5/453.txt     \n",
      "  inflating: Collection5/454.ann     \n",
      "  inflating: Collection5/454.txt     \n",
      "  inflating: Collection5/455.ann     \n",
      "  inflating: Collection5/455.txt     \n",
      "  inflating: Collection5/457.ann     \n",
      "  inflating: Collection5/457.txt     \n",
      "  inflating: Collection5/458.ann     \n",
      "  inflating: Collection5/458.txt     \n",
      "  inflating: Collection5/459.ann     \n",
      "  inflating: Collection5/459.txt     \n",
      "  inflating: Collection5/460.ann     \n",
      "  inflating: Collection5/460.txt     \n",
      "  inflating: Collection5/461.ann     \n",
      "  inflating: Collection5/461.txt     \n",
      "  inflating: Collection5/462.ann     \n",
      "  inflating: Collection5/462.txt     \n",
      "  inflating: Collection5/463.ann     \n",
      "  inflating: Collection5/463.txt     \n",
      "  inflating: Collection5/464.ann     \n",
      "  inflating: Collection5/464.txt     \n",
      "  inflating: Collection5/465.ann     \n",
      "  inflating: Collection5/465.txt     \n",
      "  inflating: Collection5/466.ann     \n",
      "  inflating: Collection5/466.txt     \n",
      "  inflating: Collection5/467.ann     \n",
      "  inflating: Collection5/467.txt     \n",
      "  inflating: Collection5/468.ann     \n",
      "  inflating: Collection5/468.txt     \n",
      "  inflating: Collection5/469.ann     \n",
      "  inflating: Collection5/469.txt     \n",
      "  inflating: Collection5/470.ann     \n",
      "  inflating: Collection5/470.txt     \n",
      "  inflating: Collection5/471.ann     \n",
      "  inflating: Collection5/471.txt     \n",
      "  inflating: Collection5/472.ann     \n",
      "  inflating: Collection5/472.txt     \n",
      "  inflating: Collection5/473.ann     \n",
      "  inflating: Collection5/473.txt     \n",
      "  inflating: Collection5/474.ann     \n",
      "  inflating: Collection5/474.txt     \n",
      "  inflating: Collection5/475.ann     \n",
      "  inflating: Collection5/475.txt     \n",
      "  inflating: Collection5/476.ann     \n",
      "  inflating: Collection5/476.txt     \n",
      "  inflating: Collection5/477.ann     \n",
      "  inflating: Collection5/477.txt     \n",
      "  inflating: Collection5/478.ann     \n",
      "  inflating: Collection5/478.txt     \n",
      "  inflating: Collection5/479.ann     \n",
      "  inflating: Collection5/479.txt     \n",
      "  inflating: Collection5/480.ann     \n",
      "  inflating: Collection5/480.txt     \n",
      "  inflating: Collection5/481.ann     \n",
      "  inflating: Collection5/481.txt     \n",
      "  inflating: Collection5/482.ann     \n",
      "  inflating: Collection5/482.txt     \n",
      "  inflating: Collection5/483.ann     \n",
      "  inflating: Collection5/483.txt     \n",
      "  inflating: Collection5/484.ann     \n",
      "  inflating: Collection5/484.txt     \n",
      "  inflating: Collection5/485.ann     \n",
      "  inflating: Collection5/485.txt     \n",
      "  inflating: Collection5/486.ann     \n",
      "  inflating: Collection5/486.txt     \n",
      "  inflating: Collection5/487.ann     \n",
      "  inflating: Collection5/487.txt     \n",
      "  inflating: Collection5/488.ann     \n",
      "  inflating: Collection5/488.txt     \n",
      "  inflating: Collection5/489.ann     \n",
      "  inflating: Collection5/489.txt     \n",
      "  inflating: Collection5/490.ann     \n",
      "  inflating: Collection5/490.txt     \n",
      "  inflating: Collection5/491.ann     \n",
      "  inflating: Collection5/491.txt     \n",
      "  inflating: Collection5/492.ann     \n",
      "  inflating: Collection5/492.txt     \n",
      "  inflating: Collection5/493.ann     \n",
      "  inflating: Collection5/493.txt     \n",
      "  inflating: Collection5/494.ann     \n",
      "  inflating: Collection5/494.txt     \n",
      "  inflating: Collection5/495.ann     \n",
      "  inflating: Collection5/495.txt     \n",
      "  inflating: Collection5/496.ann     \n",
      "  inflating: Collection5/496.txt     \n",
      "  inflating: Collection5/497.ann     \n",
      "  inflating: Collection5/497.txt     \n",
      "  inflating: Collection5/498.ann     \n",
      "  inflating: Collection5/498.txt     \n",
      "  inflating: Collection5/499.ann     \n",
      "  inflating: Collection5/499.txt     \n",
      "  inflating: Collection5/500.ann     \n",
      "  inflating: Collection5/500.txt     \n",
      "  inflating: Collection5/501.ann     \n",
      "  inflating: Collection5/501.txt     \n",
      "  inflating: Collection5/502.ann     \n",
      "  inflating: Collection5/502.txt     \n",
      "  inflating: Collection5/503.ann     \n",
      "  inflating: Collection5/503.txt     \n",
      "  inflating: Collection5/504.ann     \n",
      "  inflating: Collection5/504.txt     \n",
      "  inflating: Collection5/505.ann     \n",
      "  inflating: Collection5/505.txt     \n",
      "  inflating: Collection5/506.ann     \n",
      "  inflating: Collection5/506.txt     \n",
      "  inflating: Collection5/507.ann     \n",
      "  inflating: Collection5/507.txt     \n",
      "  inflating: Collection5/508.ann     \n",
      "  inflating: Collection5/508.txt     \n",
      "  inflating: Collection5/509.ann     \n",
      "  inflating: Collection5/509.txt     \n",
      "  inflating: Collection5/510.ann     \n",
      "  inflating: Collection5/510.txt     \n",
      "  inflating: Collection5/511.ann     \n",
      "  inflating: Collection5/511.txt     \n",
      "  inflating: Collection5/512.ann     \n",
      "  inflating: Collection5/512.txt     \n",
      "  inflating: Collection5/513.ann     \n",
      "  inflating: Collection5/513.txt     \n",
      "  inflating: Collection5/514.ann     \n",
      "  inflating: Collection5/514.txt     \n",
      "  inflating: Collection5/515.ann     \n",
      "  inflating: Collection5/515.txt     \n",
      "  inflating: Collection5/516.ann     \n",
      "  inflating: Collection5/516.txt     \n",
      "  inflating: Collection5/517.ann     \n",
      "  inflating: Collection5/517.txt     \n",
      "  inflating: Collection5/518.ann     \n",
      "  inflating: Collection5/518.txt     \n",
      "  inflating: Collection5/519.ann     \n",
      "  inflating: Collection5/519.txt     \n",
      "  inflating: Collection5/520.ann     \n",
      "  inflating: Collection5/520.txt     \n",
      "  inflating: Collection5/521.ann     \n",
      "  inflating: Collection5/521.txt     \n",
      "  inflating: Collection5/522.ann     \n",
      "  inflating: Collection5/522.txt     \n",
      "  inflating: Collection5/523.ann     \n",
      "  inflating: Collection5/523.txt     \n",
      "  inflating: Collection5/524.ann     \n",
      "  inflating: Collection5/524.txt     \n",
      "  inflating: Collection5/525.ann     \n",
      "  inflating: Collection5/525.txt     \n",
      "  inflating: Collection5/526.ann     \n",
      "  inflating: Collection5/526.txt     \n",
      "  inflating: Collection5/527.ann     \n",
      "  inflating: Collection5/527.txt     \n",
      "  inflating: Collection5/528.ann     \n",
      "  inflating: Collection5/528.txt     \n",
      "  inflating: Collection5/529.ann     \n",
      "  inflating: Collection5/529.txt     \n",
      "  inflating: Collection5/530.ann     \n",
      "  inflating: Collection5/530.txt     \n",
      "  inflating: Collection5/531.ann     \n",
      "  inflating: Collection5/531.txt     \n",
      "  inflating: Collection5/532.ann     \n",
      "  inflating: Collection5/532.txt     \n",
      "  inflating: Collection5/533 (!).ann  \n",
      "  inflating: Collection5/533 (!).txt  \n",
      "  inflating: Collection5/534.ann     \n",
      "  inflating: Collection5/534.txt     \n",
      "  inflating: Collection5/535.ann     \n",
      "  inflating: Collection5/535.txt     \n",
      "  inflating: Collection5/536.ann     \n",
      "  inflating: Collection5/536.txt     \n",
      "  inflating: Collection5/537.ann     \n",
      "  inflating: Collection5/537.txt     \n",
      "  inflating: Collection5/538.ann     \n",
      "  inflating: Collection5/538.txt     \n",
      "  inflating: Collection5/539.ann     \n",
      "  inflating: Collection5/539.txt     \n",
      "  inflating: Collection5/540.ann     \n",
      "  inflating: Collection5/540.txt     \n",
      "  inflating: Collection5/541.ann     \n",
      "  inflating: Collection5/541.txt     \n",
      "  inflating: Collection5/542.ann     \n",
      "  inflating: Collection5/542.txt     \n",
      "  inflating: Collection5/543.ann     \n",
      "  inflating: Collection5/543.txt     \n",
      "  inflating: Collection5/544.ann     \n",
      "  inflating: Collection5/544.txt     \n",
      "  inflating: Collection5/545.ann     \n",
      "  inflating: Collection5/545.txt     \n",
      "  inflating: Collection5/546.ann     \n",
      "  inflating: Collection5/546.txt     \n",
      "  inflating: Collection5/547.ann     \n",
      "  inflating: Collection5/547.txt     \n",
      "  inflating: Collection5/548.ann     \n",
      "  inflating: Collection5/548.txt     \n",
      "  inflating: Collection5/549.ann     \n",
      "  inflating: Collection5/549.txt     \n",
      "  inflating: Collection5/550.ann     \n",
      "  inflating: Collection5/550.txt     \n",
      "  inflating: Collection5/551.ann     \n",
      "  inflating: Collection5/551.txt     \n",
      "  inflating: Collection5/552.ann     \n",
      "  inflating: Collection5/552.txt     \n",
      "  inflating: Collection5/553.ann     \n",
      "  inflating: Collection5/553.txt     \n",
      "  inflating: Collection5/554.ann     \n",
      "  inflating: Collection5/554.txt     \n",
      "  inflating: Collection5/555 (!).ann  \n",
      "  inflating: Collection5/555 (!).txt  \n",
      "  inflating: Collection5/556.ann     \n",
      "  inflating: Collection5/556.txt     \n",
      "  inflating: Collection5/557.ann     \n",
      "  inflating: Collection5/557.txt     \n",
      "  inflating: Collection5/558.ann     \n",
      "  inflating: Collection5/558.txt     \n",
      "  inflating: Collection5/559.ann     \n",
      "  inflating: Collection5/559.txt     \n",
      "  inflating: Collection5/560.ann     \n",
      "  inflating: Collection5/560.txt     \n",
      "  inflating: Collection5/561.ann     \n",
      "  inflating: Collection5/561.txt     \n",
      "  inflating: Collection5/562.ann     \n",
      "  inflating: Collection5/562.txt     \n",
      "  inflating: Collection5/563.ann     \n",
      "  inflating: Collection5/563.txt     \n",
      "  inflating: Collection5/564.ann     \n",
      "  inflating: Collection5/564.txt     \n",
      "  inflating: Collection5/565.ann     \n",
      "  inflating: Collection5/565.txt     \n",
      "  inflating: Collection5/567.ann     \n",
      "  inflating: Collection5/567.txt     \n",
      "  inflating: Collection5/568.ann     \n",
      "  inflating: Collection5/568.txt     \n",
      "  inflating: Collection5/569.ann     \n",
      "  inflating: Collection5/569.txt     \n",
      "  inflating: Collection5/570.ann     \n",
      "  inflating: Collection5/570.txt     \n",
      "  inflating: Collection5/571.ann     \n",
      "  inflating: Collection5/571.txt     \n",
      "  inflating: Collection5/572.ann     \n",
      "  inflating: Collection5/572.txt     \n",
      "  inflating: Collection5/574.ann     \n",
      "  inflating: Collection5/574.txt     \n",
      "  inflating: Collection5/575.ann     \n",
      "  inflating: Collection5/575.txt     \n",
      "  inflating: Collection5/576.ann     \n",
      "  inflating: Collection5/576.txt     \n",
      "  inflating: Collection5/577.ann     \n",
      "  inflating: Collection5/577.txt     \n",
      "  inflating: Collection5/578.ann     \n",
      "  inflating: Collection5/578.txt     \n",
      "  inflating: Collection5/579.ann     \n",
      "  inflating: Collection5/579.txt     \n",
      "  inflating: Collection5/581.ann     \n",
      "  inflating: Collection5/581.txt     \n",
      "  inflating: Collection5/582.ann     \n",
      "  inflating: Collection5/582.txt     \n",
      "  inflating: Collection5/583.ann     \n",
      "  inflating: Collection5/583.txt     \n",
      "  inflating: Collection5/584 (!).ann  \n",
      "  inflating: Collection5/584 (!).txt  \n",
      "  inflating: Collection5/585.ann     \n",
      "  inflating: Collection5/585.txt     \n",
      "  inflating: Collection5/586.ann     \n",
      "  inflating: Collection5/586.txt     \n",
      "  inflating: Collection5/587.ann     \n",
      "  inflating: Collection5/587.txt     \n",
      "  inflating: Collection5/588.ann     \n",
      "  inflating: Collection5/588.txt     \n",
      "  inflating: Collection5/589.ann     \n",
      "  inflating: Collection5/589.txt     \n",
      "  inflating: Collection5/590.ann     \n",
      "  inflating: Collection5/590.txt     \n",
      "  inflating: Collection5/591.ann     \n",
      "  inflating: Collection5/591.txt     \n",
      "  inflating: Collection5/592.ann     \n",
      "  inflating: Collection5/592.txt     \n",
      "  inflating: Collection5/593.ann     \n",
      "  inflating: Collection5/593.txt     \n",
      "  inflating: Collection5/594.ann     \n",
      "  inflating: Collection5/594.txt     \n",
      "  inflating: Collection5/595.ann     \n",
      "  inflating: Collection5/595.txt     \n",
      "  inflating: Collection5/596.ann     \n",
      "  inflating: Collection5/596.txt     \n",
      "  inflating: Collection5/597.ann     \n",
      "  inflating: Collection5/597.txt     \n",
      "  inflating: Collection5/598 (!).ann  \n",
      "  inflating: Collection5/598 (!).txt  \n",
      "  inflating: Collection5/599.ann     \n",
      "  inflating: Collection5/599.txt     \n",
      "  inflating: Collection5/600.ann     \n",
      "  inflating: Collection5/600.txt     \n",
      "  inflating: Collection5/601.ann     \n",
      "  inflating: Collection5/601.txt     \n",
      "  inflating: Collection5/602.ann     \n",
      "  inflating: Collection5/602.txt     \n",
      "  inflating: Collection5/610.ann     \n",
      "  inflating: Collection5/610.txt     \n",
      "  inflating: Collection5/611.ann     \n",
      "  inflating: Collection5/611.txt     \n",
      "  inflating: Collection5/612.ann     \n",
      "  inflating: Collection5/612.txt     \n",
      "  inflating: Collection5/613.ann     \n",
      "  inflating: Collection5/613.txt     \n",
      "  inflating: Collection5/614.ann     \n",
      "  inflating: Collection5/614.txt     \n",
      "  inflating: Collection5/615.ann     \n",
      "  inflating: Collection5/615.txt     \n",
      "  inflating: Collection5/616.ann     \n",
      "  inflating: Collection5/616.txt     \n",
      "  inflating: Collection5/617.ann     \n",
      "  inflating: Collection5/617.txt     \n",
      "  inflating: Collection5/618.ann     \n",
      "  inflating: Collection5/618.txt     \n",
      "  inflating: Collection5/619.ann     \n",
      "  inflating: Collection5/619.txt     \n",
      "  inflating: Collection5/620.ann     \n",
      "  inflating: Collection5/620.txt     \n",
      "  inflating: Collection5/621.ann     \n",
      "  inflating: Collection5/621.txt     \n",
      "  inflating: Collection5/622.ann     \n",
      "  inflating: Collection5/622.txt     \n",
      "  inflating: Collection5/623.ann     \n",
      "  inflating: Collection5/623.txt     \n",
      "  inflating: Collection5/624.ann     \n",
      "  inflating: Collection5/624.txt     \n",
      "  inflating: Collection5/625.ann     \n",
      "  inflating: Collection5/625.txt     \n",
      "  inflating: Collection5/626.ann     \n",
      "  inflating: Collection5/626.txt     \n",
      "  inflating: Collection5/627.ann     \n",
      "  inflating: Collection5/627.txt     \n",
      "  inflating: Collection5/628.ann     \n",
      "  inflating: Collection5/628.txt     \n",
      "  inflating: Collection5/629.ann     \n",
      "  inflating: Collection5/629.txt     \n",
      "  inflating: Collection5/630.ann     \n",
      "  inflating: Collection5/630.txt     \n",
      "  inflating: Collection5/631.ann     \n",
      "  inflating: Collection5/631.txt     \n",
      "  inflating: Collection5/632.ann     \n",
      "  inflating: Collection5/632.txt     \n",
      "  inflating: Collection5/633.ann     \n",
      "  inflating: Collection5/633.txt     \n",
      "  inflating: Collection5/abdulatipov.ann  \n",
      "  inflating: Collection5/abdulatipov.txt  \n",
      "  inflating: Collection5/artjakov.ann  \n",
      "  inflating: Collection5/artjakov.txt  \n",
      "  inflating: Collection5/Avtovaz.ann  \n",
      "  inflating: Collection5/Avtovaz.txt  \n",
      "  inflating: Collection5/blokhin.ann  \n",
      "  inflating: Collection5/blokhin.txt  \n",
      "  inflating: Collection5/chaves.ann  \n",
      "  inflating: Collection5/chaves.txt  \n",
      "  inflating: Collection5/chirkunov.ann  \n",
      "  inflating: Collection5/chirkunov.txt  \n",
      "  inflating: Collection5/kamchatka.ann  \n",
      "  inflating: Collection5/kamchatka.txt  \n",
      "  inflating: Collection5/klinton.ann  \n",
      "  inflating: Collection5/klinton.txt  \n",
      "  inflating: Collection5/kuleshov.ann  \n",
      "  inflating: Collection5/kuleshov.txt  \n",
      "  inflating: Collection5/last_01.ann  \n",
      "  inflating: Collection5/last_01.txt  \n",
      "  inflating: Collection5/last_02.ann  \n",
      "  inflating: Collection5/last_02.txt  \n",
      "  inflating: Collection5/last_03.ann  \n",
      "  inflating: Collection5/last_03.txt  \n",
      "  inflating: Collection5/last_04.ann  \n",
      "  inflating: Collection5/last_04.txt  \n",
      "  inflating: Collection5/last_05.ann  \n",
      "  inflating: Collection5/last_05.txt  \n",
      "  inflating: Collection5/last_06.ann  \n",
      "  inflating: Collection5/last_06.txt  \n",
      "  inflating: Collection5/last_07_new.ann  \n",
      "  inflating: Collection5/last_07_new.txt  \n",
      "  inflating: Collection5/last_08.ann  \n",
      "  inflating: Collection5/last_08.txt  \n",
      "  inflating: Collection5/last_09.ann  \n",
      "  inflating: Collection5/last_09.txt  \n",
      "  inflating: Collection5/last_10.ann  \n",
      "  inflating: Collection5/last_10.txt  \n",
      "  inflating: Collection5/last_11.ann  \n",
      "  inflating: Collection5/last_11.txt  \n",
      "  inflating: Collection5/last_12.ann  \n",
      "  inflating: Collection5/last_12.txt  \n",
      "  inflating: Collection5/last_13.ann  \n",
      "  inflating: Collection5/last_13.txt  \n",
      "  inflating: Collection5/last_14.ann  \n",
      "  inflating: Collection5/last_14.txt  \n",
      "  inflating: Collection5/last_15.ann  \n",
      "  inflating: Collection5/last_15.txt  \n",
      "  inflating: Collection5/last_16.ann  \n",
      "  inflating: Collection5/last_16.txt  \n",
      "  inflating: Collection5/last_17.ann  \n",
      "  inflating: Collection5/last_17.txt  \n",
      "  inflating: Collection5/last_18.ann  \n",
      "  inflating: Collection5/last_18.txt  \n",
      "  inflating: Collection5/last_19.ann  \n",
      "  inflating: Collection5/last_19.txt  \n",
      "  inflating: Collection5/last_20.ann  \n",
      "  inflating: Collection5/last_20.txt  \n",
      "  inflating: Collection5/last_21.ann  \n",
      "  inflating: Collection5/last_21.txt  \n",
      "  inflating: Collection5/last_22.ann  \n",
      "  inflating: Collection5/last_22.txt  \n",
      "  inflating: Collection5/last_23.ann  \n",
      "  inflating: Collection5/last_23.txt  \n",
      "  inflating: Collection5/last_24.ann  \n",
      "  inflating: Collection5/last_24.txt  \n",
      "  inflating: Collection5/last_25.ann  \n",
      "  inflating: Collection5/last_25.txt  \n",
      "  inflating: Collection5/last_26.ann  \n",
      "  inflating: Collection5/last_26.txt  \n",
      "  inflating: Collection5/last_27.ann  \n",
      "  inflating: Collection5/last_27.txt  \n",
      "  inflating: Collection5/last_28.ann  \n",
      "  inflating: Collection5/last_28.txt  \n",
      "  inflating: Collection5/last_29.ann  \n",
      "  inflating: Collection5/last_29.txt  \n",
      "  inflating: Collection5/last_30_new.ann  \n",
      "  inflating: Collection5/last_30_new.txt  \n",
      "  inflating: Collection5/last_31.ann  \n",
      "  inflating: Collection5/last_31.txt  \n",
      "  inflating: Collection5/last_32.ann  \n",
      "  inflating: Collection5/last_32.txt  \n",
      "  inflating: Collection5/last_33.ann  \n",
      "  inflating: Collection5/last_33.txt  \n",
      "  inflating: Collection5/last_34.ann  \n",
      "  inflating: Collection5/last_34.txt  \n",
      "  inflating: Collection5/last_35.ann  \n",
      "  inflating: Collection5/last_35.txt  \n",
      "  inflating: Collection5/last_36.ann  \n",
      "  inflating: Collection5/last_36.txt  \n",
      "  inflating: Collection5/last_37.ann  \n",
      "  inflating: Collection5/last_37.txt  \n",
      "  inflating: Collection5/last_38.ann  \n",
      "  inflating: Collection5/last_38.txt  \n",
      "  inflating: Collection5/last_39.ann  \n",
      "  inflating: Collection5/last_39.txt  \n",
      "  inflating: Collection5/last_40.ann  \n",
      "  inflating: Collection5/last_40.txt  \n",
      "  inflating: Collection5/last_41.ann  \n",
      "  inflating: Collection5/last_41.txt  \n",
      "  inflating: Collection5/last_42.ann  \n",
      "  inflating: Collection5/last_42.txt  \n",
      "  inflating: Collection5/last_43.ann  \n",
      "  inflating: Collection5/last_43.txt  \n",
      "  inflating: Collection5/last_44.ann  \n",
      "  inflating: Collection5/last_44.txt  \n",
      "  inflating: Collection5/last_45.ann  \n",
      "  inflating: Collection5/last_45.txt  \n",
      "  inflating: Collection5/last_46.ann  \n",
      "  inflating: Collection5/last_46.txt  \n",
      "  inflating: Collection5/last_47.ann  \n",
      "  inflating: Collection5/last_47.txt  \n",
      "  inflating: Collection5/last_48.ann  \n",
      "  inflating: Collection5/last_48.txt  \n",
      "  inflating: Collection5/last_49.ann  \n",
      "  inflating: Collection5/last_49.txt  \n",
      "  inflating: Collection5/last_50.ann  \n",
      "  inflating: Collection5/last_50.txt  \n",
      "  inflating: Collection5/last_51.ann  \n",
      "  inflating: Collection5/last_51.txt  \n",
      "  inflating: Collection5/last_52.ann  \n",
      "  inflating: Collection5/last_52.txt  \n",
      "  inflating: Collection5/last_53.ann  \n",
      "  inflating: Collection5/last_53.txt  \n",
      "  inflating: Collection5/last_54.ann  \n",
      "  inflating: Collection5/last_54.txt  \n",
      "  inflating: Collection5/last_55.ann  \n",
      "  inflating: Collection5/last_55.txt  \n",
      "  inflating: Collection5/last_56.ann  \n",
      "  inflating: Collection5/last_56.txt  \n",
      "  inflating: Collection5/last_57.ann  \n",
      "  inflating: Collection5/last_57.txt  \n",
      "  inflating: Collection5/last_58.ann  \n",
      "  inflating: Collection5/last_58.txt  \n",
      "  inflating: Collection5/last_59.ann  \n",
      "  inflating: Collection5/last_59.txt  \n",
      "  inflating: Collection5/last_60.ann  \n",
      "  inflating: Collection5/last_60.txt  \n",
      "  inflating: Collection5/last_61.ann  \n",
      "  inflating: Collection5/last_61.txt  \n",
      "  inflating: Collection5/last_62.ann  \n",
      "  inflating: Collection5/last_62.txt  \n",
      "  inflating: Collection5/last_63.ann  \n",
      "  inflating: Collection5/last_63.txt  \n",
      "  inflating: Collection5/last_64.ann  \n",
      "  inflating: Collection5/last_64.txt  \n",
      "  inflating: Collection5/last_65.ann  \n",
      "  inflating: Collection5/last_65.txt  \n",
      "  inflating: Collection5/last_66.ann  \n",
      "  inflating: Collection5/last_66.txt  \n",
      "  inflating: Collection5/last_67.ann  \n",
      "  inflating: Collection5/last_67.txt  \n",
      "  inflating: Collection5/last_68.ann  \n",
      "  inflating: Collection5/last_68.txt  \n",
      "  inflating: Collection5/last_69.ann  \n",
      "  inflating: Collection5/last_69.txt  \n",
      "  inflating: Collection5/last_70.ann  \n",
      "  inflating: Collection5/last_70.txt  \n",
      "  inflating: Collection5/last_71.ann  \n",
      "  inflating: Collection5/last_71.txt  \n",
      "  inflating: Collection5/last_72.ann  \n",
      "  inflating: Collection5/last_72.txt  \n",
      "  inflating: Collection5/last_73.ann  \n",
      "  inflating: Collection5/last_73.txt  \n",
      "  inflating: Collection5/last_74.ann  \n",
      "  inflating: Collection5/last_74.txt  \n",
      "  inflating: Collection5/last_75.ann  \n",
      "  inflating: Collection5/last_75.txt  \n",
      "  inflating: Collection5/lenoblast.ann  \n",
      "  inflating: Collection5/lenoblast.txt  \n",
      "  inflating: Collection5/maykl dzhekson.ann  \n",
      "  inflating: Collection5/maykl dzhekson.txt  \n",
      "  inflating: Collection5/mvd.ann     \n",
      "  inflating: Collection5/mvd.txt     \n",
      "  inflating: Collection5/mvd2.ann    \n",
      "  inflating: Collection5/mvd2.txt    \n",
      "  inflating: Collection5/rosobrnadzor.ann  \n",
      "  inflating: Collection5/rosobrnadzor.txt  \n",
      "  inflating: Collection5/ryadovoy chelah.ann  \n",
      "  inflating: Collection5/ryadovoy chelah.txt  \n",
      "  inflating: Collection5/semenenko.ann  \n",
      "  inflating: Collection5/semenenko.txt  \n",
      "  inflating: Collection5/shojgu1.ann  \n",
      "  inflating: Collection5/shojgu1.txt  \n",
      "  inflating: Collection5/shojgu3.ann  \n",
      "  inflating: Collection5/shojgu3.txt  \n",
      "  inflating: Collection5/shojgu4.ann  \n",
      "  inflating: Collection5/shojgu4.txt  \n",
      "  inflating: Collection5/shojgu6.ann  \n",
      "  inflating: Collection5/shojgu6.txt  \n",
      "  inflating: Collection5/si_tzjanpin.ann  \n",
      "  inflating: Collection5/si_tzjanpin.txt  \n",
      "  inflating: Collection5/sobjanin2.ann  \n",
      "  inflating: Collection5/sobjanin2.txt  \n",
      "  inflating: Collection5/turkmenija.ann  \n",
      "  inflating: Collection5/turkmenija.txt  \n",
      "  inflating: Collection5/uchitel.ann  \n",
      "  inflating: Collection5/uchitel.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip collection5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "UbQrXeDxr7qP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbQrXeDxr7qP",
    "outputId": "a7b36ab0-c7bc-42ae-bdfd-f6d0bd610470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object load_ne5 at 0x7fd1cffff750>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = load_ne5('Collection5/')\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37YoyR77sEaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "37YoyR77sEaf",
    "outputId": "054669a5-3e20-47ec-e551-1a905667c813"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Полиция ЮАР применила свето-шумовые гранаты на акции против Обамы\\r\\n\\r\\n\\r\\nДемонстранты выступали против приезда президента США Барака Обамы в ЮАР. В момент столкновений Обама с супругой встречались с родными Манделы.\\r\\n Столкновения полиции с демонстрантами, выступающими против приезда президента США Барака Обамы в ЮАР, произошли в субботу на окраине Йоханнесбурга, передают западные информагентства.\\r\\n\\r\\nПолиция ЮАР светошумовыми гранатами разогнала противников приезда Обамы\\r\\n\\r\\nПо сообщениям, вооруженные полицейские применили для разгона толпы свето-шумовые гранаты. Стычки с полицией произошли в поселении Соуэто, находящемся на юго-западной окраине города у здания кампуса университета Йоханнесбурга, где в субботу Обама встречается с молодежью.\\r\\n\\r\\nСтолкновения произошли в то время, когда Обама и его супруга Мишель встречались с родными Нельсона Манделы в здании фонда экс-президента ЮАР, отмечает агентство Рейтер.\\r\\n\\r\\nВ начале июня Мандела попал в госпиталь в Претории с рецидивом легочной инфекции. Несколько дней назад его состояние стало критическим, хотя затем значительно улучшилось. В субботу президент ЮАР Джейкоб Зума сообщил, что Мандела по-прежнему находится в критическом состоянии, но власти надеются, что ему станет лучше и его очень скоро выпишут.\\r\\n\\r\\nКак у экс-президента ЮАР обострились проблемы со здоровьем\\r\\n\\r\\nВ начале декабря 2012 года Мандела был госпитализирован в Йоханнесбурге. Врачи провели ряд тестов, которые выявили рецидив легочной инфекции, потребовавший соответствующего лечения. Позже экс-президенту ЮАР была успешно проведена операция по удалению камней из желчного пузыря. Незадолго до наступления нового года он был выписан из больницы. '"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = next(records).text\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "u0A1HrGwseOF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0A1HrGwseOF",
    "outputId": "d13e3ed0-2341-472e-e1b8-3dfeccdc660a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Барака Обамы', 'PERSON'),\n",
       " ('Джейкоб Зума', 'PERSON'),\n",
       " ('Мандела', 'PERSON'),\n",
       " ('Манделы', 'PERSON'),\n",
       " ('Мишель', 'PERSON'),\n",
       " ('Полиция', 'PERSON'),\n",
       " ('ЮАР', 'ORGANIZATION')}"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H3SAZq3JsxZI",
   "metadata": {
    "id": "H3SAZq3JsxZI"
   },
   "source": [
    "**Вывод**: Николай Диденко и Игорь волков правильно распознаны как персона и ЗАТО - как организация. А вот Дума Северска, новости, новый, Северск и Томской - ошибочно помечены как персона.\n",
    "\n",
    "Качество весьма посредственное."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NM_ThJw7uShc",
   "metadata": {
    "id": "NM_ThJw7uShc"
   },
   "source": [
    "## Проверить deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33Puc8FptXDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "33Puc8FptXDN",
    "outputId": "debb71da-d85e-4b1b-c3e8-f15b4eec5f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.5.0\n",
      "Uninstalling tensorflow-2.5.0:\n",
      "  Successfully uninstalled tensorflow-2.5.0\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 7.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 52.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.2.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 41.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 47.8 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, unidecode, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1 unidecode-1.2.0\n",
      "Collecting deeppavlov\n",
      "  Downloading deeppavlov-0.16.0-py3-none-any.whl (901 kB)\n",
      "\u001b[K     |████████████████████████████████| 901 kB 7.8 MB/s \n",
      "\u001b[?25hCollecting h5py==2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 27.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
      "Collecting rusenttokenize==0.0.5\n",
      "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
      "Collecting overrides==2.7.0\n",
      "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
      "Collecting scikit-learn==0.21.2\n",
      "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 21.2 MB/s \n",
      "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
      "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.1 MB/s \n",
      "\u001b[?25hCollecting pydantic==1.3\n",
      "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 40.0 MB/s \n",
      "\u001b[?25hCollecting fastapi==0.47.1\n",
      "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
      "\u001b[?25hCollecting sacremoses==0.0.35\n",
      "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
      "\u001b[K     |████████████████████████████████| 859 kB 42.7 MB/s \n",
      "\u001b[?25hCollecting pyopenssl==19.1.0\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
      "\u001b[?25hCollecting aio-pika==6.4.1\n",
      "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 20 kB/s \n",
      "\u001b[?25hCollecting pytz==2019.1\n",
      "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 50.6 MB/s \n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 41.5 MB/s \n",
      "\u001b[?25hCollecting pymorphy2==0.8\n",
      "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s \n",
      "\u001b[?25hCollecting requests==2.22.0\n",
      "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s \n",
      "\u001b[?25hCollecting uvicorn==0.11.7\n",
      "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
      "Collecting nltk==3.4.5\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 34.4 MB/s \n",
      "\u001b[?25hCollecting uvloop==0.14.0\n",
      "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 29.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
      "Collecting prometheus-client==0.7.1\n",
      "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
      "Collecting numpy==1.18.0\n",
      "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 10.3 MB/s \n",
      "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
      "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
      "\u001b[K     |████████████████████████████████| 654 kB 71.7 MB/s \n",
      "\u001b[?25hCollecting pandas==0.25.3\n",
      "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 7.4 MB/s \n",
      "\u001b[?25hCollecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 28.2 MB/s \n",
      "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
      "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
      "Collecting yarl\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 72.4 MB/s \n",
      "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
      "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl\u001b[0m\n",
      "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 7.8 MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cryptography>=2.8\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 43.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.5.30)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.0.1)\n",
      "Collecting httptools==0.1.*\n",
      "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 54.6 MB/s \n",
      "\u001b[?25hCollecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
      "\u001b[?25hCollecting websockets==8.*\n",
      "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.1 MB/s \n",
      "\u001b[?25hCollecting pamqp==2.3.0\n",
      "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
      "Collecting multidict>=4.0\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 59.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
      "Building wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449924 sha256=d160a07ec46c3755ee3862bad4c27e691b2e54e2e1d17ce82c59f92996bd40c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5604 sha256=0c9987093936f61ca84e18e9ba95a20ddab03d49a68d95c7d6778dfea14370ab\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
      "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41403 sha256=4c0665d15f2f3bb0310e4e6810a3ddde33dd61536dc2adf97c1cda2b1d479cdc\n",
      "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
      "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=3d118e21d434d6805352ba83a626260fe577530e731b91016ab2c49482abb5b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883990 sha256=3c07937b83d68e3af1c5ff2268b332c930e6635db3e0bdaae39899140d2a3cc6\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
      "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=061aebdecd3da6bf6c74a3c0af9e4508dad63898d845a914c17dd4496cb573f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
      "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
      "Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, starlette, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, fastapi, Cython, aio-pika, deeppavlov\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Attempting uninstall: sacremoses\n",
      "    Found existing installation: sacremoses 0.0.45\n",
      "    Uninstalling sacremoses-0.0.45:\n",
      "      Successfully uninstalled sacremoses-0.0.45\n",
      "  Attempting uninstall: prometheus-client\n",
      "    Found existing installation: prometheus-client 0.11.0\n",
      "    Uninstalling prometheus-client-0.11.0:\n",
      "      Successfully uninstalled prometheus-client-0.11.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.23\n",
      "    Uninstalling Cython-0.29.23:\n",
      "      Successfully uninstalled Cython-0.29.23\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\n",
      "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
      "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
      "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 deeppavlov-0.16.0 fastapi-0.47.1 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "nltk",
         "numpy",
         "pandas",
         "pytz",
         "sklearn"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# установка deeppavlov\n",
    "\n",
    "!pip uninstall -y tensorflow tensorflow-gpu\n",
    "!pip install numpy scipy librosa unidecode inflect librosa transformers\n",
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "TbCVBlkPug3D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbCVBlkPug3D",
    "outputId": "52dcb96e-eb19-44cf-a309-3e9ba1a7ff7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-08 12:27:20.35 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
      "Collecting tensorflow==1.15.5\n",
      "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 1.7 kB/s \n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 47.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.34.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
      "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 37.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.36.2)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.5.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=c28f8b73f44b64e8608f9b1548e400dee84ac9951643167fed7226569c6eb9ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built gast\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
      "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
      "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n",
      "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
      "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-tqe32sh6\n",
      "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-tqe32sh6\n",
      "Building wheels for collected packages: bert-dp\n",
      "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23591 sha256=bed4347f5d3d558a852cc8a4b487b3d3a27c1eae35944f5afb04f5dc68bb8bc2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-106qdcf4/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
      "Successfully built bert-dp\n",
      "Installing collected packages: bert-dp\n",
      "Successfully installed bert-dp-1.0\n",
      "2021-08-08 12:27:50.545 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
      "Collecting gensim==3.8.1\n",
      "  Downloading gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 81 kB/s \n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.18.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-3.8.1\n",
      "Requirement already satisfied: tensorflow==1.15.5 in /usr/local/lib/python3.7/dist-packages (1.15.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.12.1)\n",
      "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.36.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.34.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install squad_bert\n",
    "!python -m deeppavlov install ner_ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceyMhJVAunBr",
   "metadata": {
    "id": "ceyMhJVAunBr"
   },
   "outputs": [],
   "source": [
    "import deeppavlov\n",
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fmHU6VjvYj5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "5fmHU6VjvYj5",
    "outputId": "112776d4-67a4-4dcb-9ced-cdc21fa6d3f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\r\\n\\r\\nСеверск до конца года останется без сити-менеджера\\r\\n\\r\\n\\r\\nДума Северска признала несостоявшимся конкурс на пост главы администрации. Новый конкурс, скорее всего, будет объявлен осенью.\\r\\n Дума самого большого закрытого города системы Росатома — города Северск в Томской области — в четверг признала несостоявшимся конкурс на пост главы администрации, так как выдвинулся всего один претендент, сообщил РИА Новости глава конкурсной комиссии, депутат Константин Изместьев.\\r\\n\\r\\nГлава администрации ЗАТО — сити-менеджер, согласно уставу, назначается на эту должность по контракту, который заключается с мэром. Предыдущий глава Игорь Волков покинул пост 1 февраля. Исполняющим обязанности главы ЗАТО был назначен первый заместитель Волкова Николай Диденко, который до 2012 года был вице-мэром Новосибирска.\\r\\n\\r\\nКак сообщил Изместьев, на конкурс был подан только один пакет документов — от замначальника по ЖКХ, транспорту и связи администрации Северска Владимира Родыгина. Его документы были в порядке, однако, согласно положению, конкурсная комиссия должна предложить думе для голосования не менее двух кандидатов.\\r\\n\\r\\n\"Дума приняла решение принять результаты конкурса и конкурс не состоявшимся. Исполняющим обязанности главы администрации был назначен Николай Диденко\", — сказал Изместьев.\\r\\n\\r\\nПо его словам, скорее всего, новый конкурс будет объявлен осенью. \"Лето — это каникулы, думаю, что осенью дума вернется к этому вопросу и до конца года конкурс будет проведен\", — отметил глава комиссии.\\r\\n\\r\\nКонкурсные мероприятия проводит трехсторонняя комиссия из представителей госкорпорации \"Росатом\", Томской области и думы Северска. Кандидат должен иметь стаж работы на государственных или выборных муниципальных должностях, либо иметь стаж работы на руководящей должности не менее пяти лет.'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "GriAR23-vC_V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GriAR23-vC_V",
    "outputId": "eedba9a9-35e0-413a-8bc4-2cf464ecb52b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 12:30:33.896 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
      "100%|██████████| 663M/663M [11:22<00:00, 972kB/s] \n",
      "2021-08-08 12:41:57.129 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
      "2021-08-08 12:42:06.133 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle to /root/.deeppavlov/models/entity_and_type_detection_rus.pickle\n",
      "100%|██████████| 2.07M/2.07M [00:02<00:00, 835kB/s]\n",
      "2021-08-08 12:42:11.37 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz to /root/.deeppavlov/models/ner_cq_rus.tar.gz\n",
      "100%|██████████| 1.32G/1.32G [11:31<00:00, 1.91MB/s]\n",
      "2021-08-08 12:53:44.147 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/ner_cq_rus.tar.gz archive into /root/.deeppavlov/models/ner_ent_and_type_rus\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 12:54:04.74 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:571: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 12:54:33.382 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ent_and_type_rus/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ent_and_type_rus/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['\\r'],\n",
       "  ['\\n'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['С'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['ц'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['а'],\n",
       "  ['н'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['е'],\n",
       "  ['з'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['и'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  ['-'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['е'],\n",
       "  ['д'],\n",
       "  ['ж'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['Д'],\n",
       "  ['у'],\n",
       "  ['м'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['С'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['р'],\n",
       "  ['и'],\n",
       "  ['з'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['е'],\n",
       "  ['с'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['я'],\n",
       "  ['в'],\n",
       "  ['ш'],\n",
       "  ['и'],\n",
       "  ['м'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  [],\n",
       "  ['а'],\n",
       "  ['д'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['ц'],\n",
       "  ['и'],\n",
       "  ['и'],\n",
       "  ['.'],\n",
       "  [],\n",
       "  ['Н'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['е'],\n",
       "  ['е'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  ['с'],\n",
       "  ['е'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['у'],\n",
       "  ['д'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['б'],\n",
       "  ['ъ'],\n",
       "  ['я'],\n",
       "  ['в'],\n",
       "  ['л'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['ь'],\n",
       "  ['ю'],\n",
       "  ['.'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  [],\n",
       "  ['Д'],\n",
       "  ['у'],\n",
       "  ['м'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['а'],\n",
       "  ['м'],\n",
       "  ['о'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['ь'],\n",
       "  ['ш'],\n",
       "  ['о'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['з'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  ['р'],\n",
       "  ['ы'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['е'],\n",
       "  ['м'],\n",
       "  ['ы'],\n",
       "  [],\n",
       "  ['Р'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['а'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['м'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['—'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['С'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  [],\n",
       "  ['Т'],\n",
       "  ['о'],\n",
       "  ['м'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['б'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['—'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  [],\n",
       "  ['ч'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  ['в'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['г'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['р'],\n",
       "  ['и'],\n",
       "  ['з'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['е'],\n",
       "  ['с'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['я'],\n",
       "  ['в'],\n",
       "  ['ш'],\n",
       "  ['и'],\n",
       "  ['м'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  [],\n",
       "  ['а'],\n",
       "  ['д'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['ц'],\n",
       "  ['и'],\n",
       "  ['и'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['т'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  ['д'],\n",
       "  ['в'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['у'],\n",
       "  ['л'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  ['с'],\n",
       "  ['е'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['р'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['д'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['т'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['о'],\n",
       "  ['о'],\n",
       "  ['б'],\n",
       "  ['щ'],\n",
       "  ['и'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['Р'],\n",
       "  ['И'],\n",
       "  ['А'],\n",
       "  [],\n",
       "  ['Н'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['н'],\n",
       "  ['о'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['с'],\n",
       "  ['и'],\n",
       "  ['и'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['е'],\n",
       "  ['п'],\n",
       "  ['у'],\n",
       "  ['т'],\n",
       "  ['а'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['К'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['а'],\n",
       "  ['н'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['И'],\n",
       "  ['з'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['ь'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['.'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['Г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['а'],\n",
       "  ['д'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['ц'],\n",
       "  ['и'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['З'],\n",
       "  ['А'],\n",
       "  ['Т'],\n",
       "  ['О'],\n",
       "  [],\n",
       "  ['—'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['и'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  ['-'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['е'],\n",
       "  ['д'],\n",
       "  ['ж'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['о'],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['с'],\n",
       "  ['н'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['у'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['у'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['з'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['ч'],\n",
       "  ['а'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['э'],\n",
       "  ['т'],\n",
       "  ['у'],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['ж'],\n",
       "  ['н'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['ь'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  ['т'],\n",
       "  ['у'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['ы'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['з'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  ['л'],\n",
       "  ['ю'],\n",
       "  ['ч'],\n",
       "  ['а'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  ['с'],\n",
       "  ['я'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  [],\n",
       "  ['м'],\n",
       "  ['э'],\n",
       "  ['р'],\n",
       "  ['о'],\n",
       "  ['м'],\n",
       "  ['.'],\n",
       "  [],\n",
       "  ['П'],\n",
       "  ['р'],\n",
       "  ['е'],\n",
       "  ['д'],\n",
       "  ['ы'],\n",
       "  ['д'],\n",
       "  ['у'],\n",
       "  ['щ'],\n",
       "  ['и'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['И'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['ь'],\n",
       "  [],\n",
       "  ['В'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['к'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['у'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['1'],\n",
       "  [],\n",
       "  ['ф'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['л'],\n",
       "  ['я'],\n",
       "  ['.'],\n",
       "  [],\n",
       "  ['И'],\n",
       "  ['с'],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['н'],\n",
       "  ['я'],\n",
       "  ['ю'],\n",
       "  ['щ'],\n",
       "  ['и'],\n",
       "  ['м'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['б'],\n",
       "  ['я'],\n",
       "  ['з'],\n",
       "  ['а'],\n",
       "  ['н'],\n",
       "  ['н'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  [],\n",
       "  ['З'],\n",
       "  ['А'],\n",
       "  ['Т'],\n",
       "  ['О'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['ы'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['з'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['ч'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['в'],\n",
       "  ['ы'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['з'],\n",
       "  ['а'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['и'],\n",
       "  ['т'],\n",
       "  ['е'],\n",
       "  ['л'],\n",
       "  ['ь'],\n",
       "  [],\n",
       "  ['В'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['Н'],\n",
       "  ['и'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['Д'],\n",
       "  ['и'],\n",
       "  ['д'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['ы'],\n",
       "  ['й'],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['2'],\n",
       "  ['0'],\n",
       "  ['1'],\n",
       "  ['2'],\n",
       "  [],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['ы'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  ['и'],\n",
       "  ['ц'],\n",
       "  ['е'],\n",
       "  ['-'],\n",
       "  ['м'],\n",
       "  ['э'],\n",
       "  ['р'],\n",
       "  ['о'],\n",
       "  ['м'],\n",
       "  [],\n",
       "  ['Н'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  ['о'],\n",
       "  ['с'],\n",
       "  ['и'],\n",
       "  ['б'],\n",
       "  ['и'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  ['а'],\n",
       "  ['.'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['\\r'],\n",
       "  ['\\n'],\n",
       "  ['К'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['о'],\n",
       "  ['о'],\n",
       "  ['б'],\n",
       "  ['щ'],\n",
       "  ['и'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['И'],\n",
       "  ['з'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['ь'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  ['н'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['ы'],\n",
       "  ['л'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['а'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['л'],\n",
       "  ['ь'],\n",
       "  ['к'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['а'],\n",
       "  ['к'],\n",
       "  ['е'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['о'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['т'],\n",
       "  ['о'],\n",
       "  ['в'],\n",
       "  [],\n",
       "  ['—'],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['т'],\n",
       "  [],\n",
       "  ['з'],\n",
       "  ['а'],\n",
       "  ['м'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['ч'],\n",
       "  ['а'],\n",
       "  ['л'],\n",
       "  ['ь'],\n",
       "  ['н'],\n",
       "  ['и'],\n",
       "  ['к'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['Ж'],\n",
       "  ['К'],\n",
       "  ['Х'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['н'],\n",
       "  ['с'],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['т'],\n",
       "  ['у'],\n",
       "  [],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['с'],\n",
       "  ['в'],\n",
       "  ['я'],\n",
       "  ['з'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['а'],\n",
       "  ['д'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['и'],\n",
       "  ['с'],\n",
       "  ['т'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  ['ц'],\n",
       "  ['и'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['С'],\n",
       "  ['е'],\n",
       "  ['в'],\n",
       "  ['е'],\n",
       "  ['р'],\n",
       "  ['с'],\n",
       "  ['к'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['В'],\n",
       "  ['л'],\n",
       "  ['а'],\n",
       "  ['д'],\n",
       "  ['и'],\n",
       "  ['м'],\n",
       "  ['и'],\n",
       "  ['р'],\n",
       "  ['а'],\n",
       "  [],\n",
       "  ['Р'],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['ы'],\n",
       "  ['г'],\n",
       "  ['и'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ['.'],\n",
       "  [],\n",
       "  ['Е'],\n",
       "  ['г'],\n",
       "  ['о'],\n",
       "  [],\n",
       "  ['д'],\n",
       "  ['о'],\n",
       "  ['к'],\n",
       "  ['у'],\n",
       "  ['м'],\n",
       "  ['е'],\n",
       "  ['н'],\n",
       "  ['т'],\n",
       "  ['ы'],\n",
       "  [],\n",
       "  ['б'],\n",
       "  ['ы'],\n",
       "  ['л'],\n",
       "  ['и'],\n",
       "  [],\n",
       "  ['в'],\n",
       "  [],\n",
       "  ['п'],\n",
       "  ['о'],\n",
       "  ['р'],\n",
       "  ['я'],\n",
       "  ['д'],\n",
       "  ['к'],\n",
       "  ['е'],\n",
       "  [','],\n",
       "  [],\n",
       "  ['о'],\n",
       "  ['д'],\n",
       "  ['н'],\n",
       "  ['а'],\n",
       "  ...],\n",
       " array([[[0.9062447 , 0.08021647, 0.01353872]],\n",
       " \n",
       "        [[0.9062447 , 0.08021647, 0.01353872]],\n",
       " \n",
       "        [[0.9062447 , 0.08021647, 0.01353872]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.8517804 , 0.12466325, 0.02355628]],\n",
       " \n",
       "        [[0.910557  , 0.07432719, 0.0151158 ]],\n",
       " \n",
       "        [[0.9711703 , 0.02443417, 0.00439548]]], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)\n",
    "deeppavlov_ner(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ash5XzYq2T6f",
   "metadata": {
    "id": "Ash5XzYq2T6f"
   },
   "source": [
    "## Написать свой нер попробовать разные подходы\n",
    " 1. передаём в сетку токен и его соседей\n",
    " 2. передаём в сетку только токен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "k1DIsqdj1qiy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1DIsqdj1qiy",
    "outputId": "6924250a-f840-4800-8db3-313d837f1f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "RVPKMidu1uP7",
   "metadata": {
    "id": "RVPKMidu1uP7"
   },
   "outputs": [],
   "source": [
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "K3NgkHBN1wtD",
   "metadata": {
    "id": "K3NgkHBN1wtD"
   },
   "outputs": [],
   "source": [
    "words_docs = []\n",
    "for ix, rec in enumerate(records):\n",
    "    words = []\n",
    "    for token in tokenize(rec.text):\n",
    "        # if \"http://\" in input:\n",
    "        #   token='None'\n",
    "        type_ent = 'OUT'\n",
    "        for ent in rec.spans:\n",
    "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
    "                type_ent = ent.type\n",
    "                break\n",
    "        words.append([token.text, type_ent])\n",
    "    words_docs.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "NZcEz2U826Vr",
   "metadata": {
    "id": "NZcEz2U826Vr"
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "WMzpp6pt27cv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMzpp6pt27cv",
    "outputId": "762a465c-14aa-4617-c489-26127d7a19b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         219001\n",
       "PER          21182\n",
       "ORG          13651\n",
       "LOC           4563\n",
       "GEOPOLIT      4346\n",
       "MEDIA         2481\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "twu8SSjM2_pL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twu8SSjM2_pL",
    "outputId": "a5b98ce7-90ef-48a6-df0e-61fa78870cbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265224, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "BQ-V4qT_3F9b",
   "metadata": {
    "id": "BQ-V4qT_3F9b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input, Bidirectional,Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn import model_selection, preprocessing, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "g3duN-hS4dQl",
   "metadata": {
    "id": "g3duN-hS4dQl"
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nsEPMkrw4if7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsEPMkrw4if7",
    "outputId": "50080dbe-2504-4eaf-bb5c-388d41f5f5dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.apply(len).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nmyOb7YC4lbS",
   "metadata": {
    "id": "nmyOb7YC4lbS"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
    "\n",
    "train_data = train_data.batch(2048)\n",
    "valid_data = valid_data.batch(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5NXkkW-t4n5B",
   "metadata": {
    "id": "5NXkkW-t4n5B"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2kBoS6Jy4qbd",
   "metadata": {
    "id": "2kBoS6Jy4qbd"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    return input_data\n",
    "\n",
    "vocab_size = 30000\n",
    "seq_len = 10\n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    # ngrams=(1, 3),\n",
    "    output_sequence_length=seq_len\n",
    "    )\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "JhzaCGmC4tLR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhzaCGmC4tLR",
    "outputId": "a6c828c3-e76d-45d8-ad57-c3e794f3265c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01585075, 0.01757005, 0.00924502, 0.05195608, 0.82677284,\n",
       "       0.07860525])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=np.unique(encoder.inverse_transform(valid_y),return_counts=True)[1]\n",
    "t=t/t.sum()\n",
    "t  # распределение таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Ds0fhF4D405-",
   "metadata": {
    "id": "Ds0fhF4D405-"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  tf.keras.layers.Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\n",
    "  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "  tf.keras.layers.Dense(300, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  # tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(6, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d61JyB1k42Av",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d61JyB1k42Av",
    "outputId": "074734fa-8fe1-4644-8918-c3679d654cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 6s 25ms/step - loss: 0.7278 - accuracy: 0.8198 - val_loss: 0.4003 - val_accuracy: 0.8277\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 0.2800 - accuracy: 0.9028 - val_loss: 0.2545 - val_accuracy: 0.9271\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.1600 - accuracy: 0.9494 - val_loss: 0.2335 - val_accuracy: 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd16a695950>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',         \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_data, validation_data=valid_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1TNEN5BY45fQ",
   "metadata": {
    "id": "1TNEN5BY45fQ"
   },
   "outputs": [],
   "source": [
    "pred=model.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "BQ1yWk3E47Ux",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQ1yWk3E47Ux",
    "outputId": "e70cd8b6-6a07-4109-d3c7-49a390c8ca52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GEOPOLIT', 1.0064137770407093),\n",
       " ('LOC', 0.9470936289193036),\n",
       " ('MEDIA', 0.8778728546200967),\n",
       " ('ORG', 1.343452731090637),\n",
       " ('OUT', 0.9945523157079739),\n",
       " ('PER', 0.8559166679611959)]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(encoder.classes_,pred.mean(axis=0)/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "LXFSbt0y49iX",
   "metadata": {
    "id": "LXFSbt0y49iX"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\n",
    "    # tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(6,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "W7zA2G_Y4_VU",
   "metadata": {
    "id": "W7zA2G_Y4_VU"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bywEPF_o5Aug",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bywEPF_o5Aug",
    "outputId": "9896db63-e315-45e6-f8a3-ee8069067dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 17s 67ms/step - loss: 0.8678 - accuracy: 0.8205 - val_loss: 0.4065 - val_accuracy: 0.8626\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 5s 48ms/step - loss: 0.3236 - accuracy: 0.8890 - val_loss: 0.3002 - val_accuracy: 0.8986\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 0.2136 - accuracy: 0.9359 - val_loss: 0.2530 - val_accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd17e22a210>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=valid_data, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
